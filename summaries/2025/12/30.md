# Hacker News Summary - 2025-12-30

## [Kidnapped by Deutsche Bahn](https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/)
**Score:** 934 | **Comments:** 838 | **ID:** 46419970

> **Article:** The article "Kidnapped by Deutsche Bahn" details a frustrating travel experience with Germany's national railway. The author's train was severely delayed due to a technical issue. Instead of terminating at the intended station, the train was rerouted to a different city, 60km past the author's destination. When the author attempted to get off at their stop, the train crew refused, stating that the train was not scheduled to stop there and they were not authorized to open the doors. The author was effectively forced to travel far beyond their destination, highlighting a rigid adherence to procedure over common sense and customer service.
>
> **Discussion:** The discussion on Hacker News is extensive, with many commenters sharing similar negative experiences with Deutsche Bahn (DB) and other European rail systems. A central theme is the comparison of rail reliability and service across countries. Many users from the UK and other parts of Europe confirm that DB's issues are not unique, with the UK's system often cited as even more expensive and dysfunctional. However, others argue that DB's problems, particularly its high delay rates and lack of communication, are uniquely bad for a major European nation.

There is a significant debate about the root causes. One perspective, often from those who have lived in Germany, is that Germans have an exceptionally low tolerance for any inconvenience and that DB is still a robust system compared to places like the US. They argue that many delays are due to unpredictable events (e.g., accidents, technical failures) that are difficult to prevent. The opposing view is that these issues are systemic, pointing to a lack of investment, poor management, and rigid bureaucracy. The incident in the article—forcing passengers to travel 60km past their stop due to scheduling rules—is cited as a prime example of this inflexibility.

Other key points include:
*   **Customer Service:** A major point of contention. While some defend UK staff, many describe DB and UK staff as unhelpful and apathetic, with secure jobs leading to a lack of motivation to assist passengers.
*   **Cost:** The high price of train travel in both Germany and the UK is frequently mentioned as a major deterrent, making driving a more attractive option for many.
*   **International Perceptions:** Commenters from outside Europe expressed surprise at the dysfunction, having previously viewed German trains as a model of efficiency.
*   **Proposed Solutions:** Some suggest that airline-style compensation rules for delays could provide the necessary financial incentive for rail operators to improve reliability.

---

## [GOG is getting acquired by its original co-founder](https://www.gog.com/blog/gog-is-getting-acquired-by-its-original-co-founder-what-it-means-for-you/)
**Score:** 529 | **Comments:** 295 | **ID:** 46422412

> **Article:** CD Projekt Red, the parent company of the GOG.com digital game store, is selling GOG to its original co-founder, Michał Kiciński. The official rationale is strategic: CD Projekt wants to focus exclusively on developing high-quality RPGs and entertainment based on its intellectual properties (like The Witcher and Cyberpunk). For GOG, the acquisition is framed as a way to gain stronger, independent backing to pursue its core mission of game preservation, DRM-free gaming, and long-term player ownership. GOG's leadership states the company is financially stable and that this move will accelerate its unique value proposition.
>
> **Discussion:** The Hacker News community largely welcomed the news, viewing the acquisition as a positive step for GOG's long-term health and its mission of ethical, DRM-free game distribution. Many commenters expressed strong support for GOG as a principled alternative to Steam, emphasizing the importance of true game ownership over what one user called "leasing" games on other platforms.

A central theme was the preservation of game history. Users noted that shareholder-driven corporations often neglect older titles, and GOG's independence under a founder who values this mission is crucial for keeping classic games accessible and playable on modern systems.

However, there was a notable split on the financial implications. While the official announcement described GOG's recent performance as "encouraging," some users interpreted this as corporate euphemism for financial instability. They argued that a truly successful company wouldn't need to be sold. Others countered that the sale allows GOG to escape the high-pressure, all-or-nothing cycle of AAA game development, where a single commercial flop (like the troubled launch of *Cyberpunk 2077*, which some defended as a long-term success) could threaten the entire division.

Finally, practical concerns were raised about GOG's platform. Several users reiterated long-standing requests for a native Linux client or better support for third-party tools like the Heroic Games Launcher, while others noted that GOG's user experience can be less polished than Steam's, though they considered the trade-off for DRM-free games to be worthwhile.

---

## [You can make up HTML tags](https://maurycyz.com/misc/make-up-tags/)
**Score:** 529 | **Comments:** 177 | **ID:** 46416945

> **Article:** The article "You can make up HTML tags" explains that modern browsers will render any non-standard HTML tag (e.g., `<my-custom-tag>`) without error. By default, these unknown elements behave like inline `<span>` elements, but they can be fully styled with CSS and manipulated with JavaScript just like standard elements. The author presents this as a simple, native way to create semantic markup for specific projects without needing complex frameworks or libraries, essentially highlighting the power of standard HTML behavior.
>
> **Discussion:** The Hacker News discussion largely validates the article's premise but quickly pivots to the distinction between "raw" unknown tags and formalized Web Components. While several users confirm that unknown tags are treated as `HTMLElement` (or `HTMLUnknownElement`) and function fine with CSS and selectors, the consensus is that for any serious application, one should use the Custom Elements API (Web Components).

Key themes in the discussion include:

*   **Web Components vs. "Tag Soup":** Many commenters, including those who like the idea of custom tags, advocate for using the Custom Elements API (referencing libraries like Lit) rather than just writing raw HTML with made-up tags. This ensures the elements have defined behavior and lifecycle, and degrades gracefully if JavaScript fails to load.
*   **Semantic HTML vs. Div Soup:** A significant sub-thread debated the article's example of using custom tags to structure a document. Several users argued that the example was unnecessary "div soup" and that standard semantic HTML tags (`<article>`, `<header>`, `<blockquote>`) were the correct, accessible choice.
*   **Nostalgia and Framework Fatigue:** Several developers expressed frustration with the dominance of heavy frameworks like React. They view native Web Components (and the ability to use custom tags) as a "beautiful, elegant solution" that allows for complex UIs without the overhead of a Virtual DOM or SPA architecture.
*   **Browser Mechanics:** Technical details were clarified regarding how browsers handle these tags—specifically, that valid custom element names (containing a hyphen) result in an `HTMLElement` instance rather than `HTMLUnknownElement`, to allow for future prototype upgrades.

---

## [Google is dead. Where do we go now?](https://www.circusscientist.com/2025/12/29/google-is-dead-where-do-we-go-now/)
**Score:** 483 | **Comments:** 459 | **ID:** 46425198

> **Article:** The article, written by the operator of a small entertainment agency in Durban, South Africa, laments the decline of Google AdWords as an effective marketing tool. The author notes that while AdWords was once their primary source of leads, it has become prohibitively expensive and ineffective, leading to a sharp drop in business. The post is a plea for advice from other small businesses on where to migrate their marketing efforts in a post-Google world, expressing frustration and uncertainty about the future of online advertising for small players.
>
> **Discussion:** The Hacker News discussion largely validates the author's experience, framing it as a symptom of broader shifts in the internet landscape rather than an isolated issue. A central theme is that the "open web," which Google's search and ad platforms were built upon, is dying. Users are increasingly finding information within "walled gardens" like social media apps, a trend confirmed by one commenter's anecdote about planning a trip entirely through social media.

There is a strong consensus that the decline of Google AdWords is a positive development for many. Several users shared experiences of it being a costly "scam" plagued by click fraud and opaque results. They express hope that AI will eventually "equal the playing field" by promoting businesses based on merit rather than advertising budget.

However, a counterpoint was raised that while the ad model is failing, the underlying business is thriving, with one user pointing to Google's stock performance. The conversation also explored alternatives like the search engine Kagi, but this was met with skepticism, as its viability depends on the very open web that is perceived to be in decline. Ultimately, the discussion paints a picture of a small business caught in a difficult transition, where the old certainties of online marketing have evaporated without a clear successor.

---

## [Show HN: Z80-μLM, a 'Conversational AI' That Fits in 40KB](https://github.com/HarryR/z80ai)
**Score:** 470 | **Comments:** 106 | **ID:** 46417815

> **Project:** The project is 'Z80-μLM', a 'Conversational AI' model designed to run on vintage Z80-based computers (like the Sinclair ZX Spectrum or CP/M systems) with extreme hardware constraints. The entire model, including its weights and inference logic, fits within a 40KB binary file (.com). It is a proof-of-concept demonstrating that a tiny, purpose-built language model can generate text and hold simple conversations on hardware from the late 1970s and 1980s. The author provides the source code and binaries on GitHub, aiming to show what is possible with minimal resources.
>
> **Discussion:** The Hacker News community reacted with enthusiasm, primarily marveling at the technical achievement of fitting a model into such a tiny footprint. The discussion revolved around several key themes:

*   **Nostalgia and "Magic":** Many commenters expressed delight at the concept, imagining how magical this would have seemed in the 1980s. The idea of an "LLM in a .com file" was highlighted as particularly impressive. Some noted, however, that the output is so terse it might not feel as "magical" as a more verbose ELIZA-style bot.
*   **Practical Applications and Demos:** A top request was for a Z80 simulator or emulator set up with the project, allowing people to play with it directly in their browser without needing vintage hardware. One user noted a remarkable coincidence, mentioning they were working on a project involving a CP/M emulator and coding agents that this would fit into perfectly.
*   **Technical and Hardware Context:** Users discussed the hardware limitations of the era, with one recalling how power-hungry early digital cameras were. Another commenter, who builds their own Z80 computers, expressed excitement to try it out. A humorous concern was raised that AI companies might start buying up all the Z80 chips, though another user pointed out they are already largely unavailable.
*   **Security and Interpretability:** A more advanced discussion emerged about whether a secret (like a passphrase) could be securely embedded in such a small model's weights. The consensus was that with a model this tiny, the secret would likely be easily reverse-engineered, linking the concept to the academic field of "interpretability" and "undetectable backdoors" in machine learning.
*   **Model Size:** One commenter humorously corrected the "LLM" label to "SLM" (Small Language Model), acknowledging the scale.

---

## [List of domains censored by German ISPs](https://cuiiliste.de/domains)
**Score:** 297 | **Comments:** 117 | **ID:** 46423566

> **Article:** The linked article from cuiiliste.de presents a list of domains censored by German Internet Service Providers (ISPs). The censorship is implemented via DNS blocks, primarily targeting websites involved in copyright infringement, such as illicit streaming services and major piracy archives like Anna's Archive and Sci-Hub. The list is curated by CUII, a private organization backed by the film industry, which ISPs voluntarily adopt rather than being a government mandate.
>
> **Discussion:** The Hacker News discussion reveals that the censorship is not a government mandate but a voluntary, industry-driven initiative by a private entity called CUII. Consequently, the blocks are easily circumvented by using alternative DNS providers like NextDNS or ControlD, or by using encrypted DNS protocols like DNS-over-HTTPS (DoH) or VPNs. Users noted that many smaller German ISPs do not enforce these blocks at all.

While some commenters jokingly treated the list as a "collection of the best pirate sites," others expressed concern over the scope of the blocks, which include legitimate resources like Anna's Archive and Sci-Hub. The conversation also touched on the broader context of German strictness regarding copyright enforcement, contrasting it with the country's stance on other issues like "hate speech." A talk at the upcoming Chaos Communication Congress (39c3) was highlighted as a resource for further information on the topic.

---

## [Tesla's 4680 battery supply chain collapses as partner writes down deal by 99%](https://electrek.co/2025/12/29/tesla-4680-battery-supply-chain-collapses-partner-writes-down-dea/)
**Score:** 269 | **Comments:** 302 | **ID:** 46423290

> **Article:** The article from Electrek reports that L&F, a key supplier for Tesla's 4680 battery cells, has written down its supply contract with Tesla from a value of $2.9 billion to just $7,386. This massive 99.999% reduction indicates a near-total collapse of the supply agreement, suggesting that Tesla's production and demand for the 4680 cells have failed to materialize as planned. The 4680 cell was previously touted as a revolutionary component essential for producing a low-cost $25,000 vehicle.
>
> **Discussion:** The HN discussion is overwhelmingly skeptical of Tesla's current trajectory and valuation. The central theme is the disconnect between the company's poor operational performance and its high stock price. Many commenters attribute this to a speculative bubble, comparing Tesla stock to a "tulip future" or a "call option on Musk succeeding," where the value is based on hype and hope rather than fundamentals.

Several key points were raised:
*   **Valuation vs. Reality:** Users express disbelief that the stock remains high despite numerous negative indicators, such as declining sales in Europe, China, and the US, and the failure of major technological promises like the 4680 battery and Robotaxi.
*   **Accusations of Financial Engineering:** A significant point of contention is the practice of Tesla's affiliated companies (like SpaceX) purchasing unsold Cybertrucks. Commenters view this as a form of "quasi-fraud" or "greater fool" scheme designed to artificially inflate revenue and hide weak consumer demand.
*   **Skepticism of the Source:** One commenter dismisses the article's source (Electrek) as one-sided, suggesting the 4680 program might simply be undergoing a strategic pause rather than a total collapse.
*   **Technical Disappointment:** On a technical level, some argued that the 4680 cell was never as revolutionary as marketed, being just a larger form factor with a problematic chemistry that failed to deliver on its promises.
*   **Broader Market Concerns:** The discussion broadened to the future of EVs, with some expressing pessimism that Tesla's struggles and a political shift towards fossil fuels are putting the entire electrification movement at risk.

---

## [Show HN: Vibe coding a bookshelf with Claude Code](https://balajmarius.com/writings/vibe-coding-a-bookshelf-with-claude-code/)
**Score:** 254 | **Comments:** 191 | **ID:** 46420453

> **Project:** The project is a web-based "bookshelf" application created by "vibe coding" with Claude Code. It's a personal software tool designed to visually organize and display a user's books. The author presents it as an example of how AI coding assistants can rapidly build functional, single-user applications that work exactly as the user desires, without the overhead of building for a broad audience.
>
> **Discussion:** The discussion centers on the nature, utility, and limitations of "vibe coding" (using AI to generate code with high-level prompts). Commenters largely praise the project as an ideal use case for this technology: creating small, personal, single-purpose applications. A key theme is the distinction between intent and execution, where the human provides the vision and taste, and the AI handles the implementation. This is seen as a major productivity boost, especially for developers who don't code daily.

However, there is a consensus on the limitations of this approach. Several users note that "vibe coding" works best for small, self-contained projects. For larger, more complex systems, they argue that the developer must take a more hands-on role, providing detailed architectural guidance and carefully reviewing the code to prevent bugs and unnecessary abstractions. The conversation also touches on the future role of human "taste" in an AI-driven world, with some believing it will remain a key differentiator while others are more skeptical. The project itself also evoked nostalgia for an older Mac application, Delicious Library, which had a similar purpose and aesthetic.

---

## [You can't design software you don't work on](https://www.seangoedecke.com/you-cant-design-software-you-dont-work-on/)
**Score:** 243 | **Comments:** 85 | **ID:** 46418415

> **Article:** The article "You can't design software you don't work on" argues against the idea of high-level, "generic" software design. The author contends that while general principles (like DRY or SOLID) are useful, they are insufficient for making specific architectural decisions in a large, existing codebase. True design knowledge, he claims, is deeply contextual and emerges from the act of implementation. You cannot effectively decide whether a new feature belongs in subsystem A or B without understanding the hidden dependencies, historical constraints, and specific quirks of the existing code. The author posits that the "map is not the territory": a design document is an abstraction that inevitably misses the crucial details known only to those who write the code. Therefore, the most effective designers are the developers who are actively working on the system.
>
> **Discussion:** The Hacker News discussion largely validates the article's central thesis, though it explores several nuances and counterarguments. A key point of agreement is that while high-level principles are good for setting direction, the "map is not the territory," and implementation details inevitably force deviations from the plan. One commenter invoked Naur's "Theory of Programming," which posits that the true knowledge of a system resides in the minds of its developers, not in documents.

The conversation then branched into several threads:
*   **The Engineering vs. Art Debate:** An analogy to structural engineering was challenged by the argument that software lacks the stable, material constraints of physical construction. This led to a debate on whether software development is a true engineering discipline or a more creative, artistic endeavor due to its rapidly changing nature.
*   **The Complexity of Real-World Requirements:** A powerful example of implementing a "free sample" feature for an online retailer illustrated how seemingly simple requirements hide immense complexity. This was used to argue that upfront design is impossible because these hidden details only emerge during implementation. A counterpoint suggested that good architectural patterns (like separating policy from mechanism) could manage this complexity, but the original poster retorted that such advice is useless if the existing codebase isn't structured to support it.
*   **Experience and Consistency:** Some argued that with enough experience building similar systems, one *can* design effectively without coding. However, others countered that this applies to new projects, whereas the article's point is most relevant when adding features to existing, complex systems. The importance of consistency over "ideal" design was also debated, with one side arguing it prevents chaos and the other warning it can entrench bad practices.

Ultimately, the discussion converged on the idea that the most effective design process is emergent, driven by developers who are deeply embedded in the system's reality.

---

## [Staying ahead of censors in 2025](https://forum.torproject.org/t/staying-ahead-of-censors-in-2025-what-weve-learned-from-fighting-censorship-in-iran-and-russia/20898)
**Score:** 230 | **Comments:** 287 | **ID:** 46417844

> **Article:** The article "Staying ahead of censors in 2025" from the Tor Project forum details the technical evolution required to combat sophisticated internet censorship in restrictive regimes like Iran and Russia. As censors move beyond simple IP blocking to use Deep Packet Inspection (DPI) to identify traffic patterns, Tor's countermeasures have shifted from simple obfuscation to "mimicry." The two primary new technologies discussed are **WebTunnel**, which disguises Tor traffic to look exactly like standard HTTPS traffic on a regular website, and **Conjure**, which leverages unused IP address space at the ISP level to hide the initial connection handshake. This forces censors into a dilemma: blocking these new traffic patterns would require them to break the normal functioning of the internet for their own citizens.
>
> **Discussion:** The Hacker News discussion primarily revolves around three main themes: the technical specifics of censorship, the legal and political context of Tor's operations, and a debate over the definition of censorship itself.

Technically, users were fascinated by the "Conjure" concept of using unused IP space, with one user noting the immense difficulty of convincing ISPs to cooperate. There was also a detailed side-discussion about the current state of censorship in China, where users shared that the ecosystem has evolved beyond simple VPNs to a complex market of protocols (like V2Ray and Trojan) and specialized, paid-for network routes (like CN2 GIA) to bypass the "Great Firewall."

A significant portion of the debate focused on the legal and ethical implications of providing tools to sanctioned countries. One user, facing their own business dilemma, questioned if Tor needs an OFAC license to operate in Iran and Russia, given its encryption capabilities. This sparked a counter-argument that Tor is free software and an act of speech, not a commercial "trade" regulated by OFAC, and therefore not subject to such restrictions. This led to speculation that Tor's funding from the US government influences its public focus on adversaries like Russia and Iran while ignoring censorship in allied nations.

Finally, several commenters challenged the article's narrow scope, arguing that censorship is a growing problem in Western democracies. They pointed to "chat control," age verification laws, and a high number of arrests for online speech in the UK and EU, suggesting these countries should also be considered part of the censorship landscape. The conversation concluded with a user pointing out that the core technical challenge has shifted: "random-looking" encrypted traffic is now a red flag for censors, making mimicry of legitimate traffic the new frontier in the cat-and-mouse game.

---

## [Libgodc: Write Go Programs for Sega Dreamcast](https://github.com/drpaneas/libgodc)
**Score:** 205 | **Comments:** 47 | **ID:** 46420672

> **Article:** The article introduces "libgodc," a Go runtime for the Sega Dreamcast console. Created by drpaneas, the project allows developers to write programs and games in Go for the 1999 hardware, utilizing features like goroutines, channels, and garbage collection despite the severe constraints of a 200MHz SH4 CPU and 16MB of RAM. The runtime compiles using gccgo and integrates with the KallistiOS homebrew SDK. The repository includes documentation, video tutorials, and example games such as Pong, Breakout, and a Platformer.
>
> **Discussion:** The Hacker News community reacted with high praise, specifically highlighting the project's documentation as exceptionally thorough and professional, rivaling or exceeding that of major corporations. The conversation touched on several key themes:

*   **Technical Feasibility and Constraints:** Users discussed the technical challenges of running Go on such limited hardware (16MB RAM, single-core). There was specific interest in the compiler used (gccgo) and its limitations, such as the lack of support for Go Generics.
*   **Nostalgia and Hardware Perspective:** While the constraints are severe by modern standards, some users noted that the Dreamcast was a powerhouse of its era. The discussion highlighted the impressive optimization required to run complex games like *Shenmue* on the hardware, contrasting it ironically with the bloat of modern software like Microsoft Teams.
*   **Alternative Approaches:** A sub-thread emerged regarding using WebAssembly (WASM) and the `wasip1` port for running Go on niche hardware, with users suggesting TinyGo as a potential alternative for resource-constrained environments.
*   **Future Potential:** Commenters expressed interest in the potential for porting classic games to the platform using Go.

---

## [Nvidia takes $5B stake in Intel under September agreement](https://www.reuters.com/legal/transactional/nvidia-takes-5-billion-stake-intel-under-september-agreement-2025-12-29/)
**Score:** 196 | **Comments:** 85 | **ID:** 46423010

> **Article:** Nvidia is investing $5 billion in Intel as part of an agreement made in September. This acquisition gives Nvidia a significant ownership stake (approximately 4%) in its primary competitor in the CPU market, making Nvidia one of Intel's largest shareholders alongside the US government and major investment firms.
>
> **Discussion:** The Hacker News community reacted to the news with a mix of skepticism regarding Intel's future, analysis of the financial implications, and concerns over market consolidation.

Many commenters doubted that a simple cash injection would solve Intel's deep-rooted manufacturing issues. The consensus is that Intel's primary struggle is a lack of technical expertise ("wizards") and advanced manufacturing capabilities, which money alone cannot easily fix, especially given the global shortage of EUV lithography experts.

There was significant discussion regarding the actual ownership structure of Intel. While the post implies Nvidia is a top shareholder, users corrected that major institutional investors (BlackRock, Vanguard) and the US government hold larger stakes. However, the presence of Nvidia, SoftBank, and the US government as major stakeholders was described as an "interesting turn of events."

The conversation also touched on broader economic themes. Some viewed this investment as a symptom of a "circular economy" where capital flows between large entities without generating new value, while others defended the velocity of money as a standard economic mechanism. There was also speculation that this move might be a strategic play by Nvidia to stifle potential AI competition by propping up a struggling rival.

Finally, a minor philosophical debate emerged regarding corporate ownership structures, with some users questioning the utility of corporations owning other corporations, while others defended the practice as essential for limiting liability.

---

## [Swapping SIM cards used to be easy, and then came eSIM](https://arstechnica.com/gadgets/2025/12/i-switched-to-esim-in-2025-and-i-am-full-of-regret/)
**Score:** 195 | **Comments:** 225 | **ID:** 46421653

> **Article:** The article, "I switched to eSIM in 2025 and I am full of regret," details the author's frustrating experience with eSIM technology, arguing that it has made switching phones more difficult than the old physical SIM method. The author recounts a multi-day ordeal trying to transfer an eSIM to a new device, which involved failed activations, unhelpful customer support, and ultimately required a visit to a physical store. The piece contrasts the simple "plug and play" nature of physical SIMs with the complex, often broken, digital transfer processes. It also highlights other pain points, such as the difficulty of moving an eSIM to a non-smartphone device (like a hotspot) and the lack of support for eSIMs on many international carriers. The author concludes that eSIMs, while technologically neat, primarily benefit carriers by reducing costs and increasing control, at the expense of user freedom and convenience in less common scenarios.
>
> **Discussion:** The Hacker News discussion reveals a deeply divided user experience with eSIMs, where outcomes seem highly dependent on the user's specific situation and carrier. A central theme is the conflict between user freedom and corporate control. Many commenters argue that eSIMs are designed to lock users into carrier ecosystems, making it harder to switch devices or providers without carrier approval, which they see as a move to secure business models rather than improve user experience.

However, this negative view is strongly contested by numerous anecdotes of seamless eSIM use. The most common positive experiences involve:
*   **Upgrading between new iPhones:** Many users reported that the device-to-device transfer process is automated, quick, and painless, often requiring no user intervention.
*   **Travel:** eSIMs are widely praised for their convenience when abroad, allowing users to instantly purchase and activate a local data plan via an app without needing to find a physical store.

The discussion also highlights key pain points where eSIMs often fail, such as when a phone is broken or lost (making transfer difficult), when switching between different operating systems, or when dealing with carriers who have poor digital support. A few commenters pointed out that the underlying technology is sound and open, but its implementation is often restricted by carriers. Ultimately, the consensus is that eSIM is a "mixed bag": a significant improvement for common, well-supported workflows like upgrades and travel, but a source of major frustration for edge cases and users whose carriers provide poor support.

---

## [LLMs Are Not Fun](https://orib.dev/nofun.html)
**Score:** 195 | **Comments:** 168 | **ID:** 46424136

> **Article:** The article "LLMs Are Not Fun" argues that using Large Language Models for programming is joyless and strips the craft of its meaning. The author defines the "fun" of programming as the deep, satisfying process of understanding a problem, tracing its ripples through a system, and solving it with personal mastery. He contends that LLMs replace this engaging process with a tedious loop of "prompt, review, and correct," turning the developer into a passive manager of an unpredictable intern. This shift, he claims, devalues the craft and removes the very activities that give programming its intellectual reward, concluding that this is not a fun way to work.
>
> **Discussion:** The discussion reveals a deep divide over the role and enjoyment of LLMs in programming, centered on a fundamental conflict about what makes coding fulfilling.

A significant portion of commenters strongly disagree with the article, arguing that LLMs are, in fact, "intellectual crack" and immensely fun. They contend that by automating tedious tasks like boilerplate, typing, and debugging minor errors, LLMs free them to focus on the more enjoyable and creative aspects of development: high-level design, architecture, and rapid problem-solving. For these users, the ability to bring "crazy ideas" to life in days rather than weeks is a massive boost to creativity and enjoyment.

The debate is framed by a key insight that the core conflict is between those who value the *process* of creation and those who value the *end result*. Proponents of LLMs often fall into the latter camp, seeing the craft not in the manual act of coding but in achieving a desired outcome efficiently. They argue that LLMs are simply a more powerful tool, much like a typewriter replaced a pen, and that careful review and guidance are still essential parts of their craft.

However, a powerful counter-argument focuses on the loss of meaning. These users fear that AI is taking away activities that humans find intrinsically rewarding and meaningful, especially when those activities are also their profession and source of livelihood. They worry about a future where the deep, satisfying work of understanding and building is outsourced to a machine.

Finally, a notable meta-discussion emerged about the social pressure to embrace AI. Several commenters praised the author's "brave" article, noting that there is an enormous pressure on developers to publicly endorse and enjoy these tools. They compare it to the crypto/NFT hype, suggesting that expressing skepticism about LLMs is often met with accusations of being outdated, leading to a culture where people feel guilty for not enjoying the new paradigm.

---

## [Huge Binaries](https://fzakaria.com/2025/12/28/huge-binaries)
**Score:** 191 | **Comments:** 96 | **ID:** 46417791

> **Article:** The article "Huge Binaries" by Farid Zakaria discusses the technical challenge of building executables that exceed 2GB in size, a common scenario in large-scale C++ projects at companies like Google. This size threshold is significant because it breaches the limit of the "small" code model on x86-64 architecture, which uses 32-bit relative addresses for calls and jumps. When a binary's code section (`.text`) grows beyond this, the linker can no longer generate efficient relative calls to distant functions.

The author explores the causes, primarily the practice of static linking for performance and deployment simplicity, and the massive contribution of debug symbols. He details the common but costly solution: switching to the "large" code model (`-mcmodel=large`), which uses 64-bit absolute addresses, thereby increasing register pressure and potentially degrading performance. The article serves as a technical deep-dive into a problem that arises at extreme scale.
>
> **Discussion:** The Hacker News discussion centered on whether 25GB binaries are an unavoidable consequence of scale or a sign of architectural missteps. A key theme was the justification for such sizes. Some argued it's a deliberate trade-off made by companies like Google, where a tiny performance gain (e.g., faster startup from static linking) can translate to massive savings at their scale. However, many others viewed it as a "code smell," suggesting that an executable of that size indicates a failure to properly modularize applications or that the single "artifact" should be a package or container rather than a single monolithic binary.

The role of debug symbols was clarified by multiple commenters, who noted they are the primary contributor to the reported 25GB size, a plausible figure for large C++ projects. The conversation also touched on the practical consequences, with an ex-Googler lamenting that this bloat made everyday development and deployment slow, despite the company's powerful infrastructure. Technical solutions and related tools were also discussed, including Link-Time Optimization (LTO) to eliminate dead code, Facebook's BOLT optimizer for improving code locality, and the use of trampolines as an alternative to the large code model.

---

## [Linux DAW: Help Linux musicians to quickly and easily find the tools they need](https://linuxdaw.org/)
**Score:** 191 | **Comments:** 95 | **ID:** 46419968

> **Article:** The article introduces "Linux DAW" (linuxdaw.org), a new web-based directory designed to help Linux musicians discover audio production tools. The site functions as a curated catalog of Digital Audio Workstations (DAWs), plugins, and other music software, with a key feature being its powerful filtering system. Users can filter tools by category (e.g., synth, compressor, reverb), license type (FOSS, commercial), and price, making it easier to find specific software for their needs.
>
> **Discussion:** The HN community's response was largely positive, with users praising the site for solving the problem of discoverability in the fragmented Linux audio ecosystem. Many commenters noted that finding and comparing tools has historically been difficult, making this a valuable resource.

However, the discussion quickly branched into several technical and philosophical debates:

*   **Platform and Hardware Support:** A primary practical concern was support for ARM architecture, specifically for Raspberry Pi. Users noted that the list of available tools would be limited unless developers provided ARM builds, with one suggesting the KXStudio distribution as a more comprehensive solution for the Pi.

*   **User Interface (UI) Skeuomorphism:** A significant debate emerged about the usability of skeuomorphic UIs (interfaces that mimic physical hardware, like turning knobs with a mouse). One commenter argued this was the "worst interface," while others defended it for its compactness, its similarity to physical MIDI controllers, and the lack of a clear alternative for managing numerous parameters.

*   **Linux Audio vs. Telephony:** A user drew a parallel between the low-latency audio streaming needs of musicians and telephony. This was strongly refuted by another commenter who argued that professional audio is vastly more demanding in terms of latency, channel count, and uncompressed data fidelity, making the two fields fundamentally different.

*   **FOSS UI/UX Quality:** A recurring theme was the perceived gap in UI quality between commercial and Free and Open Source Software (FOSS). While some FOSS projects were praised for their modern design (Surge, Vital), many users observed that FOSS plugins often lack polished aesthetics, attributing this to a shortage of design contributors in the open-source community.

---

## [All Delisted Steam Games](https://delistedgames.com/all-delisted-steam-games/)
**Score:** 187 | **Comments:** 77 | **ID:** 46424262

> **Article:** The article links to "All Delisted Steam Games," a comprehensive list of video games that have been removed from the Steam store and can no longer be purchased. The list serves as an archive for games that have been "delisted," often due to expired licenses, publisher/developer closures, or the release of remastered versions. While these games are no longer for sale, they remain accessible to users who already own them in their Steam libraries.
>
> **Discussion:** The Hacker News discussion centers on the primary reasons for game delisting and the implications for digital game ownership. The most frequently cited cause is the expiration of licensing agreements, particularly for games featuring real-world brands like cars in racing titles (Blur, DiRT) or franchises like Warhammer. Users express frustration that this business reality makes games with licensed content inherently ephemeral, even if they are fully playable offline.

A major theme is the resilience of existing digital libraries. Several commenters confirm that delisted games can still be downloaded and played if they were previously purchased, offering a degree of security for consumers. This is contrasted with the fear of future inaccessibility, especially for live-service games or those tied to a specific storefront. The Rocket League example highlights anxiety over a game's future on Linux and the potential for a publisher to retroactively alter a purchased product (e.g., by adding anti-cheat that breaks compatibility).

Other reasons for delisting mentioned include the shutdown of servers for multiplayer games, the release of superior remastered editions (Death Stranding Director's Cut), and developer/publisher disputes. The conversation also touches on the ethics of piracy as a means to preserve delisted games and the general difficulty of tracking which titles have been removed from the store.

---

## [Show HN: My not-for-profit search engine with no ads, no AI, & all DDG bangs](https://nilch.org)
**Score:** 181 | **Comments:** 69 | **ID:** 46417748

> **Project:** The project, "nilch," is a not-for-profit search engine frontend presented on Hacker News. Its core value proposition is simplicity and privacy, offering a clean interface with no ads, no AI, and no tracking. A key feature is its full support for all DuckDuckGo (DDG) bangs, allowing users to quickly redirect searches to other sites (e.g., `!w` for Wikipedia, `!gh` for GitHub). The creator describes it as a minimalist alternative to other privacy-focused search frontends, prioritizing a streamlined user experience over a large feature set.
>
> **Discussion:** Discussion unavailable.

---

## [UK accounting body to halt remote exams amid AI cheating](https://www.theguardian.com/business/2025/dec/29/uk-accounting-remote-exams-ai-cheating-acca)
**Score:** 169 | **Comments:** 184 | **ID:** 46420289

> **Article:** The Guardian article reports that the Association of Chartered Certified Accountants (ACCA), a major UK accounting body, will stop offering remote exams due to the rising threat of AI-powered cheating. The move reverses a shift made during the COVID-19 pandemic, which allowed students to take exams from home. The ACCA stated that while remote invigilation technology has been effective, the rapid advancement of AI tools now makes it too difficult to guarantee the integrity of remote assessments. The organization will now require candidates to sit exams in person at test centers, with exceptions only for "exceptional circumstances."
>
> **Discussion:** The Hacker News discussion is highly cynical about the motivations of professional bodies like the ACCA. The dominant sentiment is that these organizations are primarily concerned with protecting their role as "gatekeepers" and maintaining their revenue streams, rather than a genuine focus on education. Many commenters argue that the ACCA's decision is a reaction to losing control over the certification process, and that their high exam fees are unjustified, especially after profiting from the lower overhead of remote testing during the pandemic.

There is a broad consensus that AI, particularly LLMs, has fundamentally changed the nature of cheating, making it trivial and difficult to detect. Commenters share anecdotes about students who excel in AI-assisted coursework but fail in-person exams, highlighting a significant gap between perceived and actual competency. While some argue that this necessitates a return to in-person, proctored exams, others point out that even these are not foolproof, with sophisticated cheating methods (both low-tech and high-tech) having existed long before AI.

The debate extends to the value of formal education and certifications in an AI-driven world. One perspective is that certificates are becoming increasingly irrelevant, as AI tools will be used on the job anyway. A counter-argument is that the true value of education lies in developing abstract thinking and problem-solving skills, and that outsourcing this process to AI will leave individuals at a disadvantage and easily replaceable. Ultimately, many commenters feel that the entire system of remote assessment has been compromised, and a return to traditional, in-person testing is the only viable path forward to ensure fairness and maintain the credibility of qualifications.

---

## [Feynman's Hughes Lectures: 950 pages of notes](https://thehugheslectures.info/the-lectures/)
**Score:** 168 | **Comments:** 37 | **ID:** 46419273

> **Article:** The article links to a website hosting a digitized version of Richard Feynman's notes from his 1983-84 Hughes Aircraft Company lectures. These notes, totaling 950 pages, are not the famous Caltech "Feynman Lectures on Physics," but a separate, comprehensive set of handwritten notes covering a different curriculum. The site presents these notes as a tribute to Feynman's dedication and work ethic.
>
> **Discussion:** The discussion is largely a celebration of the find, with many users expressing awe at the sheer volume and artistry of the notes. Commenters admire the "Renaissance art" quality of the handwritten pages and the productivity of great scientists like Feynman. Some speculate that this level of dedication was possible due to a less competitive academic environment ("less publish or perish") compared to today.

A notable side debate emerges when one user questions the "cult of personality" surrounding Feynman, suggesting that other excellent physics textbooks (like Purcell's *Electricity and Magnetism*) are less celebrated despite their quality. Others counter that Feynman's fame is a natural result of his charisma and public-facing work, which reached a broader audience than academic textbooks. The thread concludes with a clarification that these are distinct from the more famous Caltech lectures, providing a helpful link to the original set.

---

