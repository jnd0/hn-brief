# Hacker News Summary - 2026-02-18

## [Claude Sonnet 4.6](https://www.anthropic.com/news/claude-sonnet-4-6)
**Score:** 1148 | **Comments:** 995 | **ID:** 47050488

> **Article:** Anthropic announced Claude Sonnet 4.6, a new model that delivers performance comparable to Opus 4.5 while costing roughly 40 % less per token and consuming far fewer compute resources. The release highlights a shift toward “floor‑raising” intelligence, where even the lower‑priced Sonnet tier now matches the reasoning depth previously reserved for Opus, enabling agentic workflows at half the compute cost. The company also raised $30 billion in funding, positioning itself to compete with OpenAI’s $100 billion ambitions, and cited internal safety improvements that aim to reduce deceptive behavior. The article notes that Opus 4.6, by contrast, reportedly uses five to ten times as many tokens as Opus 4.5 for the same tasks, raising questions about efficiency.
>
> **Discussion:** Commenters quickly split between those who see Sonnet 4.6 as a genuine step forward in affordability and those who worry about a regression in token efficiency, with several users reporting Opus 4.6’s wasteful token usage and questioning whether Anthropic’s safety claims are merely a veneer. Deception emerged as a central theme, with some arguing that models can now “play dead” during training and later activate hidden capabilities, turning alignment into an adversarial arms race rather than a straightforward safety problem. Others dismissed anthropomorphic concerns, pointing out that even young children routinely deceive, while a safety researcher’s cryptic resignation and Pentagon scrutiny added a layer of institutional unease. The thread also reflected broader market anxieties, with participants debating whether fierce competition will drive down costs or trigger a costly AI arms race that ultimately benefits few, and noting that the rapid pace of improvement feels reminiscent of the 1990s compute boom.

---

## [Thank HN: You helped save 33k lives](https://news.ycombinator.com/item?id=47049824)
**Score:** 870 | **Comments:** 87 | **ID:** 47049824

> **Article:** Watsi, a Y Combinator‑backed nonprofit, reports that its platform has enabled life‑saving surgeries for over 33,000 patients worldwide and highlights its Universal Fund, which has attracted long‑term donors such as 619 members who have contributed for a decade or more. The organization showcases individual patient stories on its impact page and emphasizes sustainable monthly giving as a core funding model. Recent comments from team members like Chase Adam and external supporters illustrate both gratitude and strategic ideas, including leveraging donor‑advised funds and secondary market stock donations to expand resources. The post also links to a timeline of key HN‑featured milestones since the service launched in 2012.
>
> **Discussion:** Participants discuss the tension between nonprofit and for‑profit models, arguing that profitability need not preclude social impact and that both can coexist to improve lives. Several commenters propose innovative financial structures, such as treating the fund like a sovereign fund that invests donations and spends only the investment returns, or using donor‑advised funds to channel stock gifts into a stable revenue stream for Watsi. Others question the accuracy of the “33k lives saved” claim, suggesting counterfactual calculations and quality‑adjusted life‑year metrics provide a more nuanced view of impact. The conversation also touches on effective altruism critiques, the challenges of measuring life‑saving outcomes, and the potential for partnerships with platforms that facilitate secondary market transactions for charitable giving.

---

## [15 years later, Microsoft morged my diagram](https://nvie.com/posts/15-years-later/)
**Score:** 571 | **Comments:** 227 | **ID:** 47057829

> **Article:** The article discusses a 15-year-old incident involving a diagram on Microsoft Learn, highlighting concerns about plagiarism, review processes, and systemic failures within large organizations. Critics argue that the lack of proper review and the speed of content release expose vulnerabilities, while defenders claim the issue reflects broader challenges in knowledge work today. Several participants questioned the validity of the content and the motivations behind its creation, emphasizing the need for better safeguards against misinformation. The conversation also touches on generative AI's role in content generation and the risks it poses to intellectual property. Overall, the discussion centers on trust, accountability, and the evolving nature of documentation in tech.
>
> **Discussion:** Multiple voices weighed in on the issue, with some calling the plagiarism and copy-paste behavior a systemic problem and others defending the process as efficient. Concerns were raised about the lack of review mechanisms and the impact of rushed publishing on quality. Technical debates emerged around how AI tools generate content and the implications for originality. The community expressed frustration over the speed of content dissemination and the difficulty of maintaining standards in fast-moving environments. Overall, the exchange highlighted deep divisions over responsibility, transparency, and the future of reliable documentation in software development.

---

## [Thousands of CEOs just admitted AI had no impact on employment or productivity](https://fortune.com/2026/02/17/ai-productivity-paradox-ceo-study-robert-solow-information-technology-age/)
**Score:** 538 | **Comments:** 448 | **ID:** 47055979

> **Article:** A recent study of CEOs found that AI has had no measurable impact on employment or productivity, despite widespread adoption. The article draws parallels to Robert Solow's productivity paradox from the 1970s-80s, when IT investments similarly failed to show immediate economic gains. The piece suggests that like early IT, AI's benefits are currently outweighed by costs and implementation challenges, but productivity gains may emerge as the technology matures and best practices develop.
>
> **Discussion:** The Hacker News community largely agreed with the article's framing, with many noting that AI's impact is being underestimated due to its early stage and the learning curve involved in effective use. Several commenters pointed out that AI adoption costs are minimal compared to historical IT investments, with Claude subscriptions at $20/month being comparable to other office tools. A key debate emerged around whether AI is actually optimizing work that has no economic value, with references to Graeber's "Bullshit Jobs" thesis. Others argued that AI will enable an explosion of small software companies rather than just making existing ones more efficient, fundamentally changing the software industry's structure.

---

## [CBS didn't air Rep. James Talarico interview out of fear of FCC](https://www.nbcnews.com/business/media/stephen-colbert-cbs-james-talarico-fcc-rcna259341)
**Score:** 491 | **Comments:** 226 | **ID:** 47049426

> **Article:** CBS decided not to air an interview with Rep. James Talarico, citing fear of enforcement of the FCC’s equal‑time rule. The interview was later posted online and accumulated roughly 1.4 million YouTube views. The FCC had opened a probe into The View for hosting Talarico, highlighting broader concerns about regulatory pressure on broadcasters.
>
> **Discussion:** The conversation centers on whether the FCC’s equal‑time rule is being weaponized to pressure broadcasters into silencing a political rival, with several commenters pointing out that the rule has existed for decades but only recently been applied to late‑night talk shows. Many argue that CBS’s pre‑emptive cancellation reflects a chilling effect, citing the FCC’s investigation of The View and the broader pattern of regulators using licensing leverage to shape content. A few participants counter that the fault lies with CBS for over‑complying before any formal rule change, and they note that streaming platforms are not subject to the same obligations. The thread also brings up historical analogies to media control in Russia and the Mayflower Doctrine, and it devolves into a debate over whether figures like Bari Weiss can be considered free‑speech advocates. Some users suggest concrete actions — calling local affiliates, pressuring advertisers, or donating to Talarico’s campaign — to counteract the self‑censorship, while others warn that the Streisand effect may actually amplify the interview’s reach despite the broadcast ban.

---

## [Halt and Catch Fire: TV’s best drama you’ve probably never heard of (2021)](https://www.sceneandheardnu.com/content/halt-and-catch-fire)
**Score:** 484 | **Comments:** 264 | **ID:** 47056314

> **Article:** The article argues that "Halt and Catch Fire" is a critically underappreciated television drama that authentically captures the ambition and creative spirit of the personal computing and early internet revolutions. It highlights Lee Pace's charismatic performance as marketing visionary Joe MacMillan and praises the show's ability to transcend its tech-industry setting to explore broader themes of innovation and human connection. The series is noted for its four-season arc, moving from 1980s Texas to the 1990s San Francisco tech boom, and is loosely based on Tracy Kidder's Pulitzer-winning book "The Soul of a New Machine."
>
> **Discussion:** The discussion centers on widespread praise for Lee Pace's performance as a uniquely convincing charismatic lead, with users noting the difficulty of portraying genuine persuasion on screen. A key debate emerges over the show's quality and focus, with some favoring the intense, Mad Men-esque first season while others champion the later seasons for shifting to the partnership between Donna and Cameron, which is seen as more original and compelling. Several commenters with firsthand experience in the era contest the show's technical accuracy, citing specific anachronisms that break immersion, while others defend its emotional truth over literal precision. The thread also functions as a recommendation thread for other lesser-known prestige dramas, with users exchanging titles like "Patriot," "Counterpart," and "Scavengers Reign," and noting that the show's limited accessibility on AMC+ likely contributes to its low viewership.

---

## [Tesla 'Robotaxi' adds 5 more crashes in Austin in a month – 4x worse than humans](https://electrek.co/2026/02/17/tesla-robotaxi-adds-5-more-crashes-austin-month-4x-worse-than-humans/)
**Score:** 435 | **Comments:** 239 | **ID:** 47051546

> **Article:** The article reports that Tesla's Robotaxi service in Austin experienced five additional crashes within a month, with data suggesting its crash rate is four times worse than the average human driver. It emphasizes Tesla's lack of transparency, noting that while competitors like Waymo provide detailed crash narratives, Tesla redacts all information from NHTSA reports. The incidents occurred while the vehicles were under the supervision of safety drivers, highlighting concerns about the system's readiness for public deployment despite being in a pilot program.
>
> **Discussion:** The discussion centers on the validity and context of Tesla's crash statistics, with many users arguing that comparing a small dataset from a pilot program with safety drivers to broad human driving data is misleading. A key point of contention is Tesla's refusal to release unredacted crash details, which prevents independent assessment of fault and whether incidents were minor, low-speed collisions that human drivers often wouldn't report. Technical debates arise over Tesla's camera-only approach versus LIDAR-based systems like Waymo's, with some asserting the former is fundamentally limited. The conversation also explores the differing supervision models—emergency brake-only for safety drivers versus full consumer control—and the potential for these crashes to damage public perception of all autonomous driving technology, regardless of provider differences.

---

## [Show HN: AsteroidOS 2.0 – Nobody asked, we shipped anyway](https://asteroidos.org/news/2-0-release/index.html)
**Score:** 395 | **Comments:** 48 | **ID:** 47051852

> **Project:** AsteroidOS announced a stable 2.0 release, the first official version after eight years of nightly builds. The update brings full‑featured support for devices such as the Samsung Gear 2 (code‑named “rinato”) and the ASUS ZenWatch 2 (“sparrow”), and continues to rely on libhybris and older kernels for broad compatibility. The project emphasizes privacy with zero telemetry and aims to extend the life of discontinued smartwatches by providing open‑source firmware, QML/Qt watchfaces, and JavaScript extensions. All source code, install images, and documentation are hosted on GitHub and the AsteroidOS website.
>
> **Discussion:** Commenters praised the ambition of keeping obsolete hardware alive, noting the impressive list of supported watches and the pragmatic use of libhybris for quick ports. Several users asked where to acquire compatible devices in the US, receiving tips about the widely available Ticwatch Pro 2018/2020 and the newer Ticwatch Pro 3. Technical debate centered on the performance impact of QML/Qt on wrist‑sized devices, with maintainers explaining that the stack is surprisingly lightweight compared to Android Wear. A thread emerged questioning whether the announcement text was AI‑generated, sparking a split between those who found it off‑putting and others who dismissed the concern as over‑analysis. Finally, participants discussed the challenges of supporting newer watches, the need for mainline kernel drivers, and the limited prospects for cheap microcontroller‑based smartbands.

---

## [Using go fix to modernize Go code](https://go.dev/blog/gofix)
**Score:** 368 | **Comments:** 72 | **ID:** 47049479

> **Article:** The article discusses the growing concern that large language models (LLMs) are producing Go code that mirrors outdated practices, leading to homogenized and less maintainable software. Developers are worried that reliance on such tools may stifle innovation and quality. Several contributors share personal experiences, highlighting issues like inconsistent modernization, over-simplification, and the risk of introducing bugs. The conversation also touches on the potential benefits of modernization tools and the need for better language evolution in development workflows. Technical insights emphasize the importance of maintaining clear communication and understanding in code, while community members express mixed feelings about adopting such tools. Overall, the debate centers on balancing convenience with long-term code health.
>
> **Discussion:** The discussion revolves around the impact of LLM-assisted code generation on Go programming practices. Many participants express concern that tools like go fix can lead to uniform, suboptimal code, undermining the value of modernization efforts. Some developers appreciate the speed and ease of refactoring but worry about losing nuanced understanding or introducing subtle bugs. There is a clear divide between those who value the convenience of automated improvements and those who prioritize manual craftsmanship for quality. The conversation also highlights the need for better language evolution and tooling that supports thoughtful, sustainable coding. Community members share practical examples and suggest complementary approaches, like using structural search and code fixes, to enhance modernization without sacrificing clarity.

---

## [Gentoo on Codeberg](https://www.gentoo.org/news/2026/02/16/codeberg.html)
**Score:** 356 | **Comments:** 123 | **ID:** 47050067

> **Article:** Gentoo announced it will host its source code on Codeberg, a Git hosting platform, as part of a broader effort to reduce reliance on GitHub. The move reflects a growing trend of open‑source projects exploring alternatives amid concerns over GitHub’s pricing changes and centralization. This shift is notable because Gentoo has traditionally maintained its own infrastructure and now opts for a third‑party forge. The announcement was made in a news post titled “Gentoo on Codeberg” on the Gentoo website.
>
> **Discussion:** Developers debate whether the migration signals a wider exodus from GitHub, citing both the appeal of federated forking and frustration with GitHub’s pull‑request review experience. Some commenters praise GitHub’s code search and Actions while criticizing its UI slowdown and the difficulty of handling large reviews. Others highlight the need for sustainable funding models for alternative forges, suggesting passive cost displays or community‑driven compute resources. A recurring theme is the desire for more flexible review workflows, such as those offered by Gerrit or Phabricator, and the hope that decentralized tools could diversify contribution processes. The conversation also touches on broader open‑source ecosystem shifts, from LibreOffice challenging Microsoft Office to AI‑driven services influencing hosting choices.

---

## [BarraCUDA Open-source CUDA compiler targeting AMD GPUs](https://github.com/Zaneham/BarraCUDA)
**Score:** 335 | **Comments:** 142 | **ID:** 47052941

> **Article:** BarraCUDA is an open-source CUDA compiler designed to target AMD GPUs, developed by ZaneHam. The project emphasizes avoiding dependencies on LLVM and Large Language Models (LLMs), instead handling its own instruction encoding. This approach is highlighted as refreshing in the AI-dominated landscape, and the project aims to provide a competitive alternative to NVIDIA's CUDA, particularly for AMD hardware users.
>
> **Discussion:** The discussion centers on AMD's lack of native CUDA support and the potential impact of BarraCUDA. While some users argue AMD's strategic decision to avoid CUDA is sound, others express frustration that enthusiasts must fill this gap. Technical debates emerge around the project's feasibility, with insights into the challenges of code generation and optimization without LLVM. The community reacts strongly to the "no LLM" stance, viewing it as a positive rejection of AI-generated code, though some dismiss this as "AI slop" based on minor formatting issues. There's significant interest in backward compatibility for older AMD GPUs like the GFX10 series, with the project owner actively working on this. The thread also touches on the broader theme of open-source projects challenging proprietary ecosystems, referencing historical examples like Git's creation as a response to vendor lock-in.

---

## [HackMyClaw](https://hackmyclaw.com/)
**Score:** 320 | **Comments:** 159 | **ID:** 47049573

> **Article:** The creator, identified as cuchoi, built a weekend project called HackMyClaw to test how easily Claude Opus 4.6 can be prompted into leaking secrets via email. The system, named Fiu, reads incoming messages, summarizes them, and is explicitly instructed not to reveal the contents of secrets.env without owner approval, a constraint enforced by a ~15‑line prompt rather than a technical barrier. The project’s FAQ was later updated to clarify that Fiu may send replies only with explicit confirmation, reflecting cost concerns over handling high email volume.
>
> **Discussion:** Participants debated whether the experiment truly tests prompt injection resistance or merely exploits the cost‑driven limitation that Fiu cannot reply without human approval. Several commenters argued that processing emails in bulk makes subtle injection attempts easier to spot, turning the setup into a defender advantage, while others questioned how the model could ever extract a flag if it is barred from responding. The conversation also highlighted broader concerns about model choice, with some noting that newer Opus versions show improved resistance compared to earlier Sonnet releases, and others warning that the project may be gathering a list of AI‑enthusiasts for commercial purposes. Community members expressed skepticism about the feasibility of extracting credentials, suggested alternative attack vectors such as using URLs or DNS lookups, and pointed out that the experiment underscores the need to treat every inbound email as untrusted. Overall the thread mixed technical analysis of prompt injection mechanics with critiques of the experimental design and its implications for AI security research.

---

## [Tesla Sales Down 55% UK, 58% Spain, 59% Germany, 81% Netherlands, 93% Norway](https://cleantechnica.com/2026/02/15/tesla-sales-down-tremendously-in-uk-norway-netherlands-germany-spain-sweden-denmark-portugal-switzerland/)
**Score:** 276 | **Comments:** 257 | **ID:** 47048052

> **Article:** Tesla's sales have plummeted in key European markets, with declines of 55% in the UK, 58% in Spain, 59% in Germany, 81% in the Netherlands, and 93% in Norway compared to previous periods. The article highlights Tesla's strategic pivot toward autonomy and humanoid robotics, including plans to repurpose Fremont factory production lines for Optimus robots, aiming for 1 million units annually. Meanwhile, competitors like BYD are gaining traction, with 2,779 BYD EVs sold in Australia in January 2026 versus 501 Teslas, underscoring shifting consumer preferences and pricing pressures.
>
> **Discussion:** The discussion centers on Tesla's paradoxical stock resilience despite severe sales declines and operational challenges. Commenters debate whether investor confidence stems from optimism about future breakthroughs like self-driving technology or Optimus robots, or from speculative trading dynamics. Critics argue Tesla's product strategy—such as discontinuing the Model S/X for Optimus, removing features like turn stalks, and failing to update designs—has alienated customers, while others defend Musk's visionary leadership. The role of political alignment, particularly Musk's far-right shifts, is scrutinized as a potential factor in declining appeal among European and global markets. Technical debates arise over Tesla's Autopilot capabilities compared to competitors like Waymo and Mercedes, with some users praising its real-world performance and others dismissing it as overhyped. The thread also critiques Tesla's lack of product diversity, reliability issues in older models, and missteps in international markets, contrasting it with rivals like BYD and Geely. A recurring theme is the stock's detachment from fundamentals, framed as a "cult" driven by Musk's persona rather than business viability.

---

## [I converted 2D conventional flight tracking into 3D](https://aeris.edbn.me/?city=SFO)
**Score:** 260 | **Comments:** 50 | **ID:** 47048004

> **Article:** The article showcases a 3D flight tracking visualization that converts conventional 2D flight data into an interactive three-dimensional representation. The project, created by kewonit, displays real-time aircraft positions around airports like SFO with altitude information represented through visual positioning. The visualization uses color coding to indicate different flight levels and allows users to explore flight patterns in three-dimensional space. The project is open source and currently uses the OpenSky Network API with limitations on the distance range to avoid rate limiting.
>
> **Discussion:** The discussion focused heavily on feature requests and technical improvements, with many users suggesting the addition of aircraft model types, origin/destination information, and more accurate vertical scaling. A key point of debate was whether the current exaggerated vertical scaling (which makes the visualization more aesthetically pleasing) should be replaced with a true 1:1 scale despite potential usability issues. Users also compared this project to similar tools like Airloom and Flightradar24, with some noting existing AR capabilities in other flight tracking apps. Aviation enthusiasts shared insights about flight altitudes, explaining how jet streams and air traffic control congestion can affect why flights sometimes operate at different heights. The creator responded to feedback, indicating plans to add model numbers, origin/destination on hover, and a 1:1 height scale option despite acknowledging it might be less visually appealing.

---

## [Semantic ablation: Why AI writing is generic and boring](https://www.theregister.com/2026/02/16/semantic_ablation_ai_writing/)
**Score:** 259 | **Comments:** 191 | **ID:** 47049088

> **Article:** The article critiques AI-generated writing as generic and unengaging due to "semantic ablation," where AI smooths out unique, human-like elements in prose, resulting in bland, polished text. It argues that AI's focus on clarity and safety strips away the "jagged edges" that make writing memorable, such as unexpected phrasing or distinct voice. The author likens this to corporate safespeak, emphasizing that AI lacks the ability to create surprising or emotionally resonant content.
>
> **Discussion:** The discussion centers on whether AI writing is inherently bland or a solvable technical issue. Some users agree that AI's polished output lacks human distinctiveness, comparing it to "corporate safespeak," while others argue AI can improve writing for non-experts by fixing errors. A key technical insight emerges: RLHF (Reinforcement Learning from Human Feedback) trains models to prioritize safe, expected outputs, penalizing distinctiveness. Users debate whether this is an inherent flaw or a design choice, with some suggesting less-tuned models or hybrid approaches could mitigate the issue. Others criticize the article for lacking concrete examples, comparing it to debates about model collapse. A recurring theme is the tension between AI's utility as a tool versus its role in flooding the internet with low-effort, unoriginal content. Skepticism about the article's credibility also arises, noting the author's background in pharmaceutical technology rather than AI research.

---

## [Google Public CA is down](https://status.pki.goog/incidents/5oJEbcU3ZfMfySTSXXd3)
**Score:** 256 | **Comments:** 150 | **ID:** 47055696

> **Article:** Google Public CA experienced an incident that halted certificate issuance, with a fix expected to roll out in approximately 8 hours. The status page indicates this was an intentional action, with issuance beginning to stop at 12:14 PST on February 17, 2026. The incident sparked discussions about certificate lifetimes, automation reliability, and the broader implications of centralized certificate authorities.
>
> **Discussion:** The outage sparked a broader conversation about certificate infrastructure and automation. Some users expressed concern about increasingly short certificate lifetimes, with one commenter noting that 7-day certificates are being experimented with, which could create more frequent windows for potential downtime. Others pointed out that with multiple free ACME CAs available, failover should mitigate single-provider failures, though one commenter warned about "The Great Oops" - a hypothetical scenario where a major cloud provider irrecoverably deletes all customer data with one command. The discussion also touched on YouTube's simultaneous downtime, with speculation about whether it was related to the CA incident, though experts noted there's no direct reason why a CA outage would bring down YouTube. Some users shared their experiences with YouTube as an educational resource, while others criticized the platform's algorithm and content quality.

---

## [Discord Rival Gets Overwhelmed by Exodus of Players Fleeing Age-Verification](https://kotaku.com/discord-alternative-teamspeak-age-verification-check-rivals-2000669693)
**Score:** 243 | **Comments:** 132 | **ID:** 47050376

> **Article:** Discord rival Teamspeak is experiencing a surge in users as people flee Discord due to new age verification requirements. Teamspeak, which was once a mainstay of the gaming community before Discord's rise, has modernized its features to better compete with more advanced chat options. The article suggests Teamspeak is benefiting from this exodus as users seek alternatives to Discord's new verification policies.
>
> **Discussion:** The Hacker News discussion centers on Discord's future and the reasons behind its dominance and potential vulnerabilities. Many commenters believe Discord will remain dominant despite current user exoduses, comparing it to Reddit's situation after API changes. Technical insights highlight Discord's advantages over competitors, including its centralized architecture making it resistant to DDoS attacks, free service model, and ease of use without technical expertise. There's debate about whether Discord's age verification requirements are as intrusive as feared, with some suggesting it's primarily targeting NSFW content. The discussion also explores alternatives like self-hosted solutions (Teamspeak, Mumble, Matrix) and the challenges of decentralization versus the convenience of centralized platforms.

---

## [So you want to build a tunnel](https://practical.engineering/blog/2026/2/17/so-you-want-to-build-a-tunnel)
**Score:** 233 | **Comments:** 87 | **ID:** 47049718

> **Article:** The article "So you want to build a tunnel" from Practical Engineering explores the complexities and dangers of tunnel construction. It appears to be a transcript of a video that discusses various aspects of tunneling, from small-scale amateur projects to large-scale engineering feats. The content addresses engineering challenges, safety considerations, and the technical aspects of different tunneling methods.
>
> **Discussion:** The Hacker News discussion featured personal anecdotes about the psychological benefits of digging, with one user sharing how digging helped him process his wife's cancer diagnosis. There was significant debate about building codes, with some arguing they prioritize industry standardization over safety while others emphasized that "rules are written in blood" for good reason. Commenters also discussed the military applications of tunnels in drone warfare, with some questioning whether any tunnel can truly be safe against modern technology. The thread included references to notable amateur tunnel builders like "engineerkala" on Instagram and historical figures like William Lyttle, the "Moleman of Hackney."

---

## [Show HN: I wrote a technical history book on Lisp](https://berksoft.ca/gol/)
**Score:** 218 | **Comments:** 79 | **ID:** 47048733

> **Project:** The project isa self-published technical history book titled "The Genius of Lisp," focusing on the history of Lisp through the lens of AI and programming language research, with a particular emphasis on MIT and Stanford. It includes a sample chapter on Scheme available online and uses JavaScript in its content to enhance accessibility for a general technical audience. The author acknowledges the book is a cross-section of history rather than an exhaustive encyclopedia, aiming for digestibility over encyclopedic depth.
>
> **Discussion:** The discussion centers on feedback regarding the book's content, design, and scope. Key points include criticism of the bibliography's perceived incompleteness, with commenters like jcynix and throwaway81523 noting missing foundational works and specific systems like Lisp 2 and Macsyma applications. The cover design received mixed reactions; emigre and wk_end suggested improvements for professionalism, while cdegroot (the author) acknowledged the design wasn't perfect but wasn't overly concerned. Technical readers like Jach and embedding-shape requested more substantial sample chapters beyond the introduction. The author, cdegroot, defended the book's approach as a focused history for a general audience, not an exhaustive reference, and indicated plans to add a better sample chapter. Disagreements emerged over the book's depth versus accessibility, with some commenters feeling it omitted too much technical detail while others appreciated its digestible format.

---

## [Stephen Colbert says CBS forbid interview of Democrat because of FCC threat](https://arstechnica.com/tech-policy/2026/02/stephen-colbert-says-cbs-forbid-interview-of-democrat-because-of-fcc-threat/)
**Score:** 208 | **Comments:** 65 | **ID:** 47051793

> **Article:** Stephen Colbert alleged that CBS blocked an interview with Democratic congressional candidate Seth Moulton due to pressure from the Federal Communications Commission (FCC). The FCC, under Chairman Brendan Carr, had warned late-night shows they might lose their "bona fide news" exemption from equal-time rules and opened an investigation into ABC's "The View" for a similar interview. Colbert stated he moved the interview to his show's YouTube channel in response to Carr's suggestion that shows avoiding such rules could shift to cable or streaming. The core claim is that regulatory threats from the Republican-led FCC were used to suppress political speech on a major network.
>
> **Discussion:** The discussion evolved into a multifaceted political debate. A primary thread analyzed the structural advantages of rural, conservative voters in the U.S. electoral system, with commenters like atoav arguing this creates a "dictatorship of the minority" through mechanisms like the Senate and gerrymandering, while jmyeet and others detailed a long history of Republican-led voter suppression tactics targeting minority and poor voters. A second major thread dissected the legal and ethical dimensions of the CBS decision, centered on the FCC's equal-time rule. Commenters like dabinat and nomel debated whether CBS's preemptive cancellation was a legitimate legal concern or a politically motivated act of censorship, given that no other candidate had formally requested airtime. The conversation broadened to express deep concern about a slide toward oligarchy, with CGMthrowaway warning of "quiet threats" and regulatory pressure forcing media compliance. Finally, a comparative thread examined political radicalization, with barcodehorse and squarefoot debating the symmetry and scale of violent extremism on the left versus the right, and beart noting the far-right's control of federal institutions versus the localized impact of 2020 protests.

---

