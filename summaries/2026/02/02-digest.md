# HN Daily Digest - 2026-02-02

Notepad++ got hacked by state-sponsored actors, and the irony is almost too rich: a text editor—beloved for its simplicity, ubiquity, and sheer mundanity—became a vector for targeted espionage, thanks to a compromised update mechanism and a self-signed certificate that should’ve been retired a decade ago. The attack, likely originating from China, didn’t exploit zero-days or complex crypto; it just redirected specific users to malicious servers serving trojanized updates. This wasn’t a smash-and-grab—it was surgical, hands-on-keyboard stuff, aimed at a narrow subset of users, mostly in Asia. And while the project has since patched things with proper code signing, the breach is a brutal reminder that even the most unsexy open-source tools are high-value targets when they sit on millions of desktops. Worse, the discussion spiraled into a familiar flame war: some users were furious not about the breach, but about Notepad++’s political stances in update notifications—pro-Taiwan, pro-Ukraine—and argued that software should stay neutral. That’s a convenient take if you’re not the one being surveilled, but it exposes a deeper tension in open source: can developers take ethical stands when their tools become infrastructure? Or does that make them targets? Either way, the attackers got what they wanted—access—and the rest is theater.

The theme of trust, or the lack of it, echoes through today’s top stories. Netbird, an open-source Zero Trust networking tool, is being praised as a self-hosted Tailscale alternative, but the real story isn’t the tech—it’s the migration. People are fleeing VC-backed SaaS providers, not because they’re broken, but because they don’t trust their longevity or their incentives. The same skepticism shows up in the AI agent space, where projects like NanoClaw and Moltbot are getting torn apart for giving AI agents full system access by default. One user put it perfectly: “You’re handing a drunk robot the keys to everything.” The Moltbot RCE exploit—where one click could steal API keys and data—isn’t a fluke; it’s the inevitable outcome of building agents that run arbitrary code without sandboxing. And yet, people keep doing it, because the UX is smooth and the promise is seductive: automation without friction. But friction, as it turns out, is what keeps you alive. The backlash is real—developers are now building kernel-level sandboxes, microVMs, and credential brokers—but the damage is done. The agent gold rush is repeating the same mistakes as the early web: convenience over security, speed over rigor.

Meanwhile, Apple is having a rough week. Again. Not only did the latest macOS update break Time Machine backups over SMB—forcing users to manually tweak NAS settings for a “set and forget” tool—but one developer discovered that their iPhone couldn’t do basic math. Not a typo: a high-end device, running MLX, produced wildly incorrect results in ML inference tasks, while older devices worked fine. This isn’t floating-point noise; it’s a systemic failure, possibly in the NPU or driver stack, and it’s terrifying. How many silent, undetected computational errors are happening in production? And yet, Apple’s response is the same as always: silence, or a vague KB article. The company that once prided itself on engineering excellence now feels like a gatekeeper more than a builder. The App Store’s 30% cut, iCloud’s 78% margins, the killing of PWAs, the notarization delays—all point to a company extracting rent from developers while pushing them toward iCloud and its walled garden. The 1976 Apple I ad, with its $666.66 price tag and promise of free software, reads like satire next to today’s reality. Back then, they were rebels. Now, they’re the establishment.

On the flip side, there’s a quiet rebellion brewing in the tools people are building. Netbird, headscale, OpenZiti—these are not just networking tools; they’re declarations of digital sovereignty. Same with the DIY revenge hacks, like the Raspberry Pi that automatically lowers a neighbor’s TV volume via IR. It’s not really about noise; it’s about control. People are tired of being passive users, subject to the whims of platforms, neighbors, or poorly insulated apartments. They’re building their own solutions, even if they’re janky or ethically dubious. The Notepad++ hack, the Time Machine breakage, the iPhone math bug—all of these erode trust, and when trust breaks down, people go rogue. That’s also why retro tools are having a moment: Adventure Game Studio, Amiga Unix, even 40-year-old dongle-cracking projects. These aren’t just nostalgia trips; they’re reactions to the bloat and opacity of modern software. When everything feels like a SaaS subscription or an AI wrapper, going back to hand-written assembly or BASIC feels like resistance.

Which brings us to AI in education. Some English professors are now requiring printed readings to stop students from feeding PDFs into LLMs. It’s a dumb idea, easily defeated with a phone camera and OCR, but it’s not really about stopping cheating—it’s about adding friction. The same logic applies to coding agents: if you force approval for every file write, you slow things down, but you also stay in control. The tension is clear: do we adapt to AI, or do we fight it? One CS instructor is teaching students to use AI as a personalized tutor, not a shortcut—running in-person, pen-and-paper exams while encouraging AI-assisted learning. That’s the smart path. The alternative—print-only policies, locked-down labs, browser lockdown tools—is just performative. It’s the educational equivalent of Apple’s App Store review process: rigid, paternalistic, and ultimately useless against determined actors.

The broader pattern? People are tired of black boxes. Whether it’s an AI agent, a firewall, or a backup system, the expectation is shifting from “just works” to “works and I understand how.” That’s why “The Book of PF” is getting love—because PF’s config file is readable, predictable, and doesn’t phone home. It’s also why FOSDEM is still relevant, despite overcrowding and retrocomputing nostalgia: it’s one of the last places where open source feels like a community, not a product. But even there, the cracks are showing. The conference is grappling with its own identity—apolitical or activist? Retro or cutting-edge?—and the answer isn’t clear. What is clear is that the old model of “build it and they will come” is dead. Everything now has to justify its existence, ethically and technically.

And maybe that’s not a bad thing. The days of blindly trusting update mechanisms, AI outputs, or cloud providers are ending—not because of regulation, but because enough people have been burned. The Moltbot exploit, the Notepad++ breach, the iPhone math bug—they’re all data points in a larger trend: the erosion of faith in digital systems. The response isn’t more abstraction; it’s more control, more transparency, more DIY. You see it in the move to self-hosted agents, in the revival of PF over nftables, in the demand for audit logs and approval workflows. It’s not sexy, but it’s sustainable.

Even the biology papers fit the theme. Aging muscle stem cells shift from repair to survival—sound familiar? That’s what we’re doing as an industry: trading explosive growth for long-term resilience. The hypergrowth era is over. Now it’s about endurance.

Worth watching: the push for hardware-enforced sandboxing in AI agents. If Apple’s containerization in NanoClaw gets adopted more widely—or if someone builds a secure agent runtime on Firecracker—it could finally make AI automation safe enough for real use. Until then, assume every agent is pwned.

---

*This digest summarizes the top 20 stories from Hacker News.*