# Hacker News Summary - 2026-02-22

## [I verified my LinkedIn identity. Here's what I handed over](https://thelocalstack.eu/posts/linkedin-identity-verification-privacy/)
**Score:** 1197 | **Comments:** 417 | **ID:** 47098245

> **Article:** The article details LinkedIn's identity verification process, which involves sharing personal data with subprocessors like AWS, Google Cloud, and MongoDB to confirm user identities. Biometric data is deleted immediately after processing, while other data is retained for 30 days for troubleshooting. The use of North American subprocessors raises privacy concerns for European users under the CLOUD Act, which allows U.S. authorities to access data globally.
>
> **Discussion:** Users debated privacy risks tied to LinkedIn's verification system, focusing on subprocessors handling sensitive data and the lack of EU-based alternatives. Some argued that biometric data exposure is inevitable in digital life, while others emphasized the importance of user choice in data sharing. Technical insights from a competitor highlighted that not all listed subprocessors are used per individual, but the broad list itself raised red flags. Disagreements emerged over whether regulatory action in the EU could address these issues or if building competitive local platforms was more effective. Community reactions ranged from alarm over data centralization to skepticism about Europe's ability to compete technologically with the U.S. and China. The discussion also critiqued the CLOUD Act's extraterritorial reach and questioned LinkedIn's transparency in data handling practices.

---

## [What not to write on your security clearance form (1988)](https://milk.com/wall-o-shame/security_clearance.html)
**Score:** 402 | **Comments:** 181 | **ID:** 47102576

> **Article:** The 1988 piece warns applicants filling out U.S. security clearance forms to avoid writing anything that could become a leverage point for blackmail, framing the questionnaire as a “wall of shame” that forces disclosure of personal vulnerabilities. It lists concrete items to omit—such as past FBI investigations for harmless pranks, minor drug use, foreign financial ties, and even casual alcohol consumption—while emphasizing that the “FBI question” is a notorious trap that can derail a clearance if answered truthfully. The article advises that the safest approach is to leave out any detail that isn’t directly relevant to current security duties, and to document any disclosed issues in a way that shows you understand the risk. It also notes that the form’s rigid categories often force applicants into “bins” that don’t capture nuanced histories, leading to either lies or unnecessary rejections.
>
> **Discussion:** Commenters debated whether the advice to omit certain disclosures is a pragmatic workaround or a dangerous encouragement of fraud, with many pointing out that the clearance process is designed to uncover blackmail material and that lying creates exactly the risk it seeks to avoid. The thread highlighted a recurring theme of “bins”—the rigid categories on the SF‑86 that force applicants to shoehorn nuanced histories into checkboxes, leading to either falsehoods or unnecessary rejections, and several users cited personal anecdotes of investigators forgiving past drug use if the applicant demonstrated understanding and remorse. A split emerged over which vulnerabilities matter most: while some argued that financial indiscretions are the primary concern for compromise, others insisted that even a single suspicion of marijuana use can trigger a wringer, as illustrated by a user who lost a clearance for “pissing hot” despite six‑figure debts. The conversation also veered into broader critiques of the clearance bureaucracy, likening it to a jobs program and a security‑theater exercise that wastes billions while failing to catch real threats, and a few noted the irony of the article’s own “wall‑of‑shame” framing being mirrored by the government’s opaque categories. Humor and meta‑commentary surfaced, including jokes about the milk.com domain’s value and the “Seeing like a Bank” pun, which underscored how the thread blended technical insight with a playful take on the absurdities of the clearance process.

---

## [Why is Claude an Electron app?](https://www.dbreunig.com/2026/02/21/why-is-claude-an-electron-app.html)
**Score:** 349 | **Comments:** 327 | **ID:** 47104973

> **Article:** The article discusses why Anthropic chose to build the Claude desktop application using Electron rather than native development. Boris Cherny from the Claude Code team explains that some engineers had prior experience with Electron, it allows code sharing across web and desktop platforms ensuring consistent features, and the team found it effective for their needs. The post acknowledges that engineering involves tradeoffs and this choice may evolve in the future.
>
> **Discussion:** The Hacker News discussion reveals a deep divide between technical purists and pragmatic developers. Many users complained about Electron's performance issues, with one commenter noting that their nonprofit clients on low-end machines struggle with the resource demands of Electron apps. Others defended the choice, pointing out that companies like Microsoft successfully use Electron for Teams. The debate extended to broader concerns about AI-generated code quality, with some arguing that developers are losing understanding of their systems when relying too heavily on AI tools. Technical alternatives like Tauri were mentioned, though some countered that supporting multiple browser engines creates its own QA challenges. The thread also touched on the philosophical question of whether code has become "free" in the age of AI, with mixed opinions on whether this represents progress or a loss of developer control.

---

## [Andrej Karpathy talks about "Claws"](https://simonwillison.net/2026/Feb/21/claws/)
**Score:** 276 | **Comments:** 66 | **ID:** 47099160

> **Article:** Andrej Karpathy introduced the term “Claws” to describe a new AI capability that lets models iteratively refine their outputs. He illustrated the concept with a tweet (ID 2024987174077432126) that sparked immediate discussion in the community. The blog post on simonwillison.net frames the term as part of a broader effort to coin fresh language for emerging model behaviors.
>
> **Discussion:** Commenters questioned why the conversation was being mediated through Simon Willison’s blog rather than linking directly to Karpathy’s tweet, arguing that the practice violates HN’s original‑sourcing guideline. One user accused the blog of acting as a link‑farm for engagement, while another pointed out that the author is selective about what he submits and often adds value by highlighting the novelty of the term. A few participants shared the direct xcancel link to the tweet, suggesting it as a cleaner source, and the moderators eventually moved the discussion to a dedicated item. The thread also devolved into a side debate about Simon Willison’s independence and sponsorship disclosures, with some users defending his transparency and others criticizing the perceived conflict of interest. Overall, the exchange highlighted tensions between curation practices, community norms, and the desire for more direct linking on the platform.

---

## [AI uBlock Blacklist](https://github.com/alvi-se/ai-ublock-blacklist)
**Score:** 234 | **Comments:** 104 | **ID:** 47098582

> **Article:** The article links to a GitHub repository named "AI uBlock Blacklist," a filter list for the uBlock Origin browser extension designed to block websites that generate content using artificial intelligence. The project's maintainer includes a "NAQ (Never Asked Questions)" section with the dismissive response "My website is on your list! Cry about it," which commenters criticize as an unprofessional and authoritarian stance for a public blacklist. The list's stated goal is to help users avoid low-quality, AI-generated "slop" in search results, though its broad application raises concerns about false positives.
>
> **Discussion:** The discussion revolves around the ethics and practicality of maintaining a public blocklist for AI-generated sites. A central disagreement pits those who support aggressive, preemptive blocking to filter out unwanted "SEO slop" against those who condemn the maintainer's hostile "Cry about it" attitude and warn of the power to inadvertently damage innocent websites, as seen in personal anecdotes about unreachable personal sites. The conversation expands to debate the quality of AI-assisted writing versus human or machine-translated content, with some praising the list's utility while others propose more targeted alternatives, like a list focused solely on content farms. Technical insights compare different blocking tools (Pi-hole, Adguard), and a meta-debate emerges about the future necessity of adblockers and the performative nature of changing terms like "blacklist" to "blocklist," which some view as virtue signaling versus others who see it as addressing subtle racial connotations.

---

## [EU mandates replaceable batteries by 2027 (2023)](https://environment.ec.europa.eu/news/new-law-more-sustainable-circular-and-safe-batteries-enters-force-2023-08-17_en)
**Score:** 218 | **Comments:** 174 | **ID:** 47098687

> **Article:** The EU has enacted a regulation requiring replaceable batteries in portable devices by 2027, aiming to reduce e-waste and combat planned obsolescence. The law mandates that batteries be removable by end-users using standard tools, with exceptions for waterproof devices and specific technical requirements. This move targets the proliferation of glued-in batteries in smartphones and other electronics, which critics argue exacerbates electronic waste and environmental harm from improper disposal.
>
> **Discussion:** The discussion centers on the EU's battery regulation as a pro-environmental policy, with mixed reactions on its practicality. Supporters, like mentalgear, highlight the moral imperative to address e-waste and planned obsolescence, contrasting modern devices with earlier eras when replaceable batteries were standard. Skeptics, such as mytailorisrich, argue that replaceable batteries are rarely used by consumers and question whether the mandate will meaningfully extend device lifespans. Technical debates focus on compliance: Reason077 notes that older batteries required spares due to poor longevity, while atoav emphasizes the environmental cost of glued-in batteries and the need for standardized repair tools. Disputes arise over waterproofing exemptions, with some users (e.g., jl6) pointing out that iPhones already allow battery replacement via paid services, though not fully aligning with the mandate. Others, like vanviegen, question whether replaceable batteries were ever common in early phones, while cyberrock clarifies that the regulation avoids compelling EU-specific designs. The thread also touches on disposable vapes, with relistan hoping the rule could curb their environmental impact. Overall, the community acknowledges the regulation's intent but debates its enforceability and real-world impact.

---

## [Acme Weather](https://acmeweather.com/blog/introducing-acme-weather)
**Score:** 214 | **Comments:** 128 | **ID:** 47098296

> **Article:** The article explores opinions on weather apps, highlighting concerns about privacy, data collection, and the value of accurate forecasts. Users debate whether the market still needs weather apps beyond basic functionality and question the profitability of current offerings. Some praise local and EU-based services like MeteoSwiss and Windy, while others criticize apps for lacking real-time accuracy or ethical data practices. The conversation also touches on the potential of citizen reports and the challenges of improving forecast models with mobile data. Overall, participants emphasize the need for better, more trustworthy weather information for everyday decision-making.
>
> **Discussion:** Users shared mixed views on the relevance and profitability of weather apps, with some praising local services and others questioning their accuracy and privacy implications. There was agreement on the importance of community reports and the limitations of current forecasting models. Technical concerns were raised about data collection from phones and the feasibility of improving forecasts, while privacy worries centered on how apps handle personal information. The debate underscored a broader skepticism about the value of most existing weather applications in 2026.

---

## [How I use Claude Code: Separation of planning and execution](https://boristane.com/blog/how-i-use-claude-code/)
**Score:** 212 | **Comments:** 124 | **ID:** 47106686

> **Article:** The article explores how users integrate Claude AI into software development, focusing on the balance between planning and execution. Developers share experiences highlighting the value of detailed prompts and deep content analysis, while also expressing concerns about time investment and the need for thorough review. Some participants emphasize the importance of understanding underlying code and architecture, whereas others appreciate the efficiency gains and reduced manual effort. The conversation underscores a growing reliance on AI tools but also raises questions about quality control and the necessity of human oversight. Technical insights reveal a divide between those who find planning beneficial and those who see it as a time-consuming process. Community reactions reflect both enthusiasm for AI assistance and skepticism about its reliability and impact on coding skills.
>
> **Discussion:** Several key themes emerged from the discussion. Developers noted that detailed, expert-level prompts significantly improve AI output quality, contrasting with the perception that AI merely skims surface-level information. There was a clear divide between those who found extensive planning and prompt crafting essential versus those who viewed it as unnecessary or time-consuming. Participants highlighted the role of attention mechanisms and the need for deep contextual understanding, especially for complex tasks. The conversation also touched on broader concerns about code quality, the risk of over-reliance on AI, and the value of maintaining personal coding skills alongside AI assistance. Overall, the exchange reflected a nuanced view of AI as a powerful tool when properly guided, but also a reminder of the importance of critical evaluation.

---

## [macOS's Little-Known Command-Line Sandboxing Tool (2025)](https://igorstechnoclub.com/sandbox-exec/)
**Score:** 195 | **Comments:** 80 | **ID:** 47101200

> **Article:** The article explains that macOS’s command‑line sandboxing utility sandbox‑exec has been officially deprecated since macOS 10.13.6 (released in 2017) and that Apple now advises developers to use the App Sandbox framework instead. It notes that several high‑profile tools such as the Codex CLI and Swift Package Manager continue to rely on sandbox‑exec despite the deprecation. The piece also links to a UI project called multitui.com that provides a terminal‑app sandboxing interface, and it references community concerns about the tool’s misleading name and limited functionality compared to true sandboxing concepts.
>
> **Discussion:** Developers debate why Apple chose to deprecate sandbox‑exec while still depending on it for first‑party apps, with some speculating that the company wants to phase out the older SBPL language in favor of the more maintainable App Sandbox entitlements. Several commenters point out that major ecosystems like Homebrew, Nix and Bazel still invoke sandbox‑exec during builds, highlighting the practical difficulty of migrating away from it. Others criticize the tool’s name and its resemblance to high‑level seccomp filters rather than a true isolation sandbox, and they propose alternatives such as dedicated throwaway user accounts or resource‑virtualization approaches. A few contributors share personal sandboxes they have built, discussing the complexity of policy injection and the need for transactional reconciliation of sandbox state. The conversation also touches on the broader implications for AI‑related tooling on macOS, questioning whether continued reliance on a deprecated interface could undermine security guarantees.

---

## [Personal Statement of a CIA Analyst](https://antipolygraph.org/statements/statement-038.shtml)
**Score:** 189 | **Comments:** 113 | **ID:** 47102975

> **Article:** The article is a first-person account from a CIA analyst who failed a pre-employment polygraph examination. The author details the grueling eight-hour process, including a blood pressure cuff tightened to the point of causing purple discoloration and tremors, and a theatrical "calibration test" involving lying about a chosen number. The narrative criticizes the test's purpose as a tool for intimidation and extracting confessions to minor, non-disqualifying acts, while also reflecting on the culture of dependency within the intelligence community. A specific claim is that examiners are aware of anti-polygraph websites like antipolygraph.org and have memorized the owner's backstory.
>
> **Discussion:** Commenters debated the fundamental purpose and reliability of polygraph tests, with a dominant view that they function primarily as intimidation tools ("pressure cookers") rather than truth detectors, designed to elicit confessions to embarrassing but irrelevant information. Personal anecdotes from former applicants described physically uncomfortable procedures, such as excessively tight cuffs, and psychologically stressful interrogations where examiners fixated on minor past offenses like petty theft. The discussion referenced historical CIA projects like MKUltra and remote viewing as precedents for questionable scientific pursuits, while technical insights emerged about countermeasures, like controlling the vagus nerve through physical tension. Disagreements arose over whether the test's value lay in its scientific validity or its coercive power, with many expressing cynicism about the CIA's ethical standing given its history and the test's potential for abuse. The thread also contained dark humor comparing the experience to pop culture tropes and criticizing the "battered housewife syndrome" of government employees.

---

## [CXMT has been offering DDR4 chips at about half the prevailing market rate](https://www.koreaherald.com/article/10679206)
**Score:** 167 | **Comments:** 149 | **ID:** 47101171

> **Article:** The article discusses how CXMT, a Chinese semiconductor manufacturer, has been offering DDR4 chips at approximately half the prevailing market rate. This pricing strategy has attracted attention from major PC manufacturers like Dell, HP, Acer, and Asus, who have begun qualifying CXMT's samples for potential use in their products. The significant price difference is attributed to the current AI infrastructure boom driving up NAND and DRAM prices, creating an opportunity for Chinese fabs to gain market share.
>
> **Discussion:** The Hacker News discussion centered around the implications of Chinese semiconductor manufacturers entering the market with aggressive pricing strategies. Some commenters viewed this as a natural market response to supply shortages, while others expressed concern about the long-term consequences of losing domestic production capacity in critical industries. There was debate about whether this represented dumping or simply taking advantage of artificially high prices created by AI-related demand. Several participants discussed the geopolitical implications, with some suggesting China's semiconductor buildout is aimed at reducing dependence on Western suppliers in case of conflict with Taiwan. The conversation also touched on broader themes of short-term profit focus in Western businesses versus China's longer-term strategic planning, and whether the market is functioning as intended by allowing new competitors to fill gaps left by established players. Technical discussions included comparisons of storage solutions for GPUs and the economics of semiconductor pricing at different stages of the supply chain.

---

## [EDuke32 – Duke Nukem 3D (Open-Source)](https://www.eduke32.com/)
**Score:** 161 | **Comments:** 60 | **ID:** 47104185

> **Article:** The article highlights EDuke32, an open-source port of Duke Nukem 3D, emphasizing its ability to enhance the game's graphics and gameplay while preserving its retro charm. It mentions the Build Engine's role in enabling modding, with examples like the Ashes 2063 mod for DOOM and the inclusion of accessibility features. The discussion also notes technical challenges, such as Linux compatibility issues reported by users, and the community's efforts to preserve and improve classic FPS games.
>
> **Discussion:** The conversation revolves around nostalgia for 90s FPS games, with users praising Duke Nukem 3D's level design and modding potential. Key themes include the impact of the Build Engine on modding, the importance of accessibility tools like ctoth's Quake accessibility mod, and debates about game mechanics, such as movement and level complexity. Technical insights emerge about the limitations of AI in generating content for older games, while community reactions range from enthusiasm for projects like Ashes 2063 to frustration with modern web bloat. Disagreements arise over the superiority of Duke3D's design compared to Doom and Quake, with some users valuing its tactile feel and others critiquing its abstract elements. The thread also touches on the enduring legacy of open-source communities in sustaining classic games.

---

## [Cloudflare outage on February 20, 2026](https://blog.cloudflare.com/cloudflare-outage-february-20-2026/)
**Score:** 160 | **Comments:** 108 | **ID:** 47103649

> **Article:** The article discusses a recent outage at Cloudflare and the community's reaction to it. Several contributors questioned the reliability and transparency of the service, pointing out potential design flaws and a lack of clear API contracts. Concerns were raised about the impact on users and the need for better testing and communication within the development team. Technical discussions highlighted issues like overloading existing endpoints and insufficient handling of query parameters. Overall, the conversation reflects frustration over service instability and calls for improved practices in infrastructure management.**
>
> **Discussion:** Multiple voices expressed concern over Cloudflare's recent network disruptions, with some accusing leadership of poor management and rushed changes. Technical debates centered on API design, testing, and whether the service should have handled 'pending_delete' queries differently. The community emphasized the importance of clear communication, robust testing, and avoiding risky defaults that could lead to data loss. Overall, the discussion underscored a broader worry about trust and reliability in critical internet infrastructure.

---

## [Meta Deployed AI and It Is Killing Our Agency](https://mojodojo.io/blog/meta-is-systematically-killing-our-agency/)
**Score:** 146 | **Comments:** 104 | **ID:** 47097502

> **Article:** The article argues that Meta’s recent rollout of AI‑driven account‑creation and monitoring systems is systematically disabling agency accounts, forcing agencies to use personal profiles for business purposes and then automatically flagging them for violations of the “no more than one personal account” policy. It cites Meta support representatives who claim that “account creation and monitoring are now handled almost entirely by AI” and notes that the platform provides no manual review path for flagged accounts, even after successful face‑verification. The piece also links these automated bans to a broader decline in Facebook usage, suggesting that the friction is driving agencies away from the platform. It highlights concrete steps agencies must take—such as submitting IDs, bank statements, and undergoing repeated verification loops—to regain access, only to be blocked again by the same AI parameters. The author frames the situation as a loss of agency for marketers and a strategic misstep by Meta.
>
> **Discussion:** Commenters split over whether the article is genuine reporting or clickbait, with several pointing out that the original post never mentions AI or LLMs, while others, including a user who contacted Meta support, confirm that AI now dominates account handling and that human reviewers are unreachable. Technical details emerge about the verification process: users describe being asked for full checking‑account numbers, bank statements redacted, and repeated “show ID” loops that are ignored by automated responses, illustrating the opaque nature of Meta’s AI filters. The thread expands beyond Meta to similar experiences on Google, LinkedIn, eBay, and Instagram, where new accounts are instantly banned or require obscure workarounds, suggesting a wider industry trend of AI‑driven friction. Some contributors argue that the article’s tone is hostile and that agencies are complicit in the problem, while others defend the piece as exposing a real livelihood threat and call for ethical alternatives like switching to other email providers or enterprise SSO solutions. A few suspect the post is LLM‑generated, noting its repetitive “dramatic” structure, but others insist it is human‑written, underscoring the community’s mixed reaction to automated content. Overall, the discussion reflects frustration, speculation about AI’s role, and a search for workable solutions amid increasingly automated platform policies.

---

## [Parse, Don't Validate and Type-Driven Design in Rust](https://www.harudagondi.space/blog/parse-dont-validate-and-type-driven-design-in-rust/)
**Score:** 142 | **Comments:** 39 | **ID:** 47103931

> **Article:** ... (3-4 sentences)
>
> **Discussion:** ... (4-6 sentences)
.

Let's craft.

Content Summary: The article "Parse, Don't Validate and Type-Driven Design in Rust" argues that programs should parse untrusted inputs into types that guarantee validity by construction, rather than validating data at runtime. It illustrates the concept with Rust examples such as NonZeroF32, which prevents zero values, and a non-empty vector type that ensures at least one element exists. The author emphasizes that such type-driven design moves error handling from runtime to compile time, making invalid states unrepresentable. The article also touches on the limitations of Rust's type system compared to dependently typed languages like Idris.

That's 4 sentences. Include specific detail: NonZeroF32, non-empty vector, maybe mention Idris.

Discussion Summary: The discussion explores tensions between the "parse, don't validate" philosophy and alternative designs like using a single flexible type (e.g., Clojure maps). Participants debate the trade-offs: while encoding invariants in types improves safety, it can lead to proliferation of similar but incompatible types and may be less adaptable to changing real-world requirements. Technical insights include explanations of dependent typing in Idris and Lean, where length-indexed vectors and Fin types guarantee bounds checking at compile time, and mentions of Rust's experimental pattern types and macro-based libraries that approximate dependent typing. Some commenters note that even newtype wrappers provide significant benefits by making validation history explicit, though they are weaker than full correctness-by-construction. The thread also highlights practical concerns, such as the non-empty vector implementation's inefficiencies and the challenge of arithmetic operations on non-zero types, illustrating the balance between theoretical purity and usability.

That's about 5 sentences. Ensure it's flowing, not bullet points. Avoid starting with "The discussion". We'll start directly: "The discussion explores tensions..." That's fine.

Now check: Both sections required. Use exact tags. No extra spaces? The tags are  and ,  and

---

## [LibreOffice blasts OnlyOffice for working with Microsoft to lock users in](https://www.neowin.net/news/libreoffice-blasts-fake-open-source-onlyoffice-for-working-with-microsoft-to-lock-users-in/)
**Score:** 132 | **Comments:** 109 | **ID:** 47098828

> **Article:** The article reports that LibreOffice has criticized OnlyOffice, accusing it of collaborating with Microsoft to lock users into proprietary systems, thereby undermining open-source principles. A key detail is the mention of OnlyOffice's potential Russian origins and the EU's consideration of forking it as a response, though the article notes the company is registered in Latvia with a complex ownership structure. The core conflict centers on OnlyOffice's partnership with Microsoft, which LibreOffice views as a betrayal of open-source ideals.
>
> **Discussion:** The discussion revolves around the rivalry between office suite alternatives, focusing on UI preferences, functionality, and open-source authenticity. Users debate the datedness of LibreOffice's interface versus OnlyOffice's modern look, with some valuing classic UIs for productivity. Functionality criticisms include OnlyOffice's missing features and LibreOffice's bugs, while others praise Gnumeric as a superior spreadsheet. A major theme is the controversy over OnlyOffice's partnership with Microsoft, seen by LibreOffice as locking users in, countered by supporters who view it as a pragmatic business move. Technical concerns emerge about sandboxing desktop apps and distrust from projects like Cryptpad, highlighting security and ethical debates. The thread also explores broader industry issues like Excel's flaws and the challenges of open-source adoption against entrenched proprietary software.

---

## [Show HN: Llama 3.1 70B on a single RTX 3090 via NVMe-to-GPU bypassing the CPU](https://github.com/xaskasdf/ntransformer)
**Score:** 220 | **Comments:** 31 | **ID:** 47104667

> **Project:** Hacker News user xaskasdf details a project to run the 70B parameter Llama 3.1 model on a single RTX 3090 GPU by bypassing the CPU and directly connecting the GPU to NVMe storage, achieving approximately 3000 tokens per second. This approach addresses the performance bottleneck of PCIe 3.0 x8, which limits throughput, and leverages custom GEMM kernels to optimize memory access patterns for streaming inference. The project stems from retro gaming experiments and aims to demonstrate that consumer GPUs can handle large models without professional-grade hardware.
>
> **Discussion:** The Hacker News discussion centers on the technical merits and practical limitations of bypassing the CPU for transformer model inference. Key themes include the PCIe 3.0 x8 bottleneck identified by turingsroot, which caps throughput at ~6.5GB/s and limits performance despite the RTX 3090's capabilities. There's significant debate about energy efficiency versus API costs, with esquire_900 arguing that local inference at 0.5 tokens per second is less cost-effective than cloud APIs, while umairnadeem123 counters that batch workloads benefit from local deployment. Technical insights highlight the project's innovative adaptive caching and layer-skipping techniques, with rao-v and zozbot234 exploring multi-tier Mixture of Experts (MoE) architectures for VRAM/RAM/NVMe tiers. The community also debates the role of hardware abstraction, with civicsquid and rustyhancock drawing parallels to retro gaming consoles' DMA capabilities, and jacquesm and serendip-ml discussing model compression and quantization as future optimization paths.

---

## [zclaw: personal AI assistant in under 888 KB, running on an ESP32](https://github.com/tnm/zclaw)
**Score:** 122 | **Comments:** 65 | **ID:** 47100232

> **Article:** The article introduces zclaw, a personal AI assistant designed to run on an ESP32 microcontroller with a binary size under 888 KB. It functions as a lightweight client that connects to external LLM APIs such as Anthropic, OpenAI, and OpenRouter, but does not support local model inference. The project emphasizes minimal resource usage for IoT deployments, leveraging the ESP32's Wi-Fi and TLS capabilities to act as a bridge between users and cloud-based AI services.
>
> **Discussion:** The discussion quickly centered on disappointment that zclaw relies on cloud APIs rather than local inference, with many noting that 888 KB is far too small for any meaningful on-device LLM. Users debated the actual utility of such "claw" assistants, with some dismissing them as simple API wrappers that merely pipe prompts to services like ChatGPT, while others saw potential in lightweight IoT automation—like a smart thermostat or a Tamagotchi-like device—if security concerns are addressed. There was significant skepticism about the "OpenClaw hype," with critics arguing that buying separate hardware like Mac minis for these tools is overkill when a Raspberry Pi suffices, and that the underlying code is often trivial. The binary size also drew technical criticism, with comparisons to the original Doom's 700 KB, though others noted zclaw includes networking stacks Doom didn't need. Underlying the thread was a broader critique of the tech industry's rush toward AI agents without deep understanding of the underlying systems, and warnings about overestimating what such minimal assistants can realistically achieve.

---

## [24 Hour Fitness won't let you unsubscribe from marketing spam, so I fixed it](https://ahmedkaddoura.com/projects/24hf-unsubscribe)
**Score:** 114 | **Comments:** 47 | **ID:** 47098744

> **Article:** The article describes how 24 Hour Fitness's unsubscribe functionality was broken, preventing users from opting out of marketing emails. The author discovered that the unsubscribe endpoint was returning a 400 error due to a missing parameter, and created a workaround by building a tool that automatically adds the required parameter to make the unsubscribe request succeed. The solution involved reverse engineering the API request and creating a simple web interface to help others unsubscribe from 24 Hour Fitness marketing emails.
>
> **Discussion:** The discussion centered around various approaches to handling spam emails, with several users sharing their solutions like using unique email aliases for each service or leveraging Apple's Hide My Email feature. There was debate about whether unsubscribe links actually work, with some users claiming they're effective while others argued they're often broken or ignored by companies. Technical discussions emerged about email headers, CORS implementation, and the CAN-SPAM Act's enforcement limitations. Several users shared their frustrations with other companies like Walmart and Oracle that similarly ignore unsubscribe requests, with some suggesting email providers should automatically mark such emails as spam. The conversation also touched on the ethics of companies using consent management platforms like OneTrust while violating consent regulations.

---

## [Toyota Mirai hydrogen car depreciation: 65% value loss in a year](https://carbuzz.com/toyota-mirai-massive-depreciation-one-year/)
**Score:** 135 | **Comments:** 256 | **ID:** 47103136

> **Article:** The article discusses the significant depreciation of the Toyota Mirai hydrogen fuel cell vehicle, which lost 65% of its value in just one year. This steep decline in value is attributed to the limited hydrogen infrastructure, particularly outside of California, and the overall challenges facing hydrogen fuel cell technology in the automotive market. The Mirai's depreciation is contrasted with the growing popularity and adoption of battery electric vehicles.
>
> **Discussion:** The Hacker News discussion reveals a strong consensus that hydrogen fuel cell vehicles are fundamentally flawed for personal transportation. Commenters argue that hydrogen's poor "well-to-wheel" efficiency, the complexity of creating hydrogen infrastructure, and the inherent dangers of storing and transporting a highly explosive gas make it an impractical solution. Many point out that Toyota's push for hydrogen stems from their reluctance to abandon internal combustion engine technology, rather than any technical merit. The conversation also touches on hydrogen's potential applications in aviation and long-distance renewable energy storage, but these are seen as niche cases. Several commenters note that battery electric vehicles have already won the market, with consumers clearly preferring their simplicity, lower operating costs, and the existing electrical grid infrastructure. The discussion concludes that every dollar spent on hydrogen infrastructure is a wasted opportunity to improve the already superior battery electric technology.

---

