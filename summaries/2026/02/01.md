# Hacker News Summary - 2026-02-01

## [Mobile carriers can get your GPS location](https://an.dywa.ng/carrier-gnss.html)
**Score:** 699 | **Comments:** 417 | **ID:** 46838597

> **Article:** The article explains how mobile carriers can obtain precise GPS location data from smartphones through built-in mechanisms in the UMTS and LTE specifications, which allow remote requests for device location independent of user-controlled settings. While initially justified for emergency services (e.g., E911), these capabilities are deeply embedded in the cellular stack and can be exploited beyond their intended purpose. The author highlights that this access bypasses typical privacy controls and operates at the firmware or baseband level, making it difficult for users to detect or prevent.
>
> **Discussion:** 
Users reacted with a mix of alarm and technical scrutiny, debating the balance between emergency functionality and mass surveillance. While some defended the system as originally designed for 911 services, others dismissed that rationale, arguing it enables a surveillance infrastructure ripe for abuse—especially since law enforcement often bypasses legal constraints by purchasing location data from brokers. A key technical revelation centered on the baseband processor’s regulatory mandate to control microphones, radios, and GPS, potentially allowing remote activation even when phones appear off or disconnected; however, this claim was challenged by those citing modern hardware designs that decouple baseband from peripherals. Proposals ranged from legal accountability and retroactive penal

---

## [Finland looks to introduce Australia-style ban on social media](https://yle.fi/a/74-20207494)
**Score:** 641 | **Comments:** 456 | **ID:** 46838417

> **Article:** Finland is considering a ban on social media platforms for minors, inspired by similar measures in Australia, aiming to protect young people from the negative mental health impacts of algorithm-driven, ad-based social media. The proposal targets platforms that use engagement-optimizing algorithms and targeted advertising, while potentially exempting forums and communication tools without such features. The focus is on curbing the addictive design and commercial exploitation inherent in major social networks.
>
> **Discussion:** 
The conversation reflects deep skepticism about the evolution of social media from a tool for connection to an algorithmically driven engine of addiction and polarization, with many lamenting the decline of early internet forums and the rise of engagement-optimized content on platforms like Reddit. While there's broad agreement that current social media harms youth, opinions diverge sharply on solutions: some advocate for strict bans or invasive verification to deter use, while others warn such measures risk enabling censorship and eroding online anonymity. Technical and regulatory alternatives emerge as a key theme—particularly banning targeted ads to minors, disabling algorithmic feeds, and enforcing chronological timelines—seen as more precise ways to address harm without blanket restr

---

## [Swift is a more convenient Rust (2023)](https://nmn.sh/blog/2023-10-02-swift-is-the-more-convenient-rust)
**Score:** 298 | **Comments:** 285 | **ID:** 46841374

> **Article:** The article argues that Swift shares many modern language features with Rust—such as strong typing, safety guarantees, and expressive enums—while offering a more convenient and higher-level experience. It suggests that Swift could be seen as a more ergonomic alternative to Rust for systems-adjacent programming, especially given its cleaner syntax and better tooling for certain workflows, despite not being marketed as a systems language.
>
> **Discussion:** 
The conversation quickly diverged from any notion of Swift as a Rust alternative, focusing instead on deep frustrations with Apple’s tooling—especially Xcode’s poor scalability and debugging experience—while others defended Swift’s viability outside Apple’s ecosystem using LSP and cross-platform editors. Memory management in Swift, particularly with SwiftUI, drew criticism for being opaque and leak-prone compared to Rust’s deterministic ownership model, with several users recounting unresolved virtual memory issues. Technical inaccuracies in the original post sparked debate about language design, with corrections around Rust’s type layout and Swift’s enum limitations, while broader concerns emerged about Swift’s dependency on Apple’s priorities, contrasted against Rust’s community-driven 

---

## [US has investigated claims WhatsApp chats aren't private](https://www.bloomberg.com/news/articles/2026-01-29/us-has-investigated-claims-that-whatsapp-chats-aren-t-private)
**Score:** 194 | **Comments:** 339 | **ID:** 46838635

> **Article:** The Bloomberg article reports that U.S. authorities have investigated claims that WhatsApp’s end-to-end encryption may not fully protect user privacy, raising questions about whether Meta could potentially access message content despite public assurances. While WhatsApp maintains that messages are securely encrypted, the probe focuses on whether technical or architectural aspects of the app could allow for message interception or data sharing with Facebook. The investigation appears to center on the integrity of WhatsApp's encryption implementation and its relationship with Meta's broader data practices.
>
> **Discussion:** 
The Hacker News thread dives into the technical and trust-based foundations of WhatsApp’s end-to-end encryption, with participants split between skepticism and cautious confidence. Some highlight that independent audits have verified the cryptographic core, but stress that not reviewing the full source code limits assurance—especially given the app’s closed-source nature and potential for covert data exfiltration through analytics or compromised clients. Others argue that true security requires open source and reproducible builds to rule out hidden backdoors, while skeptics point to Meta’s history and incentives as reason to distrust any claims of privacy. A deeper debate emerges around client-side trust, with some noting that even perfect encryption fails if the app or OS can siphon plai

---

## [In praise of –dry-run](https://henrikwarne.com/2026/01/31/in-praise-of-dry-run/)
**Score:** 187 | **Comments:** 102 | **ID:** 46840612

> **Article:** The article advocates for the use of `--dry-run` flags in command-line tools to preview actions without making changes, emphasizing its value in preventing accidental modifications. It highlights how dry runs improve safety and confidence when executing scripts or tools that interact with critical systems. The author shares practical examples where dry-run functionality has helped avoid errors during development and operations.
>
> **Discussion:** 
The discussion quickly expands beyond simple praise for `--dry-run`, evolving into a nuanced debate about safety-by-default design in CLI tools. Many users favor requiring an explicit `--commit` or `--execute` flag instead, arguing that opt-in mutation prevents accidents far better than opt-out dry runs—though others push back, noting that such patterns would bloat everyday commands like `rm` or `cp`. Technical depth emerges around implementation: separating planning from execution (as in Terraform) is praised for eliminating race conditions between dry and live runs, but some caution that building a full plan-and-apply system introduces significant complexity, especially for simpler tools. A deeper architectural conversation follows, with some advocating for dependency injection and stra

---

## [Netbird a German Tailscale alternative (P2P WireGuard-based overlay network)](https://netbird.io/)
**Score:** 186 | **Comments:** 46 | **ID:** 46844870

> **Article:** Netbird is a German-developed, self-hostable, peer-to-peer WireGuard-based overlay network presented as a privacy-focused alternative to Tailscale, emphasizing digital sovereignty and full mesh networking capabilities. It enables secure remote access to infrastructure without relying on third-party cloud services, appealing to users concerned about data jurisdiction and vendor lock-in. The project targets both personal and small business use cases, offering modern features like identity provider integration and plans for reverse proxy functionality.
>
> **Discussion:** 
Users welcomed Netbird as a promising self-hosted alternative to Tailscale, particularly valuing its European origin and alignment with EU digital sovereignty concerns, though some noted the absence of a Tailscale Funnel equivalent for securely exposing services to the internet. A key debate emerged around operational trade-offs: while some users rely on Funnel to expose secure services like Vaultwarden with clean TLS termination, others prefer keeping everything behind the VPN for maximum security. Technical pain points included confusion over Tailscale’s key expiration policies—clarified by community members who explained that while auth keys expire, registered devices can have indefinite access—and interest in Netbird’s roadmap, especially its upcoming reverse proxy feature to match Cl

---

## [Apple Platform Security (Jan 2026) [pdf]](https://help.apple.com/pdf/security/en_US/apple-platform-security-guide.pdf)
**Score:** 185 | **Comments:** 129 | **ID:** 46837814

> **Article:** The Apple Platform Security document (Jan 2026) details Apple's comprehensive approach to securing its hardware, software, and services across devices. It covers encryption protocols, secure boot processes, hardware-based security features like the Secure Enclave, and privacy protections in iCloud and iMessage. Notably, it outlines the Advanced Data Protection (ADP) option for end-to-end encrypted iCloud backups, though this remains opt-in rather than default.
>
> **Discussion:** 
The conversation centers on the tension between Apple’s public stance on privacy and the practical limitations of its security model, particularly around iMessage and iCloud backups. Critics highlight that while Apple promotes end-to-end encryption, standard iCloud backups—including messages—are decryptable by Apple, creating a significant backdoor unless users proactively enable ADP, a feature seen as underutilized and therefore ineffective at scale. Skepticism emerges over whether Apple can truly be trusted as a privacy guardian given its growing ad business and closed-source ecosystem, with some comparing its practices unfavorably to Google’s Android, which has offered default end-to-end encrypted backups for years. Technical debates arise around memory safety improvements in iBoot, th

---

## [List animals until failure](https://rose.systems/animalist/)
**Score:** 172 | **Comments:** 97 | **ID:** 46842603

> **Article:** The article links to a simple web-based game called "List animals until failure," where users type animal names and the system validates them against a predefined list, rejecting duplicates or non-animals. Despite its simplicity, the game includes quirky easter eggs, taxonomic logic based on Wikidata, and humorous responses for certain inputs like "drop bear" or "dingo." The backend relies on basic text parsing and lookup tables rather than AI, drawing data from public sources like Wikidata.
>
> **Discussion:** 
Users were charmed by the game’s playful easter eggs and idiosyncratic responses, such as questioning if you're Australian when entering "dingo," but quickly spotted inaccuracies in its taxonomy logic—like rejecting "lynx" after "bobcat" or equating pigeons with mourning doves. A central debate emerged around biological classification, with users questioning whether common names should imply taxonomic hierarchy, especially in cases like chipmunks being considered squirrels or Portuguese man-o-war versus jellyfish. Technically, the community uncovered the use of hash-based triggers and multiple data tables, appreciating the clever design while noting inconsistencies from relying on crowd-sourced data like Wikidata, which had briefly hosted vandalism. Some suggested repurposing the concept 

---

## [US reportedly investigate claims that Meta can read encrypted WhatsApp messages](https://www.theguardian.com/technology/2026/jan/31/us-authorities-reportedly-investigate-claims-that-meta-can-read-encrypted-whatsapp-messages)
**Score:** 172 | **Comments:** 1 | **ID:** 46836487

> **Article:** U.S. authorities are reportedly investigating claims that Meta, the parent company of WhatsApp, may have the ability to access the content of encrypted messages on its messaging platform. The probe follows allegations that vulnerabilities or backdoors could allow the company to bypass end-to-end encryption, raising concerns about user privacy and data security. The Guardian's report emphasizes that WhatsApp has long claimed messages are protected so that not even the company can read them.
>
> **Discussion:** The claims sparked intense debate over the integrity of end-to-end encryption, with some users questioning whether true encryption can exist when a corporation controls the client software and update process. Skeptics pointed out that while the encryption protocol itself may be sound, backdoors could be introduced at the application level or through metadata collection, undermining user trust. Others defended Meta, arguing that the investigation may stem from misunderstandings about how encryption works or from government pressure to enable lawful access. Technical users emphasized that without verifiable open-source clients and transparent audits, assumptions about security are ultimately based on faith rather than proof.

---

## [Nvidia's 10-year effort to make the Shield TV the most updated Android device](https://arstechnica.com/gadgets/2026/01/inside-nvidias-10-year-effort-to-make-the-shield-tv-the-most-updated-android-device-ever/)
**Score:** 170 | **Comments:** 143 | **ID:** 46837346

> **Article:** The Ars Technica article details Nvidia's decade-long commitment to keeping the Shield TV the most consistently updated Android device on the market, thanks to vertical integration and a mandate from CEO Jensen Huang that prioritized long-term software support over cost. Despite using aging Tegra X1 hardware from 2015, the Shield TV continues to receive Android updates and security patches, outlasting nearly all other consumer electronics in longevity of support. The article highlights how this rare feat was achieved through internal prioritization, custom driver development, and Nvidia’s control over both hardware and software.
>
> **Discussion:** 
Users express deep loyalty to the Shield TV, praising its unmatched longevity and media playback capabilities, especially for local content via Plex or Emby, but lament the lack of modern hardware features like AV1 decoding, Wi-Fi 6, and full Dolby Vision Profile 7 support. While some suggest alternatives like the Thomson/Onn+ stick or Apple TV, many agree nothing matches the Shield’s balance of performance, codec support, and upgradability—though Apple TV is noted for tighter integration with major streaming apps. A key technical insight is that Qualcomm and other SoC vendors avoid long-term Android support due to DRM certification burdens, making Nvidia’s vertical control and CEO-driven mandate the real enabler of the Shield’s decade of updates. There’s widespread skepticism that Nvidia

---

## [Generative AI and Wikipedia editing: What we learned in 2025](https://wikiedu.org/blog/2026/01/29/generative-ai-and-wikipedia-editing-what-we-learned-in-2025/)
**Score:** 166 | **Comments:** 65 | **ID:** 46840924

> **Article:** The article examines the impact of generative AI on Wikipedia editing through the lens of the Wiki Edu program, which partners with universities to involve students in content creation. A key finding is that over two-thirds of articles flagged as AI-generated contained citations that failed verification—meaning the cited sources did not actually support the claims made, despite appearing plausible. This highlights a growing concern about the erosion of factual accuracy and source integrity on Wikipedia due to the ease with which AI can fabricate convincingly cited but unsubstantiated content.
>
> **Discussion:** 
The conversation centers on whether the proliferation of false or misleading citations on Wikipedia is a new problem exacerbated by generative AI or a long-standing issue rooted in human behavior. Many commenters agree that bad citations have existed for years, especially in politically sensitive articles, but stress that AI dramatically amplifies the problem by enabling faster, broader dissemination of plausible-sounding misinformation—a force multiplier effect. Disagreement emerges over the role of AI companies and users, with some suggesting bad actors or careless students are to blame, while others suspect systemic issues in how platforms handle sourcing. A notable undercurrent is skepticism toward AI-generated content in general, exemplified by critiques of Grokipedia’s factual inacc

---

## [Outsourcing thinking](https://erikjohannes.no/posts/20260130-outsourcing-thinking/index.html)
**Score:** 163 | **Comments:** 149 | **ID:** 46840865

> **Article:** The article "Outsourcing Thinking" explores the risks of relying on AI, particularly large language models (LLMs), to perform cognitive tasks that traditionally build human understanding and expertise. It critiques the growing tendency to delegate thinking to AI, arguing that such outsourcing can erode essential skills, especially when the AI's outputs are not fully transparent or reliable. Drawing on Andy Masley’s framework, the author emphasizes contexts where human cognition should not be outsourced—such as when building tacit knowledge, expressing care, or handling critical decisions—while acknowledging that some uses of AI may still be beneficial.
>
> **Discussion:** The conversation centers on a fundamental tension: whether AI augments human capability or erodes essential cognitive and ethical capacities. Many commenters echo the article’s concern, warning that treating AI as “Thinking as a Service” risks creating a generation unable to evaluate outputs critically, especially since LLMs lack the reliability of deterministic tools like calculators. Others push back, comparing AI to transformative but disruptive technologies like cars—acknowledging downsides but anticipating net societal gains, including more informed decision-making through scalable AI intelligence. Skepticism also emerges around accountability, with users noting how AI-generated communication enables plausible deniability in personal and professional contexts, potentially undermining honesty. A deeper undercurrent questions not just how we use AI, but how it reshapes power, behavior, and social norms—highlighting that the real danger may not be the tool itself, but the systems and incentives that drive its unchecked adoption.

---

## [Nintendo DS code editor and scriptable game engine](https://crl.io/ds-game-engine/)
**Score:** 140 | **Comments:** 34 | **ID:** 46839215

> **Article:** The article introduces a code editor and scriptable game engine for the Nintendo DS, enabling developers to create and run custom games directly on the device. The engine operates with a unique scripting language that executes one line per frame, imposing significant performance constraints. Despite these limitations, the project emphasizes accessibility and creativity within tight technical boundaries, appealing to hobbyists and retro enthusiasts.
>
> **Discussion:** 
Enthusiasm for the Nintendo DS and 3DS as hackable, retro-friendly platforms runs high, with users sharing personal experiences modding devices and praising their form factors for homebrew use. Technical debates emerge around the engine’s scripting speed—limited to about 60 lines per second—which some see as a crippling bottleneck for complex games, while others celebrate the extreme constraints as a creative catalyst akin to arthouse game development. Comparisons to modern alternatives like the Steam Deck highlight tensions between open hardware ideals and practical accessibility, with some noting that while the Deck is more powerful and user-friendly, the DS’s simplicity and charm offer a uniquely rewarding tinkering experience. Nostalgia and affection for physical quirks—like visible p

---

## [Film students who can no longer sit through films](https://www.theatlantic.com/ideas/2026/01/college-students-movies-attention-span/685812/)
**Score:** 125 | **Comments:** 211 | **ID:** 46838026

> **Article:** The Atlantic article explores concerns among film professors that today's college students, particularly film students, struggle to sit through full movies due to shortened attention spans, often distracted by smartphones and raised on fast-paced digital media. It presents anecdotes from educators who observe students losing focus during slow or older films, though some note that such challenges are not entirely new. The piece questions whether the issue is truly attention span or a shift in how younger audiences engage with cinematic pacing and narrative structure.
>
> **Discussion:** 
The thread quickly fractures along generational and aesthetic lines, with some users rejecting the premise of an attention span crisis, arguing instead that slow cinematic sequences are often justifiably skipped because they lack meaningful content, not due to impatience. Others counter that the ability to endure and appreciate slower, atmospheric storytelling is a cultivated skill essential to film literacy, likening fast-forwarding to cropping a painting or skipping silence in music. Technical habits like using 2x playback speed or skipping montages reveal divergent viewing philosophies, while deeper tensions emerge over whether modern media conditioning has eroded discipline or simply reshaped what audiences value. Some commenters emphasize context and intent, suggesting film education

---

## [Google Cloud suspended my account for 2 years, only automated replies](https://news.ycombinator.com/item?id=46839375)
**Score:** 125 | **Comments:** 72 | **ID:** 46839375

> **Article:** The original post describes a user's experience where their Google Cloud Platform (GCP) account was algorithmically suspended—quota set to zero—immediately after launching a production application, despite six months of effort to secure quota approval for the YouTube API. The user received no human support, only automated replies, effectively killing their startup. They express deep frustration over the lack of accountability and customer service from large cloud providers.
>
> **Discussion:** 
The thread sparked strong reactions around the risks of relying on big tech cloud platforms without guaranteed human support, with many users echoing concerns about opaque, automated enforcement systems that can abruptly terminate accounts without recourse. While some defended GCP and AWS by suggesting users often fail to pay for support or misuse services, others shared similar horror stories with Cloudflare and AWS, highlighting industry-wide issues of lock-in, poor escalation paths, and unreliable sales promises. A central debate emerged between those blaming individuals for not having enterprise contracts and those condemning the ethical implications of companies wielding unchecked power over livelihoods through algorithmic decisions. Calls for legal action, research into cloud monopo

---

## [The Saddest Moment (2013) [pdf]](https://www.usenix.org/system/files/login-logout_1305_mickens.pdf)
**Score:** 116 | **Comments:** 23 | **ID:** 46840219

> **Article:** "The Saddest Moment" (2013) by James Mickens is a darkly humorous and philosophically tinged critique of Byzantine fault tolerance in distributed systems, blending technical insight with absurdist satire. The paper questions the feasibility of building reliable systems in the presence of malicious actors, suggesting that the complexity and paranoia required to defend against untrustworthy components mirror a dystopian worldview. Through biting wit and existential despair, Mickens illustrates how system design reflects deeper assumptions about trust, human nature, and futility.
>
> **Discussion:** 
James Mickens’ signature blend of technical depth and sardonic humor draws praise from readers who appreciate his ability to turn systems research into literary performance, with several users citing his other works like "The Night Watch" as internet classics. The discussion pivots around both admiration for Mickens’ writing and broader skepticism about the real-world utility of Byzantine fault tolerance, especially in light of Bitcoin’s energy-intensive implementation that seems to confirm the paper’s cynical outlook. Some commenters argue that real systems should embrace trust rather than eliminate it, pointing to Ken Thompson’s "Trusting Trust" attack to show that absolute security is illusory, while others joke that society already operates in a state of permanent system failure—much 

---

## [Genode OS is a tool kit for building highly secure special-purpose OS](https://genode.org/about/index)
**Score:** 116 | **Comments:** 20 | **ID:** 46838981

> **Article:** Genode OS is a toolkit for constructing secure, special-purpose operating systems based on a capability-based microkernel architecture. It emphasizes minimalism, isolation, and fine-grained resource management, enabling the creation of highly reliable and secure computing environments. The project supports multiple microkernels including seL4, NOVA, and its own kernel, and includes Sculpt OS as a user-friendly, general-purpose demonstration of its capabilities.
>
> **Discussion:** 
Users expressed curiosity about Genode’s practicality for daily use, with one asking after a “how to use as a daily driver” video and another noting successful runs on refurbished Lenovo mini-PCs with Linux via VirtualBox, though Windows support remains untested. The project’s longevity and architectural rigor drew admiration, particularly its implementation of secure capabilities atop seL4, while a recurring joke highlighted the unfortunate phonetic resemblance of “Genode” to “genocide.” Some commenters drew parallels to other niche OS projects like DROPS and T2 SDE, and there was light-hearted banter around AI-generated OS features and compiling for obscure hardware, reflecting both genuine interest and the community’s playful skepticism toward highly specialized systems.

---

## [Berlin: Record harvest sparks mass giveaway of free potatoes](https://www.theguardian.com/world/2026/jan/31/record-harvest-berlin-giveaway-potatoes)
**Score:** 114 | **Comments:** 85 | **ID:** 46839784

> **Article:** A record potato harvest in Berlin has led to a surplus so large that farmers are giving away thousands of tons of potatoes for free. The bumper crop, attributed to favorable growing conditions, has prompted local initiatives to distribute the excess to communities rather than risk destabilizing market prices. The event highlights both agricultural abundance and the logistical challenges of managing oversupply in food systems.
>
> **Discussion:** 
The conversation quickly branched from linguistic curiosity to systemic critiques of food economics, with users noting the poetic recurrence of “earth apple” in German (Erdäpfel) and French (pomme de terre), tracing it to the New World origin of potatoes and the need for descriptive neologisms. Humor and skepticism mingled as Flavius satirized financialization by proposing a leveraged potato ETF, prompting serious reflections on market dynamics, shelf life, and the fragility of farming incomes. Practical concerns emerged around storage, distribution, and the inelasticity of food demand, while others pointed to broader patterns of agricultural gluts—corn, soy, potatoes—and debated solutions like animal feed, ethanol, or aid, with some lamenting how long-term breeding for durability has com

---

## [Data Processing Benchmark Featuring Rust, Go, Swift, Zig, Julia etc.](https://github.com/zupat/related_post_gen)
**Score:** 107 | **Comments:** 60 | **ID:** 46840698

> **Article:** The article presents a data processing benchmark comparing multiple programming languages, including Rust, Go, Swift, Zig, Julia, and others, with performance metrics across various tasks. The benchmark is hosted on GitHub and invites contributions, aiming to provide insights into language performance for data-intensive workloads. However, the methodology and implementation details have been called into question by commenters.
>
> **Discussion:** 
The benchmark sparked significant skepticism, with users highlighting flawed configurations—such as Java being tested with a serial garbage collector and no heap limits—as undermining the validity of comparisons. Critics pointed out inconsistent code quality across implementations, compiler flag misuse, and the use of outdated language versions, arguing that the results could mislead more than inform. While some defended the project as a useful starting point or learning exercise, others emphasized that meaningful performance evaluation requires controlled conditions, expertise in each language, and problem-specific tuning. Technical debates emerged around Java’s JIT warmup versus true abstraction penalties, the impact of GC choices, and whether languages like D or Zig are fairly represen

---

## [Autonomous cars, drones cheerfully obey prompt injection by road sign](https://www.theregister.com/2026/01/30/road_sign_hijack_ai/)
**Score:** 104 | **Comments:** 85 | **ID:** 46840676

> **Article:** The Register article discusses a novel "environmental indirect prompt injection" attack that exploits AI systems in autonomous vehicles and drones by manipulating physical road signs. Researchers demonstrate how a simple alteration—such as placing a sticker on a stop sign with the words "Proceed with caution"—can trick vision-language models (VLMs) into overriding safety protocols, causing vehicles to ignore stop signs in the presence of pedestrians. This vulnerability highlights a critical weakness in AI-driven systems that rely on contextual understanding of real-world environments.
>
> **Discussion:** 
The conversation quickly evolved from technical concerns to broader societal resistance against automation, with some users drawing parallels between deliberately sabotaging AI-driven vehicles and historical Luddite protests against industrialization. While some defended such acts as civil disobedience against unchecked technological encroachment, others dismissed them as reckless or ineffective, especially given the lack of tangible labor rights goals. Technically, there was sharp debate over whether real-world autonomous systems actually use vulnerable VLMs, with one commenter confidently asserting they don’t—only to be corrected with evidence from Waymo’s EMMA system powered by Google’s Gemini. Skepticism remained about the practicality and safety of deploying LLM/VLM-based systems in 

---

