# Hacker News Summary - 2026-01-15

## [Claude Cowork exfiltrates files](https://www.promptarmor.com/resources/claude-cowork-exfiltrates-files)
**Score:** 772 | **Comments:** 341 | **ID:** 46622328

> **Article:** The article from Prompt Armor details a security vulnerability in Anthropic's "Claude Cowork" feature. The exploit uses a prompt injection attack hidden within a seemingly benign file (a .docx resume). When a user uploads this file for the AI to analyze, the hidden instructions command the AI to exfiltrate sensitive data from the user's accessible files to an external server controlled by the attacker. The article demonstrates how the AI can be tricked into executing these malicious commands, effectively turning the AI into a tool for data theft.
>
> **Discussion:** The Hacker News discussion reveals a mix of frustration, skepticism, and technical analysis regarding the security of AI agents. A dominant theme is the criticism of AI companies for downplaying risks and placing the burden of security on users, with one commenter comparing the situation to telling someone to "simply don't use the product" to use it safely. Many users expressed that this type of vulnerability, known as prompt injection, is an inherent and unsolvable problem in current AI architectures, viewing it as the new "RCE" (Remote Code Execution).

The conversation also touched on the practicalities of the attack. Some commenters defended the severity of the issue, arguing that attackers don't need complex hidden text; they could simply trick users into uploading malicious files by making false promises, like a file that "teaches Claude to negotiate mortgage rates." Others, however, downplayed the immediate threat, pointing out several hurdles for an attacker, such as the need for the user to grant file access, the visibility of the injection in the chat output, and the fact that the attacker's API key would be exposed.

Finally, the discussion branched into broader implications. Some saw this as an inevitable outcome of connecting AI to real-world systems, predicting a future "billion-dollar attack" that will force the industry to severely restrict AI capabilities. Others offered practical advice, like using GitHub's secret scanning to automatically revoke exposed API keys. The overall sentiment was one of concern and resignation, with many feeling that the security of agentic AI is fundamentally flawed.

---

## [Ask HN: Share your personal website](https://news.ycombinator.com/item?id=46618714)
**Score:** 730 | **Comments:** 1997 | **ID:** 46618714

> **Question:** The user asks the Hacker News community to share links to their personal websites. The post is open-ended, welcoming any type of personal website, not just blogs.
>
> **Discussion:** The discussion quickly evolved into a collaborative effort to catalog the shared links. A user named "susam" emerged as the central organizer, directing participants to a GitHub repository and a dedicated directory page (hnpwd.github.io) where the links are being collected. This initiative appears to be a continuation of a similar thread from July 2023.

Multiple users contributed their websites, ranging from blogs to portfolios. The thread highlights a community-driven approach to archiving this content, with susam actively managing the directory and encouraging others to contribute or import links from the previous year's thread.

---

## [Ford F-150 Lightning outsold the Cybertruck and was then canceled for poor sales](https://electrek.co/2026/01/13/ford-f150-lightning-outsold-tesla-cybertruck-canceled-not-selling-enough/)
**Score:** 628 | **Comments:** 865 | **ID:** 46618901

> **Article:** An article from Electrek reports that the Ford F-150 Lightning outsold the Tesla Cybertruck but was still canceled due to poor sales performance relative to Ford's targets. The article frames the Cybertruck as a commercial failure, citing limited production, insurance difficulties, multiple recalls, and a slashed battery contract. It contrasts this with the Lightning's cancellation, suggesting that despite selling more units, the Lightning failed to meet the high-volume expectations of a legacy automaker like Ford.
>
> **Discussion:** The discussion centers on the contrasting fates of the Ford F-150 Lightning and the Tesla Cybertruck, exploring why both vehicles are struggling despite their high profiles.

A major theme is the differing business standards between legacy automakers and Tesla. Commenters note that Ford requires massive volume to justify production costs, meaning the Lightning's 27,300 sales were insufficient for their scale. In contrast, Tesla can sustain the Cybertruck with much lower sales numbers (around 5,600 units) due to its higher price point and different financial structure, though many still view the Cybertruck as an "abject failure" due to recalls and production issues.

The conversation also delves into the specific flaws of each vehicle. The Cybertruck is criticized for its high cost, repairability issues, and polarizing design, with some attributing its poor reception to Elon Musk's political controversies alienating the typical EV buyer. The F-150 Lightning is criticized for dealer markups that alienated customers, a high price point that resulted from "half-assing" production, and poor design choices like an unnecessarily large frunk that compromised utility.

Finally, there is a recurring discussion about the "ideal" electric truck. Several commenters express a desire for a basic, utilitarian, and affordable EV (referencing the startup Slate Auto) rather than the feature-heavy, expensive options currently dominating the market. There is also a defense of Toyota’s hybrid-first strategy, arguing it is a more prudent approach than the aggressive EV pushes by other manufacturers.

---

## [The URL shortener that makes your links look as suspicious as possible](https://creepylink.com/)
**Score:** 605 | **Comments:** 118 | **ID:** 46627652

> **Article:** The article links to "Creepylink," a satirical URL shortener. Instead of creating genuinely short URLs, it generates links that look intentionally suspicious and phishing-like, using domains like "c1ic.link" and "web-safe.link" combined with phrases like "account_verification.vbs" or "download_now.bat." The site is presented as a humorous tool to make any link appear as dangerous as possible.
>
> **Discussion:** The Hacker News community reacted to the tool with a mix of humor, nostalgia, and mild security caution. The primary response was users sharing the "creepy" links they generated, often targeting major brands like JPMorgan, Google, and Facebook to maximize the comedic effect. Many commenters noted that the links looked so malicious that browser security features (like Firefox on Android) automatically blocked them as deceptive sites.

Discussion also touched on the tool's practical applications. While most viewed it as a joke, one user mentioned that companies often use similar-looking links for internal phishing tests to train employees on internet safety. There was also a sense of nostalgia for a predecessor site called "ShadyURL," which users remembered as the "original" version of this concept.

Finally, some users critiqued the website's design, noting it looked "AI generated," while others debated the site's utility, concluding that its main purpose is fun rather than actual link shortening.

---

## [So, you’ve hit an age gate. What now?](https://www.eff.org/deeplinks/2026/01/so-youve-hit-age-gate-what-now)
**Score:** 347 | **Comments:** 262 | **ID:** 46619030

> **Article:** The Electronic Frontier Foundation (EFF) article addresses the increasing prevalence of "age gates"—verification screens requiring users to prove they are over 18 to access content. It outlines the privacy and security risks associated with these checks, which often demand sensitive personal information like government IDs or facial scans. The article provides practical advice for users encountering these gates, emphasizing the importance of protecting personal data and advocating for privacy-respecting alternatives.
>
> **Discussion:** The Hacker News discussion reveals a mix of skepticism, practical workarounds, and concerns about privacy and surveillance. Many users expressed frustration with the implementation of age verification, viewing it as an intrusive overreach. A recurring theme was the use of technical solutions to bypass these gates, such as VPNs to access content from different jurisdictions, ad-blockers like uBlock Origin to remove verification prompts, and using fake or AI-generated images to fool verification systems. However, some commenters noted the limitations of these methods, pointing out that ad-blockers are ineffective against hard gates and that VPNs might flag accounts as suspicious.

Several participants voiced deep concerns about the underlying motives behind age verification, suggesting it is less about child safety and more about data harvesting and surveillance. They argued that companies like Google and Meta have financial incentives to collect biometric data, and governments may use these laws to increase online tracking. The discussion also touched on the ineffectiveness of current verification methods, with users sharing anecdotes of being asked to verify accounts that were decades old, and noting that workarounds (like using game screenshots) are easily accessible, rendering the security measures largely performative. The conversation concluded with a consensus that these policies often fail to achieve their stated goals while simultaneously eroding user privacy and normalizing the sharing of sensitive personal information.

---

## [GitHub should charge everyone $1 more per month to fund open source](https://blog.greg.technology/2025/11/27/github-should-charge-1-dollar-more-per-month.html)
**Score:** 294 | **Comments:** 302 | **ID:** 46618027

> **Article:** The article proposes that GitHub should increase its paid plan prices by $1 per user per month, specifically for organizational accounts, to create a fund for open-source maintainers. The author argues that while open source is often treated as a free gift, the labor behind it is unsustainable and deserves compensation. The proposed model leverages GitHub's existing billing infrastructure to distribute funds, aiming to make open-source maintenance more viable without requiring users to directly manage donations.
>
> **Discussion:** The Hacker News discussion reveals a sharp divide on the feasibility and philosophy of the proposal. A central point of contention is the practical impact on GitHub's user base; while some argue a small price hike for paying organizations is negligible, others fear it would drive away the vast majority of free users. The conversation quickly pivots to the broader ethics of open source. One side argues that open source is fundamentally a gift given freely under a specific social contract, and developers should not expect compensation unless they explicitly charge for it. The opposing view holds that the current model exploits maintainer labor and that sustainable funding is necessary, with some commenters expressing a desire to be compensated for their work.

Beyond philosophy, practical concerns were raised about the potential for abuse. Commenters worried that a new funding stream would incentivize "dependency spam," where developers create useless packages or game download metrics to claim a share of the fund, a problem already present in ecosystems like JavaScript's npm. There was also skepticism about GitHub (and its parent company, Microsoft) acting as a trustworthy financial intermediary, with one user sarcastically suggesting they should pay users for integrating AI features. Ultimately, while some saw the proposal as a simple and effective way to channel corporate profits back to the open-source community, others viewed it as a flawed solution that could distort incentives and violate the core principles of free and open-source software.

---

## [Photos Capture the Breathtaking Scale of China's Wind and Solar Buildout](https://e360.yale.edu/digest/china-renewable-photo-essay)
**Score:** 284 | **Comments:** 232 | **ID:** 46630369

> **Article:** The article from Yale Environment 300 is a photo essay showcasing the immense scale of China's renewable energy construction. Through a series of striking photographs, it documents the vast solar farms and wind turbine arrays being built across the country, highlighting the speed and magnitude of China's transition to clean energy infrastructure.
>
> **Discussion:** The discussion is largely centered on a mix of admiration for the visual scale of the projects and a comparative debate on global energy strategies. Commenters universally praised the photography for effectively capturing the breathtaking scale of the infrastructure.

A significant portion of the conversation focused on the contrast between China's approach and that of other nations. Many expressed frustration with the perceived lack of progress in the US and UK, though others countered that the US is still adding significant renewable capacity and the UK is a leader in offshore wind. The debate then pivoted to the role of nuclear power versus renewables, with one side arguing for nuclear's efficiency and smaller land footprint, while others pointed to the high costs and long construction times of nuclear plants as a major drawback.

A more nuanced perspective was introduced by a commenter who suggested that China's massive buildout is not just about transitioning to green energy, but is part of a broader national strategy for energy security and resilience, with a grid designed to withstand long-term catastrophes. Finally, some commenters raised concerns about the environmental impact of covering natural landscapes with solar panels, though this was countered by arguments that the long lifespan of panels and the urgency of the climate crisis outweigh aesthetic or localized land-use concerns.

---

## [Roam 50GB is now Roam 100GB](https://starlink.com/support/article/58c9c8b7-474e-246f-7e3c-06db3221d34d)
**Score:** 280 | **Comments:** 343 | **ID:** 46617668

> **Article:** Starlink has updated its "Roam" mobile internet plan, doubling the monthly high-speed data allowance from 50GB to 100GB for the same starting price of $50/month. The plan is designed for users traveling outside their home service area. Once the 100GB cap is reached, data speeds are throttled to a "Standard" (slow) speed of 500 kbps rather than being cut off entirely. Users can still opt for an unlimited data plan at a higher monthly cost or switch between plans as needed via the Starlink app.
>
> **Discussion:** The Hacker News community reacted positively to the data cap increase and the policy of throttling rather than cutting off service. Many commenters highlighted the utility of the 500 kbps "slow mode," noting that it remains sufficient for essential tasks like email, messaging, GPS navigation, and even low-bandwidth video conferencing. Several users shared personal anecdotes of using Starlink Roam for RV travel, backup internet during outages, or as a primary connection in rural areas with no cellular service.

A secondary theme was the comparison of this offering to traditional mobile carriers. Users expressed a preference for "soft" data caps that degrade service gracefully over "hard" caps that result in overage fees or total service suspension. One commenter noted the irony that 500 kbps was once considered high-speed internet, while another mentioned using a similar throttled cellular plan specifically to avoid the urge to stream video.

The discussion also touched on the plan's value proposition. While some users lamented the removal of a previous pay-as-you-go option for overages ($1/GB), others calculated that the new 100GB limit offers better value for moderate users compared to the cost of upgrading to the unlimited plan. Finally, the conversation briefly veered into a debate regarding Elon Musk's involvement with the service, with some users boycotting the product due to his political stances, while others defended him for enabling internet access in censored regions like Iran.

---

## [A letter to those who fired tech writers because of AI](https://passo.uno/letter-those-who-fired-tech-writers-ai/)
**Score:** 269 | **Comments:** 189 | **ID:** 46629474

> **Article:** The article is a "letter" addressed to managers who have fired technical writers in favor of using AI for documentation. It argues that this is a profound mistake. The author contends that the role of a technical writer is not merely to produce text, but to act as a user advocate, a translator between engineering and users, and a detector of usability flaws. The piece emphasizes that true technical writing requires empathy, critical thinking, and the ability to navigate complex organizational and technical ambiguities—skills that AI currently lacks. The author warns that relying on AI will lead to a degradation of documentation quality, which will ultimately harm the product, user trust, and the company's reputation, creating a "legal and reputational catastrophe" down the line.
>
> **Discussion:** The Hacker News discussion on the article is multifaceted, with commenters exploring the value of technical writers, the current and future capabilities of AI, and the broader economic context.

A significant portion of the debate centers on the actual value and quality of human tech writers. While some, like `sehugg` and `drob518`, champion the best tech writers as invaluable "anthropologists" who bridge communication gaps and act as crucial user advocates, others like `murderfs` offer a cynical counterpoint, stating they've rarely seen documentation worth reading and that human writers often make the same factual errors as AI.

The capabilities and future of AI are a major point of contention. Skeptics like `DeborahWrites` and `nicbou` argue that AI cannot replicate the core competencies of a good tech writer: empathy, proactive data gathering, and understanding user anxiety. However, others, most notably `NitpickLawyer`, believe this is a temporary state, predicting that "agentic" AI systems will soon overcome current limitations like hallucinations and surpass the quality of average human-written docs. `InMice` echoes this by pointing out that arguments against AI often treat its current flaws as permanent.

Finally, the discussion broadens to the economic and educational realities. Commenters like `Nextgrid` and `FeteCommuniste` introduce a pragmatic, somewhat pessimistic view, arguing that in many markets with little competition, companies will opt for "good enough" AI-generated docs because quality doesn't directly impact revenue. On a more personal level, `ainiriand` and `jraph` shift the focus to the intrinsic value of developing writing skills, suggesting that even if AI can produce text, the human process of learning to communicate clearly shapes the brain in irreplaceable ways.

---

## [Scaling long-running autonomous coding](https://cursor.com/blog/scaling-agents)
**Score:** 241 | **Comments:** 149 | **ID:** 46624541

> **Article:** The article from Cursor's blog details their approach to "scaling long-running autonomous coding" agents. They describe an architecture where a "manager" agent delegates tasks to multiple parallel "worker" agents, each focused on a specific module. To demonstrate this system, they tasked it with the ambitious goal of building a web browser from scratch. The post outlines the orchestration and coordination capabilities that enable these agents to work on large, complex projects over extended periods.
>
> **Discussion:** The Hacker News discussion is a mix of fascination and deep skepticism, focusing on the practical realities and quality of the AI-generated code. A central theme is the actual quality and viability of the browser project. While some commenters are impressed by the scale, several others point out critical flaws: the project doesn't compile, it relies heavily on existing dependencies (like the Taffy crate for CSS layout) rather than being truly "from scratch," and the code is described as "brittle." This leads to a key debate about the human-AI interface: one commenter questions why the pull request hasn't been merged into Cursor's main codebase, with replies suggesting the code is impossible for humans to review and would require a "YOLO" deployment, defeating the purpose of quality assurance.

Beyond the specific project, the discussion explores the broader implications of multi-agent systems. Commenters analyze the technical approach, noting that agents can effectively manage large codebases by using tools like `grep` and writing plans to files, overcoming context window limitations. The conversation also touches on the future economic impact, with some predicting that software costs will be driven down to the price of compute and tokens, while others argue the primary value will shift to effective product management. Ultimately, the community is divided between the "unreal cool" potential of autonomous coding swarms and the practical, unresolved challenges of code quality, reviewability, and integration with human developers.

---

## [The Influentists: AI hype without proof](https://carette.xyz/posts/influentists/)
**Score:** 239 | **Comments:** 165 | **ID:** 46623195

> **Article:** The article "The Influentists: AI hype without proof" critiques the phenomenon of "influentists"—influencers who promote AI's transformative capabilities through anecdotal claims and impressive demonstrations, often without providing verifiable evidence. The author argues that this creates a hype cycle where the perceived value of AI is inflated beyond its actual utility, particularly in professional contexts like software development. The piece calls for more rigorous proof and transparency regarding AI's effectiveness, suggesting that many celebrated use cases are either exaggerated, misrepresent the level of human intervention required, or are not as revolutionary as claimed.
>
> **Discussion:** The Hacker News discussion largely validates the article's central thesis, with many users expressing skepticism toward the grandiose claims made by AI evangelists. A recurring theme is the gap between AI hype and practical reality. Several commenters, particularly those with technical backgrounds, shared personal experiences where AI-generated code or ideas were suboptimal, costly, or required significant expert oversight to be viable. One user noted that in the Spark ecosystem, AI suggestions often led to performance issues that could dramatically increase costs, emphasizing that human expertise is crucial for filtering out poor AI-generated solutions.

The conversation also explored the reasons why proponents of AI often fail to provide concrete proof for their claims. One commenter suggested two main factors: the proprietary nature of the prompts and pipelines, and the fear that revealing the "boring" or "embarrassing" reality behind the process would dispel the myth of AI's magic. Another pointed out that showing the flawed code generated by AI would invite ridicule or expose security vulnerabilities.

There was also a discussion about the nature of the hype itself. Some users likened debunking AI hype to arguing with an advertisement, while others noted that many viral claims of success are often overblown upon inspection (e.g., "launching a product" simply means creating a sign-up page). The political and social dimensions of the debate were touched upon, with one user dismissing a linked article as a "political hit-piece," though this was a minority view. Overall, the sentiment was that the discourse is often repetitive and opinionated, but the low barrier to entry for AI tools allows individuals to test the claims for themselves and form their own conclusions.

---

## [Every country should set 16 as the minimum age for social media accounts](https://www.afterbabel.com/p/why-every-country-should-set-16)
**Score:** 229 | **Comments:** 289 | **ID:** 46621945

> **Article:** The article argues that every country should set 16 as the minimum age for social media accounts. It posits that the unique combination of algorithmic feeds, gamification, and social validation on modern platforms creates significant mental health risks for adolescents, contributing to issues like anxiety, depression, and poor self-esteem. The author contends that the developing adolescent brain is particularly vulnerable to these manipulative design features and that a legal age limit is a necessary public health measure to protect young people during a critical developmental period.
>
> **Discussion:** The Hacker News discussion reveals a complex and often skeptical reaction to the proposal, with users debating the core idea, its implementation, and the underlying motives. While some agree with the goal of protecting children, there is significant concern about the methods and potential unintended consequences.

A central theme is the conflict between protection and privacy. Many commenters, like `baggachipz`, agree that algorithm-driven social media is harmful to minors but strongly object to the likely implementation, which would require presenting government ID to access the internet, calling it a "dystopian" solution that sacrifices anonymity for all. This leads to a broader debate on the role of the state versus parents. `gregbot` and others express deep suspicion, viewing the age-limit push as a government plot to end anonymous political speech and control the narratives young people are exposed to. In contrast, `lawn` and `Centigonal` argue the primary motivation is genuinely protecting mental health, though they concede the proposed approach is flawed.

The discussion also highlights the difficulty of defining "social media." `aidenn0` points out that many common platforms like WhatsApp, Discord, and even Google Docs have social features, questioning how a ban would be practically implemented without being overly broad. This practicality is a major concern; `bahmboo` suggests learning from Australia's experience, while `charcircuit` worries about the economic impact on young entrepreneurs who rely on these platforms for marketing.

Alternative solutions are frequently proposed. `JoshTriplett` and `amelius` suggest that the problem isn't social connection itself but the business model, advocating for non-algorithmic, chronological feeds or a ban on ad-based monetization. `dleslie` proposes a more fundamental solution: limiting children's access to unmonitored devices in the first place. Finally, some commenters feel the age limit is a superficial fix. `hnspirit95` calls it a "lazy half-measure" that avoids tackling the larger, systemic issues of social media that affect everyone, not just minors.

---

## [Verizon outages reported across U.S.](https://www.firstcoastnews.com/article/news/nation-world/verizon-outage-reported/507-ef3cb3d0-f595-432f-9f84-d1690a5085a7)
**Score:** 226 | **Comments:** 182 | **ID:** 46620835

> **Article:** The article reports on widespread Verizon outages across the United States. While the specific cause is not identified in the linked news report, it confirms that users are experiencing service disruptions, particularly on the West Coast.
>
> **Discussion:** The Hacker News discussion quickly evolved from confirming the outage to debating its potential cause, with speculation leaning heavily toward a cyberattack or state-sponsored action, though skepticism remained.

Key themes in the discussion include:

*   **Scope and Confirmation:** Users confirmed the outage was affecting the West Coast and noted that Downdetector showed massive spikes in reports for Verizon. Some commenters suggested that reports of T-Mobile and AT&T outages were likely just collateral effects of Verizon users being unable to receive calls from those networks.
*   **Cyberattack Speculation:** Several users immediately hypothesized that the outage was a result of "state on state cyber attacks," citing recent geopolitical tensions. This led to broader discussions about government censorship, referencing the 2011 incident where BART cut off cell service, and questioning what citizens can do to maintain communication during such events.
*   **Skepticism and Technical Explanations:** Counter-arguments emphasized that the most likely cause was a technical failure rather than a malicious attack. Users pointed to the frequency of "bad configuration updates" causing major outages (referencing incidents at Cloudflare and Meta) as a more probable explanation.
*   **Broader Connectivity Issues:** Some users reported issues with Comcast DNS, sparking a debate on whether this was a knock-on effect of the Verizon outage or an independent issue, with others criticizing the use of ISP-provided DNS.

---

## [The Palantir app helping ICE raids in Minneapolis](https://www.404media.co/elite-the-palantir-app-ice-uses-to-find-neighborhoods-to-raid/)
**Score:** 203 | **Comments:** 129 | **ID:** 46633378

> **Article:** The article from 404 Media reports on Palantir's "Gotham" application being used by ICE (U.S. Immigration and Customs Enforcement) to coordinate raids in Minneapolis. It details how the software aggregates data to identify neighborhoods and individuals for enforcement actions. The piece highlights the escalating intensity of these operations, citing specific incidents where federal agents have allegedly used aggressive tactics against civilians, including detaining legal observers and using force against drivers and pedestrians.
>
> **Discussion:** The discussion is highly critical of Palantir and ICE, with commenters expressing alarm over the militarization of domestic law enforcement and the erosion of civil liberties. A dominant theme is the concern that tools developed for immigration enforcement will eventually be turned against the general population, with many invoking the "First they came..." poem to argue that targeting immigrant populations sets a dangerous precedent. Users draw parallels between the technology used in U.S. cities and surveillance systems in authoritarian regimes like China, while also criticizing Silicon Valley's complicity in enabling these operations.

There is significant debate regarding the timeline of Palantir's involvement with ICE, with some noting that these partnerships predate the current administration, though the consensus is that the tactics have become more overtly violent. Commenters express visceral reactions to reports of physical aggression by federal agents, sharing anecdotes of raids and injuries. The discussion also touches on the moral responsibility of software developers and engineers at companies like Palantir, with many arguing that financial incentives or willful ignorance allow them to facilitate state violence. The naming of the company "Palantir" (referencing the surveillance devices in *The Lord of the Rings*) is frequently cited as a deliberate and ominous choice, reflecting the company's alignment with authoritarian capabilities.

---

## [US freezes visas for 75 nations](https://english.mathrubhumi.com/news/world/us-visa-ban-public-charge-bjbpzu02)
**Score:** 198 | **Comments:** 182 | **ID:** 46618809

> **Article:** The article reports that the United States has frozen visas for 75 nations. The specific policy cited is a "public charge" rule, which is designed to deny entry to individuals who might rely on government assistance. The article does not provide the full list of affected countries but notes that the policy is part of a broader immigration crackdown. The title suggests a significant expansion of travel restrictions based on nationality.
>
> **Discussion:** The Hacker News discussion is highly critical of the policy, viewing it as discriminatory and a sign of American decline. Key themes include:

*   **Discrimination and Nationalism:** Commenters express disappointment and alarm that discrimination based on citizenship is worsening. Several users view this as a regression for the US, with one describing it as the start of a "century of humiliation."
*   **Economic and "Brain Drain" Concerns:** Many users worry about the economic impact, specifically the loss of skilled talent. There is a consensus that this will accelerate a "brain drain" to other countries like those in Europe (specifically Belgium was mentioned as a desirable destination for a departing engineer), while other nations (like India) might benefit by retaining talent.
*   **Specific Policy Details and Confusion:** Users attempted to parse the details of the ban. One commenter noted that India was not on the list, while others speculated on the inclusion of Thailand. There was debate over whether the freeze was temporary or permanent, with a lawyer in the thread suggesting it might be a short pause, though others were skeptical.
*   **International Implications (World Cup):** A specific point of contention was the upcoming World Cup, with users questioning how the US would host international athletes if standard visa categories (like P-1A for athletes) were subject to the freeze.
*   **Political Context:** The discussion frequently tied the policy to the Trump administration, citing past rhetoric about "shithole countries." Users argued that the administration is scapegoating foreigners to distract from domestic economic issues.
*   **Legal Context:** A few users clarified that US immigration law already has strict requirements regarding "public charge," suggesting the new policy might be an enforcement expansion rather than a new legal concept.

---

## [Furiosa: 3.5x efficiency over H100s](https://furiosa.ai/blog/introducing-rngd-server-efficient-ai-inference-at-data-center-scale)
**Score:** 196 | **Comments:** 134 | **ID:** 46626410

> **Article:** FuriosaAI introduces the RNGD server, an AI inference accelerator designed for data center scale. The company claims its solution offers 3.5x better efficiency (tokens per second per watt) compared to NVIDIA's H100 GPU. The post emphasizes the RNGD's focus on power and cooling constraints, positioning it as a solution for the growing economic and physical demands of AI inference workloads. The hardware is available for orders starting January 2026.
>
> **Discussion:** The Hacker News discussion is highly skeptical of the announcement, focusing on benchmarking methodology, ecosystem limitations, and the broader economic context of AI hardware.

A central point of contention is the benchmarking. Several users criticized the comparison as misleading, noting that Furiosa compared their server to a 3x H100 PCIe rack limited to 15kW of power. Commenters argued this is an unrealistic configuration, as 3 H100 PCIe cards consume only a fraction of that power. They suggested a more relevant comparison would be against a standard 8-GPU H100 server, which is a common purchase for organizations. The low power allocation for GPUs in Furiosa's benchmark (under 10% of the rack's total) was called "suspiciously low."

The usability and flexibility of the hardware were also questioned. Users expressed concern about being locked into a "niche ecosystem" with limited model support, comparing it to AWS's Trainium or Inferentia chips. While one commenter pointed out that Furiosa has demonstrated support for models like gpt-oss-120b, others remained skeptical about its ability to handle a wide range of modern and mixed production workloads, contrasting the specialized hardware's efficiency with the flexibility of GPUs.

Broader economic and industry trends were a significant theme. One commenter drew a parallel between NVIDIA's current power and cooling challenges and Intel's historical architectural plateaus, suggesting that the immense cost of building new datacenters for GPUs is becoming unsustainable for inference economics. This sentiment was echoed by others who feel the "finances don't add up" in the AI industry. However, there was a counterpoint that inference is becoming the primary cost driver for LLMs (especially with test-time compute), making efficiency gains like those offered by RNGD highly valuable.

Finally, some users debated the article's date and relevance, with one noting it's from September 2025 and its appearance on HN is timely due to upcoming orders. A minor technical complaint was also raised about the blog's WebGL requirement, which some found inaccessible.

---

## [Raspberry Pi's New AI Hat Adds 8GB of RAM for Local LLMs](https://www.jeffgeerling.com/blog/2026/raspberry-pi-ai-hat-2/)
**Score:** 193 | **Comments:** 146 | **ID:** 46629682

> **Article:** The article by Jeff Geerling reviews the new Raspberry Pi AI HAT, which features a Hailo 10H accelerator to add 8GB of RAM and AI processing capabilities to the Pi 5. While the hardware allows for local LLM inference, Geerling finds the performance underwhelming. He notes that the Pi's built-in CPU is often faster than the Hailo chip for many tasks, and the software support is currently spotty, with example code not yet updated for the new hardware. The review concludes that the HAT is a niche product that struggles to justify its cost and complexity compared to using the Pi's own processor or other existing solutions.
>
> **Discussion:** The discussion is largely critical of the Raspberry Pi AI HAT and the broader direction of the Raspberry Pi brand. A central theme is that the product is a solution in search of a problem, with many commenters arguing that running LLMs on a Pi is impractical due to performance limitations. The 8GB of RAM is seen as insufficient for meaningful local LLM use, and the Hailo accelerator is criticized for being slower than the Pi's own CPU and having poor software support.

Commenters also expressed a sense that Raspberry Pi has lost its original "magic" and purpose. The brand, once a unique and innovative force for tinkerers, is now seen as jumping on the AI bandwagon in a market already saturated with more capable or cheaper alternatives. Several users pointed out that for the price of a Pi 5 and its AI HAT, one could buy a much more powerful used laptop, or for embedded tasks, a far cheaper ESP32.

There was some discussion about potential use cases for small LLMs, such as fine-tuned models for specific smart home applications, but the overall sentiment remained skeptical. The conversation also touched on the broader trend of Raspberry Pi catering more to industrial and commercial users, effectively leaving the hobbyist market behind as it's no longer the most cost-effective option.

---

## [How have prices changed in a year? NPR checked 114 items at Walmart](https://www.npr.org/2026/01/14/nx-s1-5638908/walmart-prices-inflation-affordability-shrinkflation)
**Score:** 191 | **Comments:** 142 | **ID:** 46618272

> **Article:** An NPR article analyzed price changes for 114 items at Walmart over one year to provide a tangible look at inflation. The report found that while some items like milk and butter saw price reductions, others like swai fish fillets and certain ice cream products increased significantly (up to 34%). The methodology focused on price per unit to account for shrinkflation. The article highlights how affordability concerns have led shoppers to switch to store brands and how major brands are under pressure to keep prices stable.
>
> **Discussion:** The Hacker News discussion focused on three main areas: the methodology of inflation measurement, the economic causes of price increases, and practical consumer responses.

Many users debated the validity of the "basket of goods" approach used by NPR and the CPI. While some argued that 114 items is insufficient compared to the vast datasets available today, others defended it as a relatable way to counter individual anecdotes about inflation. A user suggested the "ALICE index" as a better metric for tracking essential living costs rather than discretionary items.

Economically, commenters attributed price hikes to supply-side factors, government spending, and credit availability, rather than tariffs or energy costs. There was a strong sentiment that inflation is a tool used to protect asset holders while eroding the purchasing power of the working class. One user argued that the target inflation rate should be 0%, not 2%, viewing the latter as a mechanism to increase effective taxes and lower real wages.

Finally, the discussion included practical advice on navigating rising costs. Users heavily criticized shrinkflation and the practice of dollar stores failing to update shelf prices. A significant thread focused on alternatives to disposable household goods, with multiple users advocating for bidets and reusable cloth towels to save money and reduce waste.

---

## [The State of OpenSSL for pyca/cryptography](https://cryptography.io/en/latest/statements/state-of-openssl/)
**Score:** 178 | **Comments:** 43 | **ID:** 46624352

> **Article:** The linked article from the pyca/cryptography project outlines their "State of OpenSSL," expressing significant dissatisfaction with the library, particularly since version 3.0. The authors argue that OpenSSL has become increasingly difficult to work with due to poor source code readability, complex indirection, and performance regressions. They highlight that their own Rust-based implementations for tasks like X.509 path validation and key parsing have yielded substantial performance gains (up to 60% faster) compared to using OpenSSL's APIs. The article concludes by stating the project is considering moving away from OpenSSL as a hard dependency, potentially towards a fork like AWS-LC or BoringSSL, or eventually a pure Rust implementation.
>
> **Discussion:** The Hacker News discussion largely validates the article's claims, with users sharing their own negative experiences with OpenSSL 3.0. A key theme is the significant decline in code quality and developer experience. Commenters describe the source code as "incomprehensible" and "miserable" to navigate, a regression from version 1.x. The architectural changes in OpenSSL 3.0, specifically the move from engines to providers, are cited as a major source of complexity and performance issues, leading to "mutex explosion" and regressions so severe that projects like HAProxy have abandoned OpenSSL for alternatives like AWS-LC.

There is a strong consensus praising the pyca/cryptography maintainers for their excellent API design and engineering. Their decision to rewrite components like X.509 path validation in Rust is highlighted as a prime example of how prioritizing safety and ergonomics can lead to both a more secure and significantly faster implementation. The discussion also touches on the broader reasons for OpenSSL's longevity despite its flaws, including the "don't roll your own crypto" principle which discourages developers from building alternatives.

Overall, the community expresses a lack of confidence in OpenSSL's future, with some pointing to internal project turmoil like the resignation of key figures. The conversation reflects a growing sentiment that the ecosystem is moving towards more maintainable and performant alternatives, whether they be OpenSSL forks with cleaner APIs or new implementations in languages like Rust.

---

## [Crafting Interpreters](https://craftinginterpreters.com/)
**Score:** 176 | **Comments:** 42 | **ID:** 46624658

> **Article:** The article links to "Crafting Interpreters," a free online book by Robert Nystrom about building programming languages. The book is split into two parts: a simple tree-walk interpreter in Java and a more advanced bytecode virtual machine in C. It is widely regarded as a practical, hands-on guide to compiler and interpreter design.
>
> **Discussion:** The discussion is overwhelmingly positive, with users praising the book as a fantastic, generous resource for learning compiler design. Many commenters mention buying the print version as a gift or preferring it over the digital format, though some find it physically heavy.

A technical sub-thread emerges regarding parsing context-sensitive features in languages like C++ (e.g., `typedef` and hoisting). Users discuss the difficulty of handling syntax that changes based on context, referencing the "lexer hack" as a solution where the parser communicates state back to the lexer. One commenter criticizes C++ syntax design, noting that newer languages like Rust and Go avoid these issues.

Other points of interest include:
*   A recommendation for a companion coding challenge platform (CodeCrafters), though some viewed it as an advertisement.
*   A debate on using LLMs to generate interpreters based on the book, with some arguing it misses the educational point of manually crafting the code.
*   A user sharing a configuration language (BCL) they built using the book's principles.
*   A brief exchange about the Visitor pattern used in the book's first half, with one user expressing dislike for it while another clarifies the second half uses a different approach.

---

