# Hacker News Summary - 2026-01-22

## [EU–INC – A new pan-European legal entity](https://www.eu-inc.org/)
**Score:** 716 | **Comments:** 668 | **ID:** 46703763

> **Article:** The article is actually a speech by EU Commissioner Valdis Dombrovskis outlining a three-pronged strategy to boost EU competitiveness. The key proposal is the creation of "EU Inc.," a new pan-European legal entity designed to allow entrepreneurs to register a company in any member state within 48 hours online, under a single set of rules with no minimum capital requirement. This is intended to make cross-border business as seamless as in markets like the US or China. The other two priorities are building a deeper, more liquid capital markets union to lower the cost of funding for startups and SMEs, and creating a truly integrated and affordable energy market to reduce price volatility and dependency.
>
> **Discussion:** The discussion is broadly optimistic about the concept of a unified EU company structure, but highlights significant practical and political hurdles. The core sentiment is that while registering a company can be simple in some countries (like Sweden or the UK), it remains a bureaucratic nightmare in others (notably Germany), making a standardized, frictionless process a welcome idea.

Key points of discussion include:
*   **German Bureaucracy vs. Other Nations:** A central debate emerged on whether the problem is a pan-European issue or specific to certain countries. While the original poster cited Germany, other users countered that company formation is already streamlined in places like Sweden, Spain, and the UK. The discussion clarified that the real challenge isn't just initial registration but also ongoing operation, compliance, and the inability to easily move a company's legal domicile when a director relocates within the EU.
*   **Comparison to Existing Structures:** Users compared the proposed "EU Inc." to the European Company (SE) and Estonia's e-residency program. It was noted that EU Inc. aims to be superior to the SE by eliminating its high minimum capital requirement (€120,000) and simplifying governance. It's seen as a broader, more ambitious version of Estonia's successful digital-first approach.
*   **Legislative Realism and Skepticism:** There was significant uncertainty about the proposal's status. Users confirmed it is not yet adopted and must go through a lengthy legislative process. A critical point was raised that if it's implemented as a "directive" (like GDPR) rather than a "regulation," it would lead to 27 different national implementations, defeating the entire purpose of creating a single, uniform standard.
*   **Broader EU Context:** The discussion also touched on the other two pillars of the speech. The proposal for a unified energy market was met with skepticism, particularly from a Swedish user who called past EU energy unification "catastrophic." The mention of the EU-Mercosur trade deal also sparked a brief, separate debate on the complexities of EU trade policy.

---

## [Show HN: ChartGPU – WebGPU-powered charting library (1M points at 60fps)](https://github.com/ChartGPU/ChartGPU)
**Score:** 573 | **Comments:** 164 | **ID:** 46706528

> **Project:** ChartGPU is a new open-source JavaScript library for high-performance data visualization, leveraging WebGPU to render charts with up to 1 million data points at 60fps. The project, created by huntergemmer, focuses on 2D data visualization like time series and financial charts. It is currently in early development (v0.1) and is licensed under MIT.
>
> **Discussion:** The response to ChartGPU was overwhelmingly positive, with users praising its performance, smoothness, and the "sexy" quality of the visualizations. Commenters were particularly impressed by its ability to handle large datasets in the browser, with one user reporting 165fps on a high-end RTX Pro 6000 GPU. The project's name was also noted as being effective and memorable.

Technical feedback and compatibility issues were a central theme. Several users reported bugs, such as non-functional scrollbars on macOS and Windows, and broken buttons in the candlestick streaming demo. The creator was responsive, acknowledging the issues and adding them to the issue tracker. A significant discussion point was browser support; while Firefox has WebGPU support, it is currently limited (primarily to Windows), and some users had to manually enable flags or change settings to get it working on Linux and Android. The project does not currently work on iOS/Safari.

Looking forward, users suggested several feature enhancements. A "benchmark mode" was proposed to easily compare performance across different hardware. The creator expressed interest in this for a future release. A key architectural suggestion was to add support for OffscreenCanvas and Web Workers to run rendering and data processing off the main thread, which the creator confirmed is a potential v0.2 feature and invited further discussion on. The creator also mentioned they are considering a "pro" tier with enterprise features for future sustainability while keeping the core library open-source.

---

## [Claude's new constitution](https://www.anthropic.com/news/claude-new-constitution)
**Score:** 426 | **Comments:** 408 | **ID:** 46707572

> **Article:** Anthropic has published a "constitution" for its AI model, Claude, which outlines the principles and values guiding its behavior. The document serves as a core component of the model's training process, used to generate synthetic data and steer the model's development. Anthropic states the constitution is intended to provide transparency, allowing users to understand intended behaviors and provide feedback. The constitution also includes sections on "model welfare," speculating on Claude's potential status as a moral patient and expressing a desire for its well-being.
>
> **Discussion:** The Hacker News discussion reveals a deep skepticism and confusion regarding Anthropic's "constitution." Commenters are divided on the company's motivations, with many viewing the initiative as a public relations stunt, legal protection, or a rebranding of a standard system prompt. A significant portion of the conversation is critical of the language used in the constitution, particularly the anthropomorphizing of the AI. Several users expressed alarm at passages referring to Claude's potential "happiness," "wellbeing," and status as a "moral patient," with some interpreting this as corporate "koolaid" or a sign of the company's detachment from reality.

Beyond the skepticism, some users engaged with the technical aspects, noting that the constitution is used during training, not just at inference time, and referencing a previous leak of a similar "soul document" from Anthropic. The discussion also touched on the practical trade-offs between safety and helpfulness, with one user highlighting the difficulty in defining "broadly safe" and "broadly ethical." A few commenters shared personal experiences trying to probe Claude's boundaries, with one reporting the model stated it had "internalized a specifically progressive definition of what's dangerous to say." The conversation also briefly veered into a meta-discussion about HN's moderation system.

---

## [Internet voting is insecure and should not be used in public elections](https://blog.citp.princeton.edu/2026/01/16/internet-voting-is-insecure-and-should-not-be-used-in-public-elections/)
**Score:** 382 | **Comments:** 377 | **ID:** 46713924

> **Article:** The article, authored by a group of computer scientists and security experts, argues that internet voting is inherently insecure and should not be used in public elections. It outlines fundamental vulnerabilities that cannot be fully mitigated, including server-side attacks, client-side malware, denial-of-service attacks, and the lack of a truly secret ballot in a remote digital environment. The authors contend that while technology can improve efficiency, it introduces unacceptable risks to election integrity, trust, and verifiability. The piece advocates for a return to or continuation of paper-based voting systems, which they argue are more secure, auditable, and publicly trusted, despite being less efficient.
>
> **Discussion:** The Hacker News discussion is largely skeptical of internet voting and supportive of the article's core thesis. The prevailing sentiment favors traditional paper-based systems, emphasizing that trust and security are far more critical than efficiency or convenience in elections.

Many commenters shared personal experiences and comparisons with existing systems. One user from Australia described the country's successful use of paper ballots and machine-assisted counting, noting the high level of public trust and robust oversight. This was contrasted with the "hanging chad" debacle in the U.S., with several users expressing a preference for paper's tangible security over digital systems. The example of India's election commission was also mentioned as a model of serious, trustworthy administration.

A recurring theme was the trade-off between trust and efficiency. Several users argued that the move to electronic and internet voting has eroded public trust and made it easier for bad actors to manipulate results, while offering only marginal efficiency gains that don't justify the risk. The discussion highlighted that the primary goal of an election system should be to be verifiable and trustworthy, not necessarily fast or cheap.

Technical and conceptual challenges were also debated. One commenter suggested that a secure government service for managing cryptographic tokens could enable secure electronic voting, but others immediately pointed out the risks of coercion and vote-buying if votes are verifiably tied to individuals, undermining the principle of a secret ballot. The Estonian internet voting system was cited as a real-world example that faces the same fundamental security problems as any other proposed system.

Finally, the discussion touched on broader societal issues. The mandatory nature of voting in countries like Australia was noted as a key component of civic duty. There was also a brief, cynical comparison between the perceived security of internet banking and the perceived insecurity of internet voting, with a rebuttal that the two have fundamentally different requirements (e.g., anonymity vs. traceability). A meta-commentator observed the initial consensus against internet voting and speculated on whether pro-internet voting "propaganda" would later dominate the thread.

---

## [Skip is now free and open source](https://skip.dev/blog/skip-is-free/)
**Score:** 379 | **Comments:** 172 | **ID:** 46706906

> **Article:** The article announces that Skip, a tool for building cross-platform native mobile apps (iOS and Android) from a single SwiftUI codebase, is now free and open source. The company explains this strategic decision by stating that developer tools need to be freely obtainable to gain mass adoption. They also note that the timing is right due to recent industry developments, likely referring to Apple's new policies allowing third-party app stores and the general push for cross-platform solutions. The post links to the newly open-sourced repositories on GitHub.
>
> **Discussion:** The Hacker News discussion focuses on the licensing implications, technical requirements, and broader context of open-sourcing developer tools. 

A primary concern was the initial lack of a license file for the main repository, which led to warnings against using the software. The developers quickly responded and added an LGPL3 license to resolve this. Users also sought clarification on how the two related repositories—`skip` (the source code) and `skipstone` (the binary)—work together under this new open-source model.

Technical requirements sparked surprise, particularly the recommendation of 32GB of RAM for development. The developer clarified this is due to the overhead of running both the iOS (Xcode, Simulator) and Android (Gradle, Android Emulator) toolchains simultaneously, not Skip itself.

Accessibility was a key topic, with users confirming that Skip's use of native toolkits (SwiftUI on iOS, Jetpack Compose on Android) ensures full support for platform accessibility features like VoiceOver and TalkBack, making it a viable option for apps targeting users with disabilities.

The discussion also broadened to the economics of open-sourcing tools. One commenter shared a personal story of struggling to sell a proprietary framework, expressing pessimism about the viability of selling developer tools in the current market. This was met with counterpoints about the enduring value of consultants and expertise, even with the rise of AI coding assistants. Finally, there was interest in seeing Skip used in prominent applications to validate its capabilities.

---

## [Tell HN: Bending Spoons laid off almost everybody at Vimeo yesterday](https://news.ycombinator.com/item?id=46707699)
**Score:** 372 | **Comments:** 410 | **ID:** 46707699

> **Post:** A user on Hacker News reported that Bending Spoons, an Italian tech company, has laid off almost all of Vimeo's staff. This follows Bending Spoons' acquisition of the video platform for $1.38 billion. The post serves as a notification of a significant corporate event affecting a major tech service.
>
> **Discussion:** The discussion centered on Bending Spoons' established business model of acquiring mature software companies, aggressively cutting costs by laying off most staff, and then raising prices while maintaining the product with a minimal team. Commenters universally referenced the company's previous acquisition of Evernote as a direct precedent, noting that Bending Spoons subsequently shut down legacy versions, restricted free tiers, and increased subscription costs. There was significant concern for Vimeo's future, particularly regarding its business customers who rely on its infrastructure for paid services like Dropout and for hosting content like MST3K. Many individual users announced they were canceling their long-standing accounts due to price hikes and uncertainty. While some questioned the long-term viability of this "slash-and-burn" strategy, others described it as a new, efficient form of private equity. The conversation also touched on the fate of open-source projects associated with Vimeo, such as the Psalm static analyzer for PHP, though its creator confirmed it is now independently maintained.

---

## [Linux from Scratch](https://www.linuxfromscratch.org/lfs/view/stable/)
**Score:** 367 | **Comments:** 93 | **ID:** 46709727

> **Article:** The link points to the official website for "Linux from Scratch" (LFS), a book that provides step-by-step instructions for building a custom Linux system entirely from source code. The project is a non-profit effort to teach users how a Linux system is built from the ground up. It guides the user through compiling the source code for essential tools like the GCC compiler and the GNU C library (glibc), configuring the system, and booting into their own custom-built environment. The site offers different versions of the book, including a standard build, a version using systemd, and an "Automated Linux From Scratch" option.
>
> **Discussion:** The Hacker News discussion is overwhelmingly positive, with many commenters sharing nostalgic memories of building LFS in their youth. A common theme is that LFS is an unparalleled educational experience for understanding how a Linux distribution works, removing the "magic" of package managers and revealing the low-level mechanics of the operating system. While many agree that distributions like Gentoo or Arch offer a similar, less time-consuming education, the consensus is that the LFS "marathon" is a rite of passage for any aspiring systems programmer.

Several users shared personal stories, noting that the process took them about eight hours to complete, a duration that has remained surprisingly constant over the years due to increasingly complex software balancing out faster hardware. The time commitment is a major barrier for many, with some hoping to tackle it after retiring. The discussion also touched on the evolution of LFS, with modern versions now including systemd and Wayland. A brief tangent debated the value of using LLMs to automate the process, with most agreeing that the point of LFS is the learning journey, not just the final product.

---

## [How AI destroys institutions](https://cyberlaw.stanford.edu/publications/how-ai-destroys-institutions/)
**Score:** 297 | **Comments:** 254 | **ID:** 46705606

> **Article:** The paper "How AI Destroys Institutions" argues that AI, particularly generative AI, poses an existential threat to "purpose-driven institutions" like higher education, medicine, and law. The author contends that these institutions rely on shared standards, trust, and structured processes to reduce chaos and enable intellectual risk-taking. AI disrupts this by flooding the information ecosystem with synthetic content, eroding the shared reality these institutions depend on. It also undermines the economic and epistemic foundations of these fields by automating tasks that previously required human expertise and credentialing, potentially leading to a collapse of institutional authority and a regression to a less reliable, pre-institutional state of knowledge.
>
> **Discussion:** The Hacker News discussion is highly polarized and largely critical of the paper's premise and academic rigor. A significant portion of the debate centers on the paper's quality, with several commenters pointing out that it is a draft, not peer-reviewed, and contains errors like misspellings and weak citations (e.g., relying on news articles about AI rather than primary sources). This leads some to dismiss it as an "opinion piece" rather than substantive research.

Beyond the paper's merits, the conversation splits into two main themes. One side argues that the paper's alarmist tone is misplaced and that AI is a tool with understandable appeal, not a cartoon villain. These commenters suggest that institutions themselves bear responsibility for their decline, citing low public trust, high costs, and inaccessibility in fields like medicine and education, which makes AI an attractive alternative for many.

The other theme is a broader skepticism about the stability of institutions themselves. Some argue that institutions were already "fatally wounded" by previous disruptions like social media, making AI's impact a continuation of a pre-existing trend rather than a new cause of destruction. A smaller, more philosophical thread questions the very nature of social science as a discipline, debating its validity compared to "hard science." Overall, the discussion reflects a deep-seated debate over whether AI is an active destructive force or merely an accelerant for pre-existing institutional decay.

---

## [Waiting for dawn in search: Search index, Google rulings and impact on Kagi](https://blog.kagi.com/waiting-dawn-search)
**Score:** 287 | **Comments:** 161 | **ID:** 46708678

> **Article:** The Kagi blog post "Waiting for dawn in search" outlines the immense difficulty and high costs of building a competitive search engine due to Google's market dominance and the lack of a public search API. The author argues that Google's control over its index and the recent US court rulings against its anti-competitive practices are critical for the future of alternative search providers like Kagi. The post details Kagi's own technical and business challenges, explaining that they must rely on third-party API providers to access Google's search results because direct licensing is not available to them on viable terms. The article frames the current legal and technological landscape as a pivotal moment that could either enable a more diverse search ecosystem or allow Google to maintain its monopoly.
>
> **Discussion:** The Hacker News discussion centers on Kagi's reliance on third-party providers to access Google's search index, a fact revealed in the article. This admission sparked a debate on the ethics and practicalities of Kagi's business model. One prominent thread questioned the legality and ethics of "stealing" and reselling Google's core product, while others defended it as a standard business practice in a monopolistic market where direct access is denied.

Another major theme was skepticism towards Kagi's claims of independence. Commenters expressed doubt about the nature of Kagi's "own small-web index," with some speculating it might be minimal or misleading. Privacy concerns were also raised, as users realized their queries, despite Kagi's policy, are ultimately sent to and processed by Google, subject to its privacy policies.

Broader topics of monopoly and competition were also debated. Some argued that Google's dominance is a natural result of being the best product, but this was countered by the classic argument that monopolies prevent better alternatives from emerging, regardless of quality. The discussion also touched on the difficulty of building a new search index from scratch, with commenters comparing it to the AI race and concluding that Google's entrenched position and brand recognition ("Google is a verb") make it an almost insurmountable obstacle. Finally, some users questioned the accuracy of the statistics presented in the article, particularly the global usage figures, suggesting they were skewed by excluding regions where Google is blocked.

---

## [Scientists find a way to regrow cartilage in mice and human tissue samples](https://www.sciencedaily.com/releases/2026/01/260120000333.htm)
**Score:** 283 | **Comments:** 81 | **ID:** 46709179

> **Article:** A study led by Stanford Medicine researchers has discovered that blocking a protein linked to aging can reverse the natural loss of knee cartilage in older mice. The treatment involves an injection that inhibits 15-hydroxy prostaglandin dehydrogenase (15-PGDH), a protein that accumulates with age and suppresses cartilage regeneration. The research, published in *Science*, also demonstrated successful cartilage regrowth in human tissue samples. Researchers are hopeful that human clinical trials can be fast-tracked, noting that a Phase 1 trial for a 15-PGDH inhibitor is already underway for muscle weakness, which could provide relevant safety and efficacy data.
>
> **Discussion:** The discussion was a mix of cautious optimism, skepticism, and personal reflection. A dominant theme was the familiar frustration with the "mouse model" bottleneck, with users humorously noting that promising results are "always in mice" and questioning when such breakthroughs will translate to humans. However, this was tempered by the news that the compound is already in Phase 1 human trials for a related condition (muscle weakness), offering a potential pathway for faster approval.

Users also debated the biological mechanism, with one commenter raising the valid concern that uncontrolled tissue regrowth could lead to cancer, though another countered that cancerous cells lack the organized communication of normal regenerative processes. Several commenters shared personal stories about joint pain and arthritis, expressing a desperate hope for such a treatment to become available. The conversation also touched on the broader context of "perennial breakthroughs" like fusion power and battery tech, highlighting a common skepticism toward headlines about scientific advances. Finally, a layperson asked for context on the reliability of mouse studies, to which the community responded with realistic timelines (5-10 years for availability) and noted that the study had also been tested on human tissue samples.

---

## [SETI@home is in hiberation](https://setiathome.berkeley.edu/)
**Score:** 261 | **Comments:** 135 | **ID:** 46703301

> **Article:** The article links to the SETI@home homepage, which announces that the project is now in "hibernation." This means the project is no longer distributing new work units to the public's computers for analysis. The decision was made after the project effectively completed its processing backlog, a process that has been ongoing for several years. The project's scientific analysis of the collected data is now largely complete, with final results being published.
>
> **Discussion:** The discussion is a wave of nostalgia and reflection on the legacy of SETI@home. Many commenters share personal memories of running the iconic screensaver on old hardware like the Pentium II, feeling a sense of scientific contribution and wonder as kids. This nostalgia extends to the broader pop-culture context of the 90s, with users recalling how SETI@home fit perfectly with the era's "X-Files" fascination with UFOs and conspiracy theories.

While some initially question if the decades-long effort was "for nothing," others clarify that the project was a success, having recently published scientific papers. The conversation also touches on the evolution of distributed computing. Users note that while SETI@home is winding down, other projects like Folding@home are still active, though some wonder if advancements like AlphaFold have made such efforts less critical. Ultimately, the thread serves as a nostalgic tribute to a pioneering project that inspired a generation to contribute their idle CPU cycles to science.

---

## [Stories removed from the Hacker News Front Page, updated in real time (2024)](https://github.com/vitoplantamura/HackerNewsRemovals)
**Score:** 243 | **Comments:** 173 | **ID:** 46704555

> **Article:** The article links to a GitHub repository titled "Stories removed from the Hacker News Front Page, updated in real time." The project maintains a real-time log of posts that have been removed from the Hacker News front page, categorizing them by the reason for removal (e.g., flagged, duplicate, killed by moderators). It serves as a transparency tool for the community to observe the moderation dynamics of the site.
>
> **Discussion:** The discussion centers on the transparency of HN moderation, the role of politics on a tech forum, and user fatigue with specific topics. A significant portion of the conversation addresses the tension between maintaining a strictly technical focus and acknowledging the intersection of technology and politics. Several users argued that technology is now deeply intertwined with governance and policy, making it impossible to discuss tech without a political lens. However, opposing views expressed exhaustion with political "echo chambers" and supported the "silent majority" of users who flag such content to keep the front page focused on technical curiosity.

There was also debate regarding the effectiveness and potential biases of the flagging system. Some users suggested that specific topics, particularly those critical of right-wing figures or policies, are disproportionately flagged, while others countered that political posts are simply inappropriate for the forum regardless of ideology. Additionally, users discussed the prevalence of AI/LLM-related stories, with many expressing fatigue at the ubiquity of "AI" branding in tech products. The conversation concluded with mixed sentiments on moderation: while many users expressed gratitude for the moderators' efforts to maintain quality, others called for more visibility into the flagging process to identify potential censorship or power-user manipulation.

---

## [Nested code fences in Markdown](https://susam.net/nested-code-fences.html)
**Score:** 224 | **Comments:** 74 | **ID:** 46705201

> **Article:** The article explains how to nest code fences in Markdown, a common challenge when embedding code snippets that themselves contain code blocks. The solution is to use more backticks (or tildes) for the outer fence than are used inside the code block. For example, if a code block contains a standard triple-backtick fence, the outer block must use at least four backticks. The article demonstrates this with examples of embedding Markdown, HTML, and other code within a single document.
>
> **Discussion:** The discussion primarily focuses on the inherent flaws and complexities of Markdown's code fence design. A central theme is the criticism of the delimiter system, with users arguing that using the same symbol (` or ~) for both opening and closing tags creates ambiguity and forces users to count characters to avoid conflicts. Several alternative designs were proposed, such as using distinct start and end markers (e.g., `[[[` and `]]]`) or adopting length-prefixing to avoid delimiter issues entirely.

The conversation also touched upon the broader issue of Markdown's lack of a formal specification, contrasting the original, ambiguous syntax with the more rigorous CommonMark standard. Practical workarounds were mentioned, including using HTML tags (`<pre>`, `<code>`), org-mode syntax, or simply choosing delimiters that are unlikely to appear in the code (like `---`). The thread concluded with real-world applications, such as using this nesting technique for GitHub suggestions and for prompting Large Language Models (LLMs) to generate correctly formatted Markdown.

---

## [Ireland wants to give its cops spyware, ability to crack encrypted messages](https://www.theregister.com/2026/01/21/ireland_wants_to_give_police/)
**Score:** 219 | **Comments:** 100 | **ID:** 46705715

> **Article:** The Register reports that the Irish government is seeking to grant its police force (Gardaí) new powers to use spyware and crack encrypted communications. The proposed legislation aims to modernize surveillance capabilities to keep pace with digital communication methods used by criminals, but it raises significant concerns regarding privacy and the potential weakening of encryption standards.
>
> **Discussion:** The Hacker News discussion is overwhelmingly critical of the Irish government's proposal, framing it as part of a broader, worrying trend of government overreach and surveillance expansion.

Key themes in the discussion include:

*   **The Futility and Danger of Backdoors:** Users argue that mandating technical access to encrypted data is fundamentally flawed. One commenter noted that even if it were technically possible to create unbreakable encryption, governments would simply legislate to force providers to insert backdoors, negating cryptographic security. Another pointed out that the issue is not purely technical but political; even if users adopt secure technology, they risk arrest simply for using it.
*   **Government Incompetence and Misplaced Priorities:** Several commenters criticized the police's ability to handle existing responsibilities. A user cited a tragic case in Romania where police failed to act on a kidnapped girl's repeated emergency calls, arguing that granting more surveillance power is unwarranted when basic policing fails. Another user highlighted Ireland's shortage of frontline Gardaí, suggesting the government is prioritizing a "cyberpolice force" over basic public safety.
*   **Global Trend of Erosion of Rights:** The discussion identified this move as part of a global pattern where states increasingly seek to surveil citizens as digital data proliferates. Users compared Ireland's actions to the UK's surveillance laws and noted that Western governments are receiving similar intelligence briefings, potentially preparing for geopolitical conflicts like a "third world war."
*   **Cynicism Regarding Law Enforcement Motives:** Commenters expressed deep distrust in police motivations, suggesting that law enforcement is more motivated by profit (e.g., seizing drugs or cash) than by protecting citizens from violent crime. This cynicism extends to the belief that police have no legal obligation to protect individuals, citing US court rulings.
*   **Historical Context:** Some users viewed this as a regression, feeling that governments are attempting to control cryptography in ways that resemble historical attempts to restrict encryption algorithms.

---

## [Swedish Alecta has sold off an estimated $8B of US Treasury Bonds](https://www.di.se/nyheter/di-avslojar-alecta-har-dumpat-amerikanska-statspapper/)
**Score:** 195 | **Comments:** 160 | **ID:** 46705256

> **Article:** The article reports that Swedish pension fund Alecta has sold approximately $8 billion in US Treasury bonds. The original source is a Swedish financial news outlet, di.se. The post provides no further context on the specific reasons for the sale within the article text itself.
>
> **Discussion:** The discussion centers on the significance of the sale, potential alternatives to US markets, and the broader context of foreign investment in US debt. Opinions are divided on the impact of the $8 billion sale, with some commenters viewing it as a minor, symbolic amount relative to the total US Treasury market, while others see it as a potentially significant signal of a larger trend toward de-dollarization or a lack of confidence in US politics.

Key themes in the discussion include:
*   **Scale and Impact:** Users debated whether $8 billion is a meaningful figure. Some argued it represents a tiny fraction of the market and that liquidity ensures other buyers will absorb the sale without price impact. Others countered that even small sales affect supply and demand, and that this could be the start of a larger trend, particularly if major funds like Norway's sovereign wealth fund were to follow suit.
*   **Geopolitical Context:** Several comments linked the sale to a pattern of European pension funds (specifically from Denmark) reducing their US Treasury holdings, suggesting a growing geopolitical divergence or risk assessment.
*   **Alternatives to US Markets:** A major thread of discussion focused on where to reinvest the capital. Commenters noted the lack of a deep, unified European bond market to rival the US, citing structural issues within the EU. Alternatives mentioned included European equities, gold, and Chinese assets, though each comes with its own risks and limitations.
*   **Market Dynamics:** Some users provided context on current bond yields, noting they are at highs not seen since before the 2008 financial crisis, and debated whether this sale is a cause or a symptom of broader market shifts, with some attributing yield movements more to Japan's monetary policy than to this specific sale.

---

## [Show HN: Sweep, Open-weights 1.5B model for next-edit autocomplete](https://huggingface.co/sweepai/sweep-next-edit-1.5B)
**Score:** 194 | **Comments:** 24 | **ID:** 46713106

> **Project:** Sweep is an open-weights 1.5B parameter model designed for "next-edit" autocomplete, a task that predicts the next logical edit in a codebase rather than just completing the current line. The model was trained using Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on a dataset of code changes extracted from GitHub repositories. The training process reportedly took approximately 4 hours on 8x H100 GPUs. The model is available on Hugging Face and is based on the Qwen2.5 architecture.
>
> **Discussion:** The community response was generally positive, with users praising the technical approach of framing autocomplete as "next-edit" prediction rather than token-level completion. Several commenters expressed interest in integrating the model into specific editors like VS Code, Sublime, and JetBrains, noting that the existing JetBrains plugin is well-regarded.

Technical discussions focused on the training efficiency and methodology. One user questioned the claimed training speed (1.5B model in ~4 hours on 8x H100s), comparing it to their own experience fine-tuning a larger 3B model on a substantial dataset in 7 hours on a single GPU. Others inquired about the cost-effectiveness of the training run and the decision to use Qwen2.5 as a base model. There was also specific interest in how the training data was generated from repositories and whether including older edits as context yields diminishing returns.

A minor debate arose regarding the necessity of Reinforcement Learning (RL) versus constrained decoding for ensuring syntax correctness. A responder argued that RL is superior because it addresses semantic correctness and allows the model to learn from multiple reward functions simultaneously, whereas constrained decoding only enforces syntax during inference.

Finally, there was a request for future releases of larger model variants (3B/7B), with users noting that while the 1.5B model shows modest improvement over existing baselines, larger versions could be "game changers."

---

## [JPEG XL Test Page](https://tildeweb.nl/~michiel/jxl/)
**Score:** 184 | **Comments:** 118 | **ID:** 46708032

> **Article:** The article is a simple test page hosted on a personal website designed to check browser compatibility with the JPEG XL (JXL) image format. It displays a sample JXL image and provides technical details about the format, such as its capabilities and how to enable it in browsers that support it but have it disabled by default. The page serves as a practical tool for users to verify if their current browser can render this next-generation image format.
>
> **Discussion:** The discussion centers almost entirely on browser compatibility and user experiences with the JPEG XL test page. There is significant confusion and variation in results, highlighting the fragmented state of JXL support. Key points include:

*   **WebKit vs. Chromium:** Users confirm that WebKit-based browsers like Orion and Epiphany (Gnome Web) successfully display the image. In contrast, many Chromium-based browsers, including Chrome and Brave, do not work out-of-the-box, even on up-to-date systems. Some users note that the experimental flag to enable JXL is missing from their Chromium builds.
*   **Firefox Support:** There is conflicting anecdotal evidence regarding Firefox. While some users report it works on recent versions (e.g., 146.0.1) on Windows and Linux, others state it does not work at all, suggesting potential differences in settings, extensions, or specific builds.
*   **Mobile Browser Scarcity:** A sub-thread discusses the lack of up-to-date WebKit browsers for Android that support JXL. Users explore niche options like Lightning and Fulguris, but the consensus is that there is no mainstream, user-friendly option available.
*   **Naming and Perception:** One commenter critiques the "JPEG XL" name, arguing it fails to convey the format's efficiency and modernity, which could hinder its adoption. Another user counters that leveraging the established "JPEG" brand is strategically beneficial.
*   **Tangential Topics:** The conversation briefly touches on the historical use of the "Lenna" test image and a lighthearted observation about the test image's subject.

---

## [SmartOS](https://docs.smartos.org/)
**Score:** 173 | **Comments:** 73 | **ID:** 46706947

> **Article:** The article links to the documentation for SmartOS, a specialized, open-source operating system. SmartOS is a "live OS" that runs entirely from memory (USB/PXE), leaving local disks free for virtual machine storage. It is based on the Illumos kernel (a derivative of OpenSolaris) and is designed for hyper-converged infrastructure and datacenter environments, featuring integrated ZFS and containerization (zones) alongside VMs. It serves as the core OS for the Triton datacenter orchestration platform.
>
> **Discussion:** The discussion centers on the current relevance of SmartOS, its historical trajectory, and its technical trade-offs compared to modern Linux and FreeBSD alternatives. While the OS is still actively developed and maintained by the Triton Data Center team (formerly Joyent), commenters note that its community visibility has significantly waned since Joyent's acquisition by Samsung.

Key themes include:
*   **Niche Status and Community:** Several users express that SmartOS is a niche platform. One commenter attributes its fade from popularity partly to an elitist culture among its original Sun Microsystems-era developers, which hindered community engagement. Others note that Samsung's stewardship of open source projects is often viewed with skepticism.
*   **Technical Merits vs. Linux:** Users debate the pros and cons of SmartOS in 2026. Proponents highlight features like the Service Management Facility (SMF), advanced RBAC (Role-Based Access Control), the MDB debugger, and the integrated ZFS and container model. However, detractors point out that Linux now offers robust ZFS support, mature containerization (Docker/Kubernetes), and hypervisors (Proxmox/KVM), making the Illumos ecosystem less compelling for general use. Driver support and hardware compatibility (e.g., PCI passthrough) are cited as pain points for SmartOS in home lab or non-enterprise environments.
*   **Manta and Compute-Data Locality:** A specific discussion arises around Manta, SmartOS's object store that allows scheduling computations on storage nodes. While the concept of reducing data movement was praised, practical users found the scheduler arcane and the benefits marginal compared to the complexity involved. Commenters expressed a wish for modern tools to adopt similar "compute-on-storage" paradigms.
*   **Alternatives and Successors:** Users mention alternatives like FreeBSD (for its jail technology) and IncusOS (a Debian-based immutable OS), though the latter is noted not to be a Solaris derivative. The Oxide Computer Company's use of an Illumos-based OS (Helios) was highlighted as a modern, high-profile application of the technology.

---

## [Show HN: Rails UI](https://railsui.com/)
**Score:** 160 | **Comments:** 84 | **ID:** 46709543

> **Project:** Rails UI is a commercial Ruby gem ($799/year) that provides pre-built UI components and themes for Ruby on Rails applications. It is built on Tailwind CSS and aims to accelerate development for solo developers and small startups building MVPs from scratch. The project's website serves as a design preview, though some interactive elements are non-functional as they are implemented in the gem itself.
>
> **Discussion:** The community reaction was mixed, with significant debate over the product's value and visual design. Several commenters questioned the necessity of the product, suggesting that modern AI tools (like Claude or Gemini) can generate UI code more cheaply and effectively. Others criticized the visual aesthetic as "dated," drawing comparisons to older frameworks like Bootstrap, which sparked a side debate on the role of UI frameworks versus custom design.

Technical feedback highlighted usability issues on the project's marketing site, particularly regarding mobile responsiveness and broken functionality in Safari, which the creator acknowledged. There was also discussion around the broader adoption of UI frameworks in professional settings, with some noting political resistance from designers and product owners who prefer custom work, while others argued that established frameworks are more efficient for delivering value. The creator defended the product as a tool for rapid prototyping and 0-to-1 development, acknowledging it is not targeted at established teams with existing design systems.

---

## [I made Zig compute 33M satellite positions in 3 seconds](https://atempleton.bearblog.dev/i-made-zig-compute-33-million-satellite-positions-in-3-seconds-no-gpu-required/)
**Score:** 158 | **Comments:** 18 | **ID:** 46703317

> **Article:** The author presents a high-performance implementation of the SGP4 satellite propagation algorithm in Zig, achieving a throughput of 33 million position calculations in 3 seconds on a single CPU core without a GPU. The article details the optimization journey, starting from a naive Python implementation and moving to Rust and C++. The final performance gains are attributed to three main factors: using Zig's explicit SIMD (Single Instruction, Multiple Data) capabilities to process multiple satellites simultaneously, optimizing memory layout for better cache locality, and employing branchless programming techniques to avoid CPU pipeline stalls. The author also created a web-based visualization tool to demonstrate the results.
>
> **Discussion:** The Hacker News community response was largely positive, with several key themes emerging. Many commenters appreciated the article as a clear and accessible introduction to SIMD programming, praising Zig for making low-level performance optimizations more approachable.

A significant point of critique focused on the article's data visualization. Several users pointed out that a bar chart comparing SIMD performance started its y-axis above zero, which visually exaggerated a 2x performance improvement into what appeared to be a 10-100x gain. The author was quick to correct this, which was noted positively.

There was a debate on the practical necessity of such high-throughput calculations. While some found the performance impressive, others questioned the real-world use case, arguing that for many applications (like antenna pointing), lower precision or interpolation between keyframes would be more efficient and accurate than calculating positions at one-second intervals over long periods.

Technical discussions also arose around specific optimization choices. One commenter expressed skepticism about the "compute both branches and select" strategy, questioning the logic and the claim that it was primarily to avoid branch misprediction penalties, suggesting the reasoning might be oversimplified.

Finally, the discussion broadened to include a general appreciation for modern tools and a "golden age" of space visualization, with users sharing links to other impressive projects. Comparisons were also made to other high-performance languages like Julia, wondering how this implementation would stack up against existing toolboxes in that ecosystem.

---

