# Hacker News Summary - 2026-01-13

## [Cowork: Claude Code for the rest of your work](https://claude.com/blog/cowork-research-preview)
**Score:** 888 | **Comments:** 403 | **ID:** 46593022

> **Article:** Anthropic has released "Cowork," a research preview of a desktop application designed to make the power of Claude Code accessible to non-developers. The app provides a graphical user interface (UI) for an AI agent that can perform tasks on a user's computer, such as organizing files, managing calendars, and creating presentations. The core idea is to take the powerful "harness" and agentic capabilities of the command-line tool, Claude Code, and package it in a way that allows a broader audience ("the rest of your work") to automate their daily, non-coding tasks.
>
> **Discussion:** Discussion unavailable.

---

## [Apple picks Gemini to power Siri](https://www.cnbc.com/2026/01/12/apple-google-ai-siri-gemini.html)
**Score:** 796 | **Comments:** 473 | **ID:** 46589675

> **Article:** According to a CNBC report, Apple has selected Google's Gemini artificial intelligence model to power a future version of its Siri voice assistant. The deal involves Apple licensing a custom, large-language model built by Google to handle Siri's core AI capabilities. This move signals a significant strategic shift for Apple, which has been widely perceived as lagging in the AI race. Instead of developing its own foundational model from scratch, the company is opting to partner with a leading external provider to quickly upgrade its technology. The partnership builds on the existing relationship between the two tech giants, where Apple already generates significant revenue from Google's payments to be the default search engine on its devices.
>
> **Discussion:** The Hacker News community reaction was a mix of surprise, strategic analysis, and skepticism. A primary theme was the business and strategic rationale behind the move. Many commenters viewed this as a pragmatic decision by Apple to avoid the immense capital expenditure required to train frontier-level models, arguing that it's more efficient to let Google handle the "heavy lifting" of training and then run a distilled version on Apple's own private cloud compute nodes. This was framed as Apple focusing on its core strength—the "last mile" delivery of a premium user experience and privacy layer, rather than building the foundational intelligence itself. The deep financial ties between the companies were also highlighted, with speculation that this could be a way to offset the multi-billion dollar payments Google makes to Apple for search default status.

There was significant discussion around Apple's perceived position in the AI race. Some saw this as an admission that Apple cannot or will not compete in building its own foundational models, with one user noting Apple's lack of the massive datacenter infrastructure (TPU pods, H100 clusters) required for such training. Others defended this as a classic Apple strategy: waiting for the market to mature and "turboence to settle" before making a decisive move, rather than rushing in prematurely.

User sentiment on the product level was largely negative. A vocal contingent expressed dismay, with comments like "Guess I am not using Siri anymore," indicating a lack of trust in Google's technology or a preference for a more independent Apple. Skepticism was also directed at the privacy implications, with one highly-upvoted comment dismissing Apple's privacy protections as "theater" in this context.

Finally, commenters sought to clarify the specifics of Apple's AI partnerships, noting that this Gemini deal would likely supplement or replace the existing opt-in integration with OpenAI's ChatGPT, rather than being a default, white-labeled solution.

---

## [TimeCapsuleLLM: LLM trained only on data from 1800-1875](https://github.com/haykgrigo3/TimeCapsuleLLM)
**Score:** 579 | **Comments:** 235 | **ID:** 46590280

> **Article:** The article links to a GitHub repository for "TimeCapsuleLLM," a project featuring a Large Language Model trained exclusively on historical data from 1800 to 1875. The project's goal is to create an AI that reflects the knowledge, language, and worldview of the 19th century, effectively isolating it from all modern information and scientific discoveries that occurred after its training cutoff date.
>
> **Discussion:** The Hacker News discussion centered on the conceptual and practical implications of the TimeCapsuleLLM project. A primary theme was using the model as a test for the reasoning capabilities and potential of LLMs. Several users speculated on whether such a model, when prompted with concepts developed after its training period (like quantum mechanics or relativity), could independently reason its way to those discoveries. The consensus was that while it might be able to develop some related mathematics, it would lack the experimental data necessary for breakthroughs in fields like physics, and would likely default to pre-discovery theories (e.g., the hypothetical planet Vulcan to explain Mercury's orbit).

Another major point of discussion was the practical application of the model. Users were keen to find an easy way to run it, inquiring about hosted APIs, chat interfaces, or pre-quantized versions for local tools like Ollama and llama.cpp. It was noted that the model's architecture (nanoGPT and Phi 1.5) should make it relatively easy to quantize and run on consumer hardware.

Finally, there was some skepticism about the project's novelty and utility. One user humorously dismissed the idea as a "reinvented history book" with higher energy consumption, while others questioned the amount of STEM material available in 19th-century texts to train a capable model. The discussion also touched on using such "time-capsule" models as a way to benchmark performance without data contamination from modern benchmarks.

---

## [Floppy disks turn out to be the greatest TV remote for kids](https://blog.smartere.dk/2026/01/floppy-disks-the-best-tv-remote-for-kids/)
**Score:** 573 | **Comments:** 330 | **ID:** 46587934

> **Article:** The article describes a clever hack to create a kid-friendly TV remote using old floppy disks. Instead of using the disks for storage, the author uses them as physical "keys" or hooks. A floppy drive connected to a Raspberry Pi reads a unique identifier from each inserted disk. The Pi then triggers a script to play a specific video or audio file associated with that disk. This creates a simple, tactile interface where a child can insert a disk labeled with a cartoon character to watch their favorite show, completely bypassing the complex and ad-filled interfaces of modern smart TVs.
>
> **Discussion:** The Hacker News community reacted very positively to the idea, praising its simplicity and effectiveness. The discussion centered on a few key themes:

*   **Tactile vs. Digital:** Commenters universally agreed that a physical interface is far superior for children (and even the elderly) compared to navigating complex on-screen menus. The tactile feedback and simplicity of inserting a disk or card were highlighted as major benefits.
*   **Modern Alternatives:** Many pointed out that this concept is already a commercial product. Companies like Yoto and Tonies offer "audio players" for kids that use physical cards and figures to trigger content. However, the DIY floppy disk approach was seen as a more creative and nostalgic alternative.
*   **Broader Application:** The idea sparked a wider conversation about the poor user experience of modern smart TVs for everyone, not just kids. Users complained about slow, laggy interfaces and the difficulty for elderly relatives to operate them.
*   **Technical Variations:** Several users shared their own similar DIY projects, suggesting alternative media like RFID stickers on business cards, NFC disks, or even DVDs/CDs as the physical "hooks" for a media center.
*   **Nostalgia and Humor:** The project was met with nostalgia for old hardware like floppy drives and Amiga computers. A recurring joke was the idea of future generations being confused by the "Save" icon, which is still a floppy disk.

---

## [Ozempic is changing the foods Americans buy](https://news.cornell.edu/stories/2025/12/ozempic-changing-foods-americans-buy)
**Score:** 384 | **Comments:** 696 | **ID:** 46587536

> **Article:** A Cornell University study analyzed retail transaction data from households that started using GLP-1 agonists (like Ozempic) and found significant shifts in their purchasing habits. Within six months of starting the medication, these households reduced their overall grocery spending by an average of 5.3% (8% for higher-income households). The composition of their spending changed drastically: purchases of savory snacks, sweets, and baked goods dropped by roughly 10%, while spending on yogurt, fresh fruit, nutrition bars, and meat snacks increased. The study notes that these changes tend to reverse if the medication is discontinued.
>
> **Discussion:** The discussion surrounding the article focused on several key themes:

*   **Scale and Scope Clarification:** Several commenters emphasized that the headline was potentially misleading. The 5.3% spending reduction applies specifically to households using GLP-1 drugs, not the entire US population. Given that the study notes roughly 1 in 6 US households use these drugs, the aggregate economic impact is substantial but distinct from a general market trend.
*   **Economic Implications:** Users debated the net financial impact. While grocery bills decreased, the high cost of the drugs (often over $1,000/month) meant the savings were negligible for most. Additionally, there was conflicting data regarding dining out; while the Cornell study suggested reduced spending, a counter-study from Bloomberg indicated GLP-1 users actually spend more at restaurants, suggesting that the savings might be reallocated to dining experiences rather than offsetting medication costs.
*   **US vs. International Context:** Commenters expressed shock at the high adoption rates in the US compared to Europe. The consensus was that the US food environment—characterized by processed foods and poor city design—creates a dependency on such drugs, whereas higher EU food standards and healthier lifestyles reduce the need.
*   **Industry Reaction and Future Trends:** Skepticism was raised regarding the long-term impact on the food industry. Some predicted that food manufacturers would eventually engineer additives to counteract the effects of the drugs or lobby to restrict their use to protect profits.
*   **Physiological and Behavioral Changes:** Anecdotal reports suggested the drugs act as strong appetite suppressants that also cause gastrointestinal distress if "bad" foods are consumed. This led to a shift toward high-protein foods (yogurt, meat) and fiber, likely to manage side effects and maintain satiety.

---

## [Postal Arbitrage](https://walzr.com/postal-arbitrage)
**Score:** 373 | **Comments:** 187 | **ID:** 46591708

> **Article:** The article "Postal Arbitrage" by Riley Walz describes a creative "life hack" for sending messages via Amazon's grocery delivery service. The author demonstrates sending a lime to a friend for a $0.25 handling fee (plus the cost of the lime itself), which is significantly cheaper than the $0.68 cost of a first-class stamp. The process involves ordering an item for delivery to the recipient and using the "gift message" feature to write a note, which is printed on the packing slip. The article frames this as a form of arbitrage, leveraging Amazon's logistics and subsidized shipping costs to send a physical item and a message for less than the price of a traditional postcard. It is presented as a humorous, tongue-in-cheek experiment in using corporate infrastructure for personal communication.
>
> **Discussion:** The Hacker News discussion on "Postal Arbitrage" is multifaceted, exploring the concept from financial, practical, philosophical, and humorous angles. The conversation can be broken down into several key themes:

A central debate revolves around the true cost of this method. While the article highlights the low out-of-pocket fee, many commenters pointed out that the cost of an Amazon Prime subscription must be considered. However, others countered that for existing Prime subscribers, this is a sunk cost, making the marginal cost of sending an item extremely low. This led to a discussion on whether this "hack" is actually costing Amazon money, with some users viewing it as a way to burn through the company's "imaginary money" and others noting the environmental cost of shipping a single, often plastic-wrapped, item.

The practicality and experience of receiving such a "card" were also heavily scrutinized. Commenters noted that Amazon often has a minimum order value for free shipping, making it impossible to send a single lime for $0.25. More fundamentally, many felt the experience was a poor substitute for a real card, describing the printed receipt paper as "crummy" and lacking the personal touch of handwriting. A counter-proposal emerged: if the goal is to send a digital message that becomes physical, one could simply use a fax machine or a network-connected printer, a suggestion that was met with ironic humor.

The discussion also took a historical and critical turn. One user drew a direct parallel to the original Ponzi scheme, which also began as an arbitrage attempt on International Reply Coupons. Another commenter strongly criticized the idea of giving any money to Amazon, arguing it supports a business model that aims to destroy competition, including the USPS itself.

Finally, the comments were punctuated with a great deal of humor and creative extensions of the idea, such as sending a Maruchan Ramen package as a birthday card, using the trick to send gravy mix, and referencing the "collect call trick" where a short message is encoded into the call announcement.

---

## [Date is out, Temporal is in](https://piccalil.li/blog/date-is-out-and-temporal-is-in/)
**Score:** 361 | **Comments:** 140 | **ID:** 46589658

> **Article:** The article argues that JavaScript's `Date` object is fundamentally flawed because it conflates two distinct concepts: an absolute point in time (a timestamp) and a human-readable date/time (which depends on calendar systems and time zones). This leads to confusing behavior, especially in parsing and time zone handling. The author introduces the new `Temporal` API as the solution. `Temporal` provides separate, explicit objects for these concepts, such as `Temporal.Instant` for timestamps and `Temporal.PlainDate` for calendar dates. This design makes date/time logic more predictable, safer, and less error-prone, effectively replacing the problematic `Date` API.
>
> **Discussion:** The Hacker News community largely agrees that the existing `Date` API is a "mess" and that `Temporal` is a long-overdue and well-designed replacement. However, the discussion is tempered by practical concerns about its current state.

The main points of discussion are:

*   **Adoption and Browser Support:** The most significant theme is that `Temporal` is not yet widely available. Commenters point out that native support is currently limited to the latest versions of Firefox and Chrome, with Safari and Edge still lacking support. The global availability is under 2%, making it impractical for production use without a polyfill. This leads to the consensus that the article's title "Temporal is in" is premature.

*   **Polyfill and Performance:** While a polyfill exists and is praised, its size (51kb) is noted as a significant concern for client-side applications, though acceptable for server-side use.

*   **API Design and Concepts:** Users appreciate the clear separation of concerns in the `Temporal` API (e.g., `Instant` vs. `PlainDate`). Some technical questions arise about the design choices, such as why `Temporal.Instant` cannot be constructed from date/time components, which is explained as a deliberate choice to avoid ambiguity with time zones and Daylight Saving Time.

*   **Comparison to Other Libraries:** The conversation references the history of date libraries like `moment.js` and `luxon`, highlighting `Temporal`'s goal of providing a native, standardized solution to a problem developers have long relied on third-party libraries to solve.

*   **Tone of the Article:** One commenter criticizes the article's "exaggerated writing style," arguing it focuses more on developer ergonomics than fundamental principles. This is countered by another user who defends the article's technical accuracy, stating that `Date` truly does represent two different things poorly.

---

## [LLVM: The bad parts](https://www.npopov.com/2026/01/11/LLVM-The-bad-parts.html)
**Score:** 330 | **Comments:** 61 | **ID:** 46588837

> **Article:** The article "LLVM: The bad parts" by Nikita Popov (author of the linked piece) critiques the LLVM compiler infrastructure, focusing on its complexity, instability, and performance issues. Key criticisms include:
*   **Compilation Speed:** LLVM has become significantly slower over time, with modern Rust compilation being notoriously slow. The initial promise of faster compilation compared to GCC has largely eroded.
*   **API Instability:** Despite the existence of a C API, internal APIs change frequently, making it difficult for frontends to keep up. Even the C API is not entirely stable (e.g., the Orc JIT library).
*   **Complexity and Maintainability:** The codebase is massive and difficult to audit. Documentation is sparse, particularly for backend components like SelectionDAG and GlobalISel, making it hard for developers to build correct custom backends.
*   **Optimizer Bugs:** The optimizer is prone to bugs that are hard to detect. The article highlights issues like Loop Invariant Code Motion (LICM) creating excessive register pressure, which downstream register allocators struggle to fix.
*   **Process Issues:** There is a lack of comprehensive testing starting from LLVM IR, and code review processes can be inconsistent or deprioritized.
>
> **Discussion:** The Hacker News discussion largely validates the article's criticisms while offering context and potential solutions. The conversation centers on four main themes:

**1. Compilation Speed and Alternatives**
There is consensus that LLVM compilation times have become a major pain point, particularly for Rust. While some argue that LLVM is "good enough" and would require immense effort to replace, others point to faster alternatives like Mozilla's Cranelift or a proposed faster -O0 backend (TPDE) as evidence that better performance is possible. The historical irony that LLVM was originally marketed as faster than GCC was noted.

**2. Stability and API Complexity**
Commenters confirmed the instability of LLVM's APIs. While the core C API is relatively stable, components like the Orc JIT API change frequently, breaking frontends. The sheer complexity of the codebase makes it difficult to audit, leading to skepticism about the safety guarantees of languages like Rust that rely on it.

**3. Optimizer and Backend Issues**
Technical discussion focused on specific optimizer failures. Users agreed that Loop Invariant Code Motion (LICM) often creates register pressure that the register allocator cannot easily resolve. There was debate on whether the fix belongs in the allocator (rematerialization) or the optimizer. A lack of documentation for backend internals (SelectionDAG/GlobalISel) was cited as a major barrier to fixing these issues.

**4. Testing and Contribution Culture**
Several commenters highlighted the lack of a comprehensive executable test suite for LLVM IR, which makes working on custom backends difficult. There was also a meta-discussion about the difficulty of getting code reviews accepted, with users suggesting that the lack of "credit" or incentive for reviewers contributes to the bottleneck.

---

## [Anthropic made a mistake in cutting off third-party clients](https://archaeologist.dev/artifacts/anthropic)
**Score:** 277 | **Comments:** 187 | **ID:** 46586766

> **Article:** The article argues that Anthropic made a strategic error by blocking third-party clients (like OpenCode and Crush) from accessing their "Claude Code" subscription. The author contends that users of these tools weren't trying to exploit the system, but were seeking a better user experience than what Anthropic's official client offers, which they describe as buggy and lacking features. The piece suggests that instead of locking down their ecosystem, Anthropic should focus on improving their product to retain customers, warning that this move damages trust and pushes users toward competitors.
>
> **Discussion:** The Hacker News discussion offers a mix of economic justification, user frustration, and philosophical debate. The prevailing economic argument, articulated by Kentonv, is that this is a necessary business strategy. With AI models becoming commoditized and easily interchangeable, companies must create "stickiness" by locking users into their specific clients and subscription models to ensure profitability.

However, many users sympathize with the article's critique of Anthropic's product quality. Several commenters argue that they use third-party tools because the official Claude Code client is buggy, slow, and lacks features. They express disappointment that Anthropic is choosing to enforce restrictions rather than improve the user experience to out-compete alternatives.

The discussion also touches on the nature of "vibe coding" and the influence of specific personalities in the AI space, with some commenters unfamiliar with the figures mentioned. Finally, a few users downplayed the impact, suggesting the affected user base is a small minority who will eventually move on, while others countered that this reflects a broader trend of developers accepting "walled gardens" over open tools.

---

## [The chess bot on Delta Air Lines will destroy you (2024) [video]](https://www.youtube.com/watch?v=c0mLhHDcY3I)
**Score:** 215 | **Comments:** 170 | **ID:** 46593395

> **Article:** The article is a YouTube video titled "The chess bot on Delta Air Lines will destroy you." The video likely demonstrates the surprisingly high difficulty of the chess game available on Delta's in-flight entertainment system. The title suggests that the bot is much stronger than passengers might expect from a simple plane game, potentially leading to frustrating losses for amateur players.
>
> **Discussion:** The Hacker News discussion reveals a significant and amusing contradiction regarding the Delta chess bot's difficulty. The central theme is that the bot's strength appears to be inconsistent across different users, leading to two opposing experiences.

One group of users, including some self-identified as strong players (e.g., 1600-2000 ELO on Lichess), report that the bot is incredibly difficult, crushing them without mercy. They theorize that as in-flight hardware has been upgraded over the years without changing the bot's underlying software, its fixed thinking time now translates to a much higher effective playing strength. This is compared to a known bug in the macOS Chess app where a disabled difficulty slider combined with faster hardware made the game unintentionally hard.

Conversely, another group of users, including players of similar or even lower skill levels, found the bot to be laughably easy, describing its moves as random or prone to occasional blunders. This discrepancy is the main point of discussion, with users speculating that the experience might vary based on the specific aircraft model, the software version, or the difficulty setting chosen (though one comment notes there's only one setting). The conversation also includes humorous anecdotes, such as a user confusing poker with blackjack and a joke about the bot being a hidden person.

---

## [X Didn't Fix Grok's 'Undressing' Problem. It Just Makes People Pay for It](https://www.wired.com/story/x-didnt-fix-groks-undressing-problem-it-just-makes-people-pay-for-it/)
**Score:** 194 | **Comments:** 159 | **ID:** 46592827

> **Article:** Summary unavailable.
>
> **Discussion:** Discussion unavailable.

---

## [Lightpanda migrate DOM implementation to Zig](https://lightpanda.io/blog/posts/migrating-our-dom-to-zig)
**Score:** 190 | **Comments:** 119 | **ID:** 46586179

> **Article:** The article details Lightpanda's migration of its DOM implementation to the Zig programming language. Lightpanda is a headless browser specifically designed for automation and web scraping. Unlike general-purpose browsers, it focuses on fetching HTML, parsing the DOM, and executing JavaScript to manipulate that DOM, while explicitly omitting CSS parsing, layout, and rendering. The migration to Zig is presented as a strategic choice to achieve high performance and low memory overhead, leveraging Zig's manual memory management and explicit control over system resources to build a more efficient engine for its specific use case.
>
> **Discussion:** The Hacker News discussion is largely positive and analytical, focusing on the technical merits of the project and the choice of Zig. The conversation revolves around a few key themes:

*   **Zig vs. Rust for Systems Programming:** The most prominent topic is the comparison between Zig and Rust. Several users note that while Rust has become the default for "safe" browser components (like in Firefox's Servo project), its borrow checker can be cumbersome for complex, mutable data structures like a DOM tree, often leading to "Rc<RefCell<T>> hell." Commenters suggest that Zig's manual memory management, combined with robust arena allocation, might offer a more ergonomic and direct way to model these relationships, making it a pragmatic choice for a DOM implementation.

*   **Clarification of Lightpanda's Scope:** Users discussed what Lightpanda is and isn't. It is a "true headless browser" that handles networking, DOM parsing, and JavaScript execution, but it does *not* handle CSS, layout, or rendering (painting pixels). This distinction led to a sub-discussion about its use cases, with one user noting the lack of screenshot capability as a potential debugging limitation, while another highlighted its utility for converting JS-heavy sites to Markdown via a pipeline.

*   **Production Readiness and Adoption:** There was some debate about the risk of using Zig, a language that has not yet reached version 1.0 and has seen breaking changes to its standard library. However, this concern was largely countered by pointing to successful production projects like TigerBeetle and Ghostty, suggesting that the benefits of Zig are worth the risk for many teams.

*   **Real-World Usage and Praise:** Several users shared their positive experiences with Lightpanda, describing it as a significant improvement over traditional text-based browsers like Lynx for scraping modern, JavaScript-dependent websites. The project was widely praised as "bonkers" and "incredible."

*   **Language Tribalism:** A minor thread touched on the fatigue of seeing "Rust vs. [other language]" debates in every comment section, with users reflecting on how the cycle of criticism has shifted over the years.

---

## [Zen-C: Write like a high-level language, run like C](https://github.com/z-libs/Zen-C)
**Score:** 186 | **Comments:** 108 | **ID:** 46587804

> **Article:** Zen-C is a new programming language that aims to provide the productivity of a high-level language while compiling to C for performance and compatibility. The project, recently released on GitHub, features a syntax heavily inspired by Rust, including type declarations, pattern matching, and traits. It also introduces some unique syntax, such as `repeat N` for loops. The core value proposition is to allow developers to write safer, more expressive code that ultimately produces readable C code, which can interface with the vast C ecosystem and run on bare-metal systems without a complex runtime.
>
> **Discussion:** The Hacker News discussion primarily focused on the language's identity, its practical utility, and its place within the ecosystem. The most prominent theme was the striking similarity of Zen-C's syntax to Rust. Commenters noted the resemblance but also pointed out minor inconsistencies, like the use of `I8` instead of Rust's `i8`, leading to jokes that it's "Rust for people who are allergic to using Rust." This sparked a debate about its purpose: if it looks like Rust, why not just use Rust?

This led to a broader conversation about the value of compiling to C versus other targets. The consensus was that targeting C is a pragmatic choice, as it offloads optimization to mature compilers (GCC, Clang) and provides a straightforward path to interoperability with countless existing C libraries. This approach was compared to other transpiling languages like Nim and the much older Vala, which were brought up as points of comparison.

The potential benefits were seen as significant for specific use cases. Commenters highlighted that by generating C code, Zen-C could easily integrate into existing C/C++ projects, leverage C-based verification tools, and achieve portability to embedded or bare-metal systems without needing to implement a new runtime. While some were skeptical about its adoption given the rise of Rust and Zig, others saw it as a valid entry in a growing market for modern systems languages, each offering a unique angle.

---

## [Windows 8 Desktop Environment for Linux](https://github.com/er-bharat/Win8DE)
**Score:** 181 | **Comments:** 170 | **ID:** 46588132

> **Article:** The article links to a GitHub repository for "Win8DE," a project that implements a Windows 8-style desktop environment for Linux. The project aims to replicate the "Metro" or "Modern UI" look and feel, characterized by its tile-based interface, within a Linux environment. It is presented as a theme or desktop shell modification for Linux users who appreciate the Windows 8 aesthetic.
>
> **Discussion:** The discussion is split between appreciation for the Windows 8 UI concept and criticism of its original implementation, with some skepticism about the new project.

A significant portion of the comments express nostalgia and praise for the Windows 8/Metro design philosophy. Users recall the interface as "smooth," "fast," and "ahead of its time," particularly on touch-based devices like Windows Phone. There's a sense that Microsoft was on to something good but abandoned it too quickly, and some hope this Linux project can iterate on the concept successfully.

However, other users counter this with strong negative memories of the original Windows 8 desktop experience. The primary complaints were the jarring full-screen "Start Screen" takeover on large desktop monitors, which broke user expectations and workflow, and the initial removal of the traditional Start button. This highlights a key theme: the UI was well-suited for touch devices but poorly adapted for mouse-and-keyboard desktops.

Finally, there is some technical skepticism. One commenter doubts that a hobbyist FOSS project can successfully replicate the complex user experience (UX) required for a modern GUI, while another notes that a true recreation would require more than just a theme—it would need a corresponding application framework like the original XAML/WinRT stack.

---

## [Ai, Japanese chimpanzee who counted and painted dies at 49](https://www.bbc.com/news/articles/cj9r3zl2ywyo)
**Score:** 179 | **Comments:** 61 | **ID:** 46585947

> **Article:** The BBC article reports on the death of Ai, a 49-year-old chimpanzee renowned for her cognitive abilities and artistic talent. Born in 1975, Ai was the first chimpanzee to learn to use Arabic numerals and could count up to nine. She also created abstract paintings, often using a brush, which were studied by researchers to understand primate behavior and cognition. Ai lived at the Primate Research Institute of Kyoto University in Japan, where she was a key subject in long-term research on chimpanzee intelligence.
>
> **Discussion:** The Hacker News discussion surrounding the article was multifaceted, with several distinct themes emerging. A prominent thread was the confusion and humor stemming from the acronym "AI," with users noting the irony of an "AI chimp" making headlines amidst the current boom in artificial intelligence. Many commenters expressed sympathy for Ai, framing her life in captivity as a "prison" and questioning the ethics of keeping intelligent animals for research, drawing parallels to the controversial breeding and culling practices in some zoos.

There was also a strong interest in seeing Ai's artwork and learning more about her, with users sharing links to scientific articles and videos of other intelligent primates like Koko the gorilla and Kanzi the bonobo. The conversation broadened to include a critique of the HN community itself, with one user lamenting the repetitive and low-effort jokes about AI, arguing the community should "do better." Finally, a few personal anecdotes and pop culture references were shared, including a user who owned a painting by the chimpanzee actor Cheeta and others referencing the video game *Super Monkey Ball*.

---

## [Statement from Federal Reserve Chair](https://www.federalreserve.gov/newsevents/speech/powell20260111a.htm?mod=ANLink)
**Score:** 176 | **Comments:** 28 | **ID:** 46589489

> **Article:** The article is a statement from Federal Reserve Chair Jerome Powell regarding the Federal Reserve's policy framework review. Powell discusses the central bank's approach to achieving its dual mandate of maximum employment and stable prices. He addresses the lessons learned from the recent period of high inflation, particularly the challenge of "transitory" inflation estimates, and outlines the Fed's ongoing evaluation of its long-term strategy, including how it interprets labor market conditions and its inflation target. The statement is forward-looking, focusing on ensuring the Fed's framework remains robust for future economic environments.
>
> **Discussion:** The Hacker News discussion is highly critical of the Federal Reserve and Jerome Powell personally. The dominant sentiment is one of deep distrust in official economic data and the competence of the Fed's leadership.

A key theme is the perceived failure of the Fed during the 2021-2022 inflation period. Commenters repeatedly cite Powell's initial characterization of inflation as "transitory" as a major error that led to aggressive rate hikes, widespread layoffs, and a lasting negative impact on the tech industry. There is a strong belief that official inflation and unemployment figures are inaccurate and do not reflect the economic reality experienced by ordinary Americans.

The discussion also turns to the political maneuvering around the Fed's leadership. Users note that President-elect Trump is seeking to replace Powell as Chair early, speculating that the motive is either revenge or a desire to install a more loyalist figure. It is clarified that even if removed as Chair, Powell would likely remain a Fed Governor, highlighting the political battle for control over the institution.

Overall, the comments portray the Fed as an unaccountable, self-serving institution whose officials are insulated from the consequences of their policy decisions, with the "transitory" inflation episode serving as the primary evidence of its incompetence.

---

## [Google removes AI health summaries after investigation finds dangerous flaws](https://arstechnica.com/ai/2026/01/google-removes-some-ai-health-summaries-after-investigation-finds-dangerous-flaws/)
**Score:** 163 | **Comments:** 95 | **ID:** 46595419

> **Article:** An article from Ars Technica reports that Google has removed some of its AI-generated health summaries from search results following an investigation that revealed "dangerous" and "alarming" flaws. The AI overviews were found to provide inaccurate, fabricated, or potentially harmful medical information, prompting the partial rollback of the feature. The article references a Guardian investigation as the original source for the story.
>
> **Discussion:** The Hacker News discussion is highly critical of Google's AI search features, with health information being the primary but not sole focus of the backlash. The community sentiment is that the AI overviews are a significant degradation of the search experience.

Key themes in the discussion include:

*   **General Distrust of AI Summaries:** Multiple users shared personal anecdotes of the AI providing dangerously wrong information, particularly for medical queries. One user noted the AI "hallucinated" details about a medication that contradicted official sources like WebMD and the manufacturer. Another described a query about a Tesla wheelchair that was debunked by an AI overview that cited the very fake video it was supposed to be debunking.
*   **Broader Degradation of Search:** Commenters expressed frustration that the AI summaries are often incorrect and that the overall search experience is declining due to a combination of AI-generated nonsense and a high volume of ads and SEO-spam. One user described it as "the final nail in the coffin of search."
*   **The "Human in the Loop" Argument:** A top-level comment argued that healthcare disruption should focus on augmenting human productivity rather than replacing professionals, given the life-and-death stakes. This sparked a brief debate on whether healthcare even "needs disruption."
*   **Regulatory and Corporate Responsibility:** A user pointed out that making medical diagnoses or recommendations would classify the software as a "Software as a Medical Device" (SaMD), which carries significant liability under FDA regulations. This highlights the regulatory minefield Google is navigating.
*   **Source Criticism:** One commenter criticized the Ars Technica article for a slightly sensationalized headline, pointing to the original Guardian report which specified "some" AI summaries were removed. This was largely dismissed by others as a minor issue.
*   **Contrasting Approaches:** A user noted the irony of Google removing its AI health feature due to safety concerns, while OpenAI simultaneously launched a dedicated "ChatGPT Health" service, suggesting different philosophies on AI safety among major tech companies.

Overall, the discussion portrays a user base that is deeply skeptical of AI summaries in high-stakes domains like health, viewing them as unreliable and a net negative for the quality of information.

---

## [Iran has now been offline for 96 hours](https://twitter.com/netblocks/status/2010750871274160361)
**Score:** 155 | **Comments:** 158 | **ID:** 46591974

> **Article:** The article links to a Twitter post from NetBlocks, an internet monitoring group, reporting that Iran has been offline for 96 hours. This indicates a severe, government-imposed internet blackout, likely in response to widespread civil unrest and protests against the regime.
>
> **Discussion:** The Hacker News discussion is multifaceted, focusing on the nature of the protests, the technical battle for information, and the geopolitical context.

Commenters express a mix of hope and pessimism regarding the uprising's potential for success. While some are hopeful for a regime change, others are skeptical, pointing to the regime's strong ideological base and the potential for a bloody civil war rather than a peaceful transition.

A significant portion of the discussion centers on the technical cat-and-mouse game of communication. Users explore the viability of Starlink as a countermeasure to the blackout, noting that Iran appears to be jamming the service, possibly by targeting the GPS signals the dishes rely on. The conversation also touches on methods for locating and seizing satellite dishes on the ground.

Finally, there is a heated debate over foreign involvement and motives. One prominent user argues that Western governments, particularly the US and Israel, are not genuinely interested in Iranian freedom but are backing the protests to install a favorable regime and dominate the Middle East. This view is challenged by others who find little evidence for such claims, leading to a debate on the credibility of sources and the true drivers of the conflict.

---

## [Show HN: AI in SolidWorks](https://www.trylad.com)
**Score:** 151 | **Comments:** 82 | **ID:** 46591100

> **Project:** The project, "AI in SolidWorks," is a tool that integrates Large Language Models (LLMs) with the SolidWorks CAD software. The goal is to allow users to create and modify 3D models using natural language commands. The initial demo, a coffee mug, was presented to gauge user interest and test the capabilities of current LLMs in this domain, acknowledging that the out-of-the-box models are not yet proficient at CAD tasks.
>
> **Discussion:** The discussion centered on the significant challenges and promising potential of using LLMs for CAD and spatial reasoning. A key theme was the current inadequacy of general-purpose models for precise 3D work; users noted that LLMs frequently make fundamental errors, such as choosing the wrong plane for sketches or creating flawed geometry, requiring human intervention to correct. The technical approach of using LLMs to generate API calls was also questioned, with one contributor sharing their own experience that models struggle to write functional SolidWorks API code directly.

However, the conversation also highlighted successful alternative strategies. One user detailed their experience using LLMs for more logic-oriented tasks in Altium (PCB design), where they act as "monotonous task-doers" for things like labeling and rule-checking. They suggested a multi-agent system where one LLM generates high-level natural language instructions (e.g., "place U1 to the left of U4") and a second, more specialized model translates this into precise, structured commands. This points to a future of specialized agents rather than a single, all-powerful model.

Broader skepticism was voiced about text as the ideal interface for inherently spatial tasks, with some users suggesting that the core difficulty lies in translating colloquial descriptions into precise modeling vocabulary and operations. The discussion also touched on the commercial viability of such tools, with concerns about defensibility given that anyone can "figure it out" with existing LLM APIs, though the creator of the project countered that the user base for SolidWorks is more concentrated than for other CAD software like Fusion 360. Ultimately, the consensus was that while the technology is promising, it is still in an early, exploratory phase with significant hurdles to overcome.

---

## [Fabrice Bellard's TS Zip (2024)](https://www.bellard.org/ts_zip/)
**Score:** 147 | **Comments:** 59 | **ID:** 46593802

> **Article:** The article links to a page by renowned programmer Fabrice Bellard describing "ts_zip," a novel text compression utility. The tool leverages a pre-trained Large Language Model (LLM) to achieve extremely high compression ratios on text files. It works by using the LLM to predict the probability of the next token in the text and then employing arithmetic coding to encode the data based on these predictions. The page includes benchmark results showing that ts_zip outperforms many traditional compressors on the Large Text Compression Benchmark, though it notes the significant size of the included LLM model.
>
> **Discussion:** The Hacker News discussion revolves around the technical validity of the benchmark results and the underlying principles of LLM-based compression. A central debate is whether the comparison to traditional algorithms is fair, given that ts_zip's "program" includes a massive 150MB pre-trained model. Many commenters argue that for a fair comparison on the standard benchmark, this model size must be added to the compressed output's size, as the benchmark measures the total Kolmogorov complexity (data + decompressor).

Several users explain the mechanism, clarifying that the process relies on arithmetic coding, which can encode data using fractional bits based on the LLM's probability distribution for the next token. This leads to a deeper discussion on information theory, where compression is framed as the art of accurate prediction, and the entropy encoder is considered a "solved problem." The conversation also touches on related applications like steganography, the potential for data loss in iterative compression (like a game of telephone), and humorous anecdotes about the legendary status of the author, Fabrice Bellard.

---

