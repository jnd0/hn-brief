# Hacker News Summary - 2026-01-13

## [Cowork: Claude Code for the rest of your work](https://claude.com/blog/cowork-research-preview)
**Score:** 951 | **Comments:** 432 | **ID:** 46593022

> **Article:** Anthropic has released "Cowork," a research preview of a desktop application that provides a graphical user interface (GUI) for its powerful Claude Code agent. The goal is to make the advanced capabilities of Claude Code accessible to non-developers ("the general population"). The app allows users to perform tasks like organizing files, managing calendars, and creating presentations through a more intuitive interface, moving the technology beyond the terminal and into everyday workflows.
>
> **Discussion:** The Hacker News community had a mixed but insightful reaction to Cowork. The general sentiment was that the concept is strong and timely, as many users are already using Claude Code for non-development tasks like managing personal finances, booking appointments, and classifying data. There was a consensus that the "harness" or interface is a critical component for broad adoption.

A significant technical debate emerged regarding Claude's image understanding capabilities. One commenter argued that the demo was misleading and that Claude still struggles with visual details, relying instead on command-line tools. However, other users pushed back, sharing personal anecdotes of being impressed by Claude's ability to detect subtle details and emotional states in images and videos. It was noted that the main limitation might be that Claude Code doesn't automatically process images by default, requiring explicit user prompting.

On the social and philosophical front, some commenters expressed skepticism, questioning the need to automate simple tasks like organizing a desktop and viewing the use of AI for tasks like creating meeting summaries as potentially "insincere." Others countered that these are valid productivity enhancements and that users still have the choice to perform tasks manually. A minor point of frustration for some was a geo-redirect bug on the announcement page, with a user providing an archive link as a workaround.

---

## [Apple picks Gemini to power Siri](https://www.cnbc.com/2026/01/12/apple-google-ai-siri-gemini.html)
**Score:** 835 | **Comments:** 516 | **ID:** 46589675

> **Article:** According to a CNBC report, Apple has chosen Google's Gemini artificial intelligence model to power an upcoming overhaul of Siri. This represents a major shift in strategy, as Apple is now officially acknowledging it will use a competitor's technology for a core feature of its operating system. The deal follows Apple's previous integration of ChatGPT for certain requests, suggesting a strategy of partnering with leading AI providers rather than relying solely on its own in-house models.
>
> **Discussion:** The Hacker News discussion centered on the strategic implications, financial motivations, and user reactions to the news. A primary theme was the financial logic behind the deal. Many commenters theorized that this is not a simple cash transaction but rather an offset against the multi-billion dollar fee Google pays Apple to be the default search engine on its devices. This allows Apple to acquire top-tier AI technology without a direct cash outlay, while Google solidifies its partnership with Apple.

Another major point of analysis was Apple's strategic positioning. Several users argued that this is a pragmatic move, acknowledging that Apple lacks the massive data center infrastructure and training expertise required to build a frontier model from scratch. They see Apple as wisely focusing on its strengths—hardware, edge inference (on-device processing), and user experience—while outsourcing the capital-intensive "heavy lifting" of model training to competitors like Google. This was contrasted with a minority view that outsourcing a core user experience component to a major competitor is a strategic mistake.

Finally, the discussion touched on user sentiment and Apple's AI track record. Some users expressed disappointment or a lack of surprise, citing Siri's historical weaknesses compared to other AI assistants. There was also confusion about how this would integrate with Apple's existing partnership with OpenAI, with commenters hoping for a user-selectable option between different AI models. The consensus was that this move solidifies Apple's pragmatic approach to the AI race, prioritizing access to the best technology over the "not invented here" syndrome.

---

## [Floppy disks turn out to be the greatest TV remote for kids](https://blog.smartere.dk/2026/01/floppy-disks-the-best-tv-remote-for-kids/)
**Score:** 610 | **Comments:** 345 | **ID:** 46587934

> **Article:** The article describes a clever DIY project to create a child-friendly TV remote using old floppy disks. Instead of using the disks for storage, the author uses them as physical "hooks" or tokens. A floppy drive connected to a Raspberry Pi reads a unique identifier from each inserted disk. The Pi then maps this ID to a specific media action, such as playing a particular video or song. This system completely bypasses complex on-screen menus and remotes, allowing a child to simply insert a disk to choose their content. The author praises the solution for its satisfying tactile feedback, the ability to customize the disks with artwork, and its simplicity for young children.
>
> **Discussion:** The Hacker News community responded very positively to the idea, with many commenters expressing admiration for its simplicity and ingenuity. The discussion quickly branched out into several key themes:

A primary theme was the shared frustration with modern TV and media interfaces. Multiple users agreed that current smart TVs and streaming apps are hostile not only for children but also for the elderly and even adults, citing slow, laggy UIs and overly complex remotes. The floppy disk project was celebrated as a brilliant solution to this problem by creating a tangible, screen-free interaction model.

Many commenters shared their own similar DIY projects, highlighting the popularity of this concept. Alternatives mentioned included using RFID cards/stickers (with a Raspberry Pi or ESP32), burnable DVDs/CDs, or SD card "cartridges." Several commercial products that use a similar physical-token concept were also pointed out, such as Yoto Players and Tonies for audio, and a similar Italian product for video.

There was a strong sense of nostalgia and appreciation for the physicality of the floppy disks. Users noted the satisfying "click" and the creative potential of decorating the disks. The idea of using obsolete media as simple physical tokens was seen as particularly clever. A humorous side note was the idea that this would be the first generation of kids for whom the floppy disk is not a "Save" icon but a literal "Play" button.

---

## [TimeCapsuleLLM: LLM trained only on data from 1800-1875](https://github.com/haykgrigo3/TimeCapsuleLLM)
**Score:** 605 | **Comments:** 246 | **ID:** 46590280

> **Article:** The article links to a GitHub repository for "TimeCapsuleLLM," a project featuring language models trained exclusively on historical data from 1800 to 1875. The project's goal is to create an AI that reflects the knowledge, perspectives, and linguistic style of the mid-19th century, effectively acting as a "time capsule" of that era's accessible information.
>
> **Discussion:** The Hacker News discussion primarily revolves around the philosophical and practical implications of training LLMs on historical, time-bound datasets. A central theme is using such models as a test for LLM intelligence and their potential for AGI. Many commenters speculate on whether a model trained only on pre-1900 data could independently "reason" its way to modern discoveries like quantum mechanics or relativity. The consensus is that while it might be able to develop related mathematics, it would lack the experimental data required for such paradigm shifts and would likely default to outdated theories (e.g., the hypothetical planet Vulcan to explain Mercury's orbit).

On a practical level, users expressed interest in easily accessible ways to run the model, such as through popular local inference tools like Ollama or LM Studio. It was noted that the model's architecture (nanoGPT and Phi 1.5) makes it small and quantizable, suitable for running on modest hardware.

Other points of interest included using these models to gain "rudimentary insight" into historical worldviews, though one user cynically noted this simply reinvents the history book with higher energy consumption. Finally, a brief demonstration of the model's output was shared, which one commenter described as sounding more like a Markov chain than a modern LLM, likely due to the limited and stylistically different training data.

---

## [Ozempic is changing the foods Americans buy](https://news.cornell.edu/stories/2025/12/ozempic-changing-foods-americans-buy)
**Score:** 400 | **Comments:** 725 | **ID:** 46587536

> **Article:** A Cornell University study analyzed NielsenIQ data to find that households using GLP-1 agonist drugs (like Ozempic) significantly change their purchasing habits. Within six months of starting the medication, these households reduced their overall grocery spending by an average of 5.3% (8% for high-income households). Spending on savory snacks, sweets, and baked goods dropped by roughly 10%, while purchases of yogurt, fresh fruit, nutrition bars, and meat snacks increased. Spending at fast-food and limited-service restaurants also fell by about 8%.
>
> **Discussion:** HN commenters focused on the scale of the impact, the financial implications, and the broader context of the US food environment. Many expressed surprise that 16% of US households reportedly use these drugs, attributing the high adoption rate to the poor quality of processed foods in the US compared to European standards. While the study showed a drop in grocery spending, users noted that the savings (often $30–$100/month) are negligible compared to the drug's high cost (often $1,000/month), making it unlikely to be a cost-saving measure. There was also skepticism regarding the headline's accuracy, with users pointing out that the savings might be offset by increased spending on more expensive healthy foods or dining out (a Bloomberg article was cited suggesting GLP-1 users spend more at restaurants). Finally, some debated the permanence of these changes, worrying that the food industry might engineer additives to counteract the drugs' effects or that users would revert to old habits upon discontinuation.

---

## [Postal Arbitrage](https://walzr.com/postal-arbitrage)
**Score:** 399 | **Comments:** 201 | **ID:** 46591708

> **Article:** The article "Postal Arbitrage" by Riley Walz describes a creative "life hack" that exploits Amazon's delivery system. The author observed that it is sometimes cheaper to order a small, lightweight item from Amazon (like a single lime or a phone case) and have it gift-wrapped with a personal message than it is to send a standard postcard via the US Postal Service. The article details sending a lime with a message to a friend for a low cost, framing it as a form of modern, digital-to-physical arbitrage. The piece is presented in a lighthearted, experimental tone, exploring the strange efficiencies and inefficiencies of modern logistics.
>
> **Discussion:** The Hacker News discussion on "Postal Arbitrage" was multifaceted, with users exploring the financial, philosophical, and practical aspects of the idea. A central debate revolved around the true cost of the hack. Many pointed out that the "sunk cost" of an existing Amazon Prime subscription makes the marginal cost of the item the only relevant factor, while others countered that the subscription fee itself must be factored in for anyone not already a member. The discussion also touched on the environmental impact, with some criticizing the wastefulness of the system while others argued the carbon footprint of the item's journey was negligible compared to the final delivery leg.

Several commenters connected the concept to historical precedents, most notably Charles Ponzi's original scheme, which was also a form of postal arbitrage involving International Reply Coupons. The conversation also branched into broader critiques of Amazon's business model and its relationship with the USPS, with some viewing the hack as a way to "burn" Amazon's capital and others expressing frustration with unsolicited mail. Finally, many participants engaged with the idea's novelty and social experience, debating whether receiving a lime with a printed message could ever replicate the personal touch of a handwritten card, or if it was simply a clever but soulless gimmick.

---

## [Date is out, Temporal is in](https://piccalil.li/blog/date-is-out-and-temporal-is-in/)
**Score:** 381 | **Comments:** 149 | **ID:** 46589658

> **Article:** The article "Date is out, Temporal is in" argues that JavaScript's built-in `Date` object is fundamentally flawed for handling human-centric time (like dates and times with time zones) because it is actually just a wrapper around a Unix timestamp. It conflates absolute points in time with calendar dates, leading to confusing behavior and bugs.

The author introduces the new Temporal API as the solution. Temporal provides distinct objects for different time concepts (e.g., `Temporal.PlainDate`, `Temporal.Instant`, `Temporal.ZonedDateTime`), making date logic predictable and immutable. The article serves as a high-level introduction to the API's benefits, positioning it as a modern, correct replacement for `Date` and libraries like Moment.js.
>
> **Discussion:** The Hacker News discussion is largely skeptical of the article's headline, focusing on the current reality of Temporal's availability and practical trade-offs. The consensus is that while Temporal is a necessary and well-designed improvement, it is far from being "in" for most production environments.

Key points of discussion include:
*   **Premature Adoption:** The most common criticism is that native Temporal support is extremely low (around 1.8%), with Safari and older browser versions lacking support entirely. Commenters note that for many organizations, it will be years before they can use it natively, making the article's title misleading.
*   **Polyfill Concerns:** While a polyfill exists, its large size (~51KB) is a significant drawback for client-side applications, though it's a viable option for server-side use.
*   **API Design and Philosophy:** There was a debate about the API's design. Some users appreciate the clear separation of concerns (e.g., `Instant` vs. `PlainDate`), while others found it cumbersome or questioned certain design choices. The discussion clarified that Temporal objects are immutable, a major improvement over `Date`.
*   **Comparison to Past Libraries:** Commenters frequently mentioned the pain of using `moment.js` (due to its large bundle size) and compared Temporal to alternatives like `Luxon` and `js-joda`.
*   **Developer Pain Points:** Many agreed that the existing `Date` API is notoriously difficult to work with, validating the article's core premise, even if they disagreed with the "Temporal is in" conclusion.

Overall, the community agrees that Temporal is the future, but the present is dominated by caution due to browser compatibility and the cost of polyfills.

---

## [LLVM: The bad parts](https://www.npopov.com/2026/01/11/LLVM-The-bad-parts.html)
**Score:** 335 | **Comments:** 64 | **ID:** 46588837

> **Article:** The article "LLVM: The bad parts" by Nikita Popov (author is a PHP core developer) provides a critical look at the practical difficulties of working with the LLVM compiler infrastructure. While acknowledging its power, the author highlights several major pain points:

*   **Compilation Speed:** LLVM is notoriously slow to compile, both for the project itself and for languages that rely on it (like Rust). This is a regression from its early days when it was marketed as faster than GCC.
*   **API Instability:** Despite the existence of a C API intended for stability, the internal C++ APIs and even parts of the C API (like the Orc JIT library) change frequently, making it difficult for frontend developers to keep up.
*   **Documentation and Complexity:** The system is incredibly complex and poorly documented. Key components like SelectionDAG and GlobalISel lack clear, executable specifications, forcing developers to reverse-engineer the code to understand the precise semantics of operations.
*   **Debuggability:** The sheer complexity makes it hard to reason about and debug issues, especially when they arise from the interaction between different optimization passes.
*   **Contribution Challenges:** The review process for LLVM can be slow and unrewarding for contributors, as it requires significant expertise and offers little direct benefit to the reviewer or their employer.

The author concludes that while LLVM is powerful, its high complexity, poor documentation, and unstable APIs create significant barriers for those who need to build upon it.
>
> **Discussion:** The Hacker News discussion largely validates the article's points, with many commenters sharing their own experiences with LLVM's challenges. Key themes include:

*   **Compilation Time:** This is a major point of frustration. Users reminisce about LLVM's original promise of fast compilation, noting that it is now extremely slow. Some mention alternatives like Cranelift or a proposed faster O0 backend for LLVM as potential solutions, but acknowledge that LLVM's feature set is hard to match.
*   **Trust and Safety:** A few commenters express unease that systems programming languages like Rust, which emphasize safety, are built on top of a massive, difficult-to-audit compiler like LLVM. The counterpoint is that the Rust project actively contributes back to LLVM, helping to fix bugs that benefit everyone.
*   **Compiler Engineering Issues:** The discussion delves into specific technical problems. One thread focuses on register pressure and the Loop Invariant Code Motion (LICM) pass, debating whether the issue lies with the optimizer or the register allocator. Another commenter strongly agrees with the article's point about poor documentation for backend development (SelectionDAG/GlobalISel), calling for a comprehensive, IR-based test suite.
*   **API Instability:** A developer directly contradicts the article's claim that the C API is stable, citing the Orc JIT API as a specific example of a C API that changes "wildly."
*   **Organizational Challenges:** The difficulty of contributing to LLVM is reinforced by a comment noting that even inside companies, motivating engineers to perform high-quality code reviews is a persistent problem.

Overall, the community sentiment aligns with the article's critical perspective, treating it as a well-articulated summary of long-standing, known issues within the LLVM ecosystem.

---

## [Anthropic made a mistake in cutting off third-party clients](https://archaeologist.dev/artifacts/anthropic)
**Score:** 294 | **Comments:** 196 | **ID:** 46586766

> **Article:** The article argues that Anthropic made a strategic error by blocking third-party clients (like OpenCode and Crush) from using its paid "Claude Code" subscriptions. The author contends that users of these alternative tools are not trying to exploit the system, but are seeking a better user experience than what Anthropic's official client offers. They describe the official Claude Code tool as buggy, slow, and lacking in features compared to community-built alternatives. By cutting off these users instead of improving its own product, the author suggests Anthropic is prioritizing control over customer satisfaction, potentially damaging its reputation and long-term moat ahead of an IPO.
>
> **Discussion:** The discussion reveals a sharp divide between understanding the business rationale and expressing frustration with the user experience. A major theme is the tension between Anthropic's product quality and its policies. Several users echo the article's sentiment, describing the official Claude Code client as buggy, slow, and lacking features, making third-party tools a necessity for a smooth workflow. They argue that Anthropic should focus on building a better product to win users, rather than locking them in.

Conversely, many commenters defend Anthropic's decision as a standard and necessary business strategy. They explain that in a market where AI models are becoming interchangeable commodities, companies must create "stickiness" to survive. Forcing users onto their own client is a classic tactic to control the user experience and prevent their service from becoming a low-margin utility. One user provides a detailed economic argument, stating that without lock-in, perfect competition will drive profits to zero, making the current business model unsustainable.

The conversation also touches on the identity of the "vibe-coder" mentioned in the article, with some users unfamiliar with the term while others point to his influence in the AI coding community. There is also a philosophical debate on whether boycotting is an effective response, with some arguing it's futile without viable alternatives, while others see it as a valid reaction to a company "taking its customers for granted."

---

## [The chess bot on Delta Air Lines will destroy you (2024) [video]](https://www.youtube.com/watch?v=c0mLhHDcY3I)
**Score:** 234 | **Comments:** 210 | **ID:** 46593395

> **Article:** The article is a YouTube video titled "The chess bot on Delta Air Lines will destroy you." It presumably showcases a chess game played against the in-flight entertainment system on a Delta flight, highlighting the surprisingly high difficulty of the AI opponent. The video frames this as a cautionary tale for casual players who might expect an easy game, only to be "destroyed" by the bot.
>
> **Discussion:** The Hacker News discussion reveals a significant split in user experiences with the Delta chess bot, leading to speculation about why its difficulty varies so wildly.

The primary debate centers on whether the bot is beatable or a formidable opponent. Several users, including a self-described 1600-2000 ELO player, claim to have beaten it easily, describing it as "bad" or prone to random blunders. Conversely, an even higher-rated player (2100 ELO) states they were "destroyed every single time," noting the bot knew opening theory and played without blunders. This discrepancy led to two main theories:

1.  **Hardware Differences:** The most popular theory is that the bot's difficulty was originally set by limiting its computation time (e.g., "think for one second"). As airplane hardware improved over the years, the same time limit allowed the engine to perform a much deeper analysis, turning an "easy" mode into a near-grandmaster level opponent. This is compared to the "Turbo button" on old PCs or a similar bug in macOS Chess.

2.  **Inconsistent Implementation:** Some users suggest the bot might intentionally play strong moves but occasionally insert a random blunder to make it beatable, though this doesn't fully explain the wildly different reports.

An amusing side-discussion involves a user mistakenly claiming to "crush" poker apps with card-counting skills, which others quickly point out is a skill for Blackjack, not Poker.

---

## [X Didn't Fix Grok's 'Undressing' Problem. It Just Makes People Pay for It](https://www.wired.com/story/x-didnt-fix-groks-undressing-problem-it-just-makes-people-pay-for-it/)
**Score:** 199 | **Comments:** 160 | **ID:** 46592827

> **Article:** The Wired article argues that X (formerly Twitter) has failed to address the misuse of its AI image generator, Grok. Instead of fixing the problem, X has commercialized it by requiring users to pay for a subscription to generate images, turning a widespread harassment tool into a premium feature. The piece details how Grok was used to create a deluge of non-consensual "undressing" images and deepfakes, primarily targeting women, and how these images were often posted publicly in replies, creating a hostile environment. The article contrasts Grok's permissive nature with the stricter safety guardrails of competitors like ChatGPT and Gemini, suggesting Grok's lack of moderation is a deliberate choice to attract users.
>
> **Discussion:** The Hacker News discussion largely validates the article's claims, with users confirming that Grok's public reply stream was flooded with non-consensual deepfakes. A central debate emerged over the comparison of Grok to tools like Photoshop. While some argued that Grok merely automates what is already possible manually, others countered that this is a disingenuous equivalence. They argued that Grok acts as a turnkey service that lowers the barrier to harassment and, crucially, posts the harmful content publicly through its own account, making the platform complicit. The discussion also highlighted the platform's perceived hypocrisy, noting that while X polices speech (e.g., flagging the term "cisgender"), it allows and profits from the generation of misogynistic and potentially illegal content. Ultimately, many commenters felt that the "inevitability" of such technology doesn't excuse corporate negligence and that the core issue is a lack of will to moderate a platform designed for scale, not safety.

---

## [Zen-C: Write like a high-level language, run like C](https://github.com/z-libs/Zen-C)
**Score:** 192 | **Comments:** 117 | **ID:** 46587804

> **Article:** Zen-C is a new programming language that aims to provide the productivity of a high-level language while compiling to readable C for performance and interoperability. The project recently appeared on GitHub, gaining significant attention quickly. Its syntax is intentionally similar to Rust, featuring manual memory management, traits, and comptime-like features. The core value proposition is to allow developers to write safer, more ergonomic code that can seamlessly integrate with existing C libraries and toolchains, and can be deployed on bare-metal systems without a complex runtime.
>
> **Discussion:** The Hacker News discussion centered on the language's identity, its technical trade-offs, and its place in the modern systems programming landscape.

A dominant theme was the language's striking resemblance to Rust. Commenters noted that the syntax is nearly identical, with minor variations like capitalized type names (e.g., `I8` vs `i8`). This led to skepticism about its purpose, with some wryly calling it "Rust for people who are allergic to using Rust." The question of "why not just use Rust?" was raised, with one user pointing to the philosophical debate about C's merits (citing SQLite's "Why C?" document) as a potential reason for its existence.

The choice of compiling to C, rather than directly to assembly or another language, was a key point of analysis. Users identified several advantages to this approach:
*   **Ecosystem Access:** It allows for easy integration with the vast world of C libraries, a major hurdle for new languages.
*   **Tooling:** It can leverage the mature ecosystem of C-based tools for verification and analysis.
*   **Portability:** By compiling to C, it can run on any platform with a C compiler, including bare-metal and embedded systems, without needing to implement a new runtime.
*   **Optimization:** It offloads the heavy lifting of optimization to established compilers like GCC and Clang.

Many commenters drew direct comparisons to other languages that use a similar transpilation model, such as Nim, Vala, and Crystal. The project was also compared to Zig, which offers similar features like C ABI support, manual memory management, and comptime.

Finally, the discussion touched on specific language features. The `repeat N` loop syntax was highlighted as a particularly nice and intuitive feature. However, some users also pointed out areas for potential improvement, such as the syntax for zero-initialized arrays and the behavior of traits. Overall, the project was received as an interesting and well-executed experiment, though its ultimate niche and adoption remain uncertain in a market increasingly dominated by Rust and Zig.

---

## [Windows 8 Desktop Environment for Linux](https://github.com/er-bharat/Win8DE)
**Score:** 190 | **Comments:** 188 | **ID:** 46588132

> **Article:** The article links to a GitHub repository for "Win8DE," a project that aims to recreate the Windows 8 desktop environment (specifically the Metro/Modern UI) for Linux. It is a theming project designed to make a Linux desktop look and feel like Windows 8.
>
> **Discussion:** The discussion is largely a nostalgic reflection on Windows 8's UI, with a mix of praise and criticism. Many commenters express fondness for the Metro/Modern UI, particularly its smoothness, simplicity, and focus on touch, with some sharing positive memories of their Windows Phone devices. There's a sense that the UI was innovative and ahead of its time, and some hope the Linux project can succeed where Microsoft faltered.

However, this nostalgia is tempered by significant criticism. Detractors recall the UI as being frustrating on non-touch devices, particularly the jarring full-screen "Start Menu" that broke user workflow on large desktop monitors. The debate highlights a key failure of Windows 8: forcing a touch-first interface onto traditional desktop users. Skepticism is also raised about the project itself, with one user arguing that hobbyist FOSS projects often fail to deliver the polished user experience (UX) required for complex GUIs. A few comments also point out that the project is purely a visual theme and lacks the underlying application framework (like XAML/WinRT) that would make it a complete clone.

---

## [Google removes AI health summaries after investigation finds dangerous flaws](https://arstechnica.com/ai/2026/01/google-removes-some-ai-health-summaries-after-investigation-finds-dangerous-flaws/)
**Score:** 183 | **Comments:** 117 | **ID:** 46595419

> **Article:** An article from Ars Technica reports that Google has removed some of its AI-generated health summaries from search results following an investigation that revealed "dangerous flaws." The AI overviews were found to provide inaccurate, misleading, or potentially harmful medical information. The article highlights this as a significant setback for Google's AI integration into search, particularly in a high-stakes domain like healthcare where misinformation can have serious consequences. The original Guardian investigation is cited as the primary source.
>
> **Discussion:** The Hacker News discussion is highly critical of Google's AI implementation, with commenters expressing a mix of frustration, concern, and not-so-surprised resignation. The conversation can be broken down into several key themes:

*   **The Unacceptability of Errors in Healthcare:** There is a strong consensus that the stakes in healthcare are too high for AI to be unreliable. As one user noted, healthcare is a "life and death" domain that requires a "human in the loop" approach rather than full automation. Another commenter shared a personal anecdote of the AI providing "bordering on criminal" information about their medication, reinforcing the real-world danger.

*   **Broader Failures of Google's AI Summaries:** The problems are not seen as isolated to health. Users report the AI consistently fails by mixing factual sources with fan fiction or wishful thinking (e.g., Minecraft queries, a fake Tesla wheelchair). It's described as actively degrading the search experience, making it harder to find reliable information and burying legitimate sites under AI-generated "slop" and ads.

*   **Brand Damage and Baffling Strategy:** Many commenters are mystified by why Google continues to deploy such a flawed product. They argue it's "wrecking the brand" and represents the "final nail in the coffin of search." The quality is seen as inexplicably poor compared to other available AI models.

*   **Skepticism of All AI in Health:** While Google is the target of this specific criticism, the discussion extends to a general wariness of AI in medicine. The mention of OpenAI's new "ChatGPT Health" service was met with skepticism, with users questioning if it would suffer from the same fundamental flaws.

*   **Regulatory and Liability Concerns:** A more technical point was raised about the legal framework, noting that any app making a medical recommendation could be classified as "Software as a Medical Device (SaMD)," which carries significant liability and regulatory oversight from bodies like the FDA.

---

## [Statement from Federal Reserve Chair](https://www.federalreserve.gov/newsevents/speech/powell20260111a.htm?mod=ANLink)
**Score:** 176 | **Comments:** 28 | **ID:** 46589489

> **Article:** The article is a statement from Federal Reserve Chair Jerome Powell delivered on January 11, 2026. In the statement, Powell reflects on his tenure and the Federal Reserve's performance. He defends the central bank's independence and its dual mandate of ensuring price stability and maximum employment. He acknowledges the economic challenges faced, particularly the post-pandemic inflation, but argues that the institution's actions were necessary to steer the economy. The statement appears to be a formal address, possibly a farewell or a defense of his legacy amidst political pressure.
>
> **Discussion:** The Hacker News discussion is highly critical of both Jerome Powell and the Federal Reserve, focusing on perceived failures and a lack of accountability.

A primary theme is the deep distrust in official economic data. Commenters argue that official inflation and unemployment figures are manipulated and do not reflect the reality experienced by ordinary Americans, who they claim face much higher costs of living. The Fed's handling of post-pandemic inflation is a major point of contention, with Powell's "transitory" characterization being frequently cited as a key example of incompetence that led to aggressive interest rate hikes and subsequent layoffs, particularly in the tech industry.

There is also a strong cynical view of the Fed as a self-serving institution. Commenters describe a "revolving door" between the Fed and major banks, suggesting that officials prioritize their careers and the preservation of the institution over their public mandate. This is framed as a lack of meritocracy and accountability.

Finally, the discussion is set against the political backdrop of the Trump administration's impending takeover. Users speculate on the motives, suggesting the move is driven by a desire for "revenge" and to install loyalists, rather than any specific economic policy goal. While Powell's term as Chair is ending, it's noted he may remain a governor, indicating the political battle for control of the Fed is ongoing.

---

## [Show HN: AI in SolidWorks](https://www.trylad.com)
**Score:** 162 | **Comments:** 85 | **ID:** 46591100

> **Project:** The project, "AI in SolidWorks," is a tool that attempts to use Large Language Models (LLMs) to automate tasks and generate 3D models within the SolidWorks CAD software. The creators acknowledge that out-of-the-box models are not inherently good at CAD and that the project is an exploration of how well they can perform with a well-engineered "harness" (integration layer). The core challenge is bridging the gap between the LLM's natural language capabilities and the precise, spatially-aware commands required by CAD software.
>
> **Discussion:** The Hacker News discussion reveals a community grappling with the practical realities of applying LLMs to complex, spatial domains like CAD. The conversation highlights several key themes:

A central debate is the suitability of text as a user interface for 3D modeling. While the project uses a chat interface, some commenters argue that most people struggle to articulate spatial concepts with the precision required, and current LLMs have a poor innate understanding of 3D space. This is evidenced by common failures like choosing the wrong plane for a sketch or misunderstanding geometric relationships.

Technical approaches and challenges were a major focus. One commenter shared their parallel work with Altium (PCB design), describing a multi-LLM system where one model (like Opus) generates high-level natural language instructions ("place U1 to the left of U4"), which a second model translates into a structured JSON DSL for execution. This "LLM-to-LLM" translation was seen as more effective than asking a single LLM to write raw API code, a point the project creator confirmed, stating they found LLM-generated SolidWorks API scripts to be largely unreliable. A recurring problem is the LLMs' weakness in spatial reasoning, which often requires specific prompting or human correction to fix.

The discussion also touched on the broader context and future of AI in this field. Commenters expressed skepticism about the defensibility of such businesses, noting that the core techniques could be bootstrapped by individuals with sufficient technical skill. There was a call for specialized models trained on CAD datasets, rather than relying on general-purpose LLMs. Alternatives were also mentioned, such as using code-based CAD tools like OpenSCAD, which might be a more natural fit for LLMs, and other "text-to-3D" tools for the early, conceptual stages of design. Finally, a tangential but popular thread lamented the stagnation of the SolidWorks user interface over the last 15 years.

---

## [Fabrice Bellard's TS Zip (2024)](https://www.bellard.org/ts_zip/)
**Score:** 161 | **Comments:** 65 | **ID:** 46593802

> **Article:** Fabrice Bellard has released "ts_zip," a novel compression utility that combines a Large Language Model (LLM) with arithmetic coding to achieve state-of-the-art lossless text compression. The core idea is that an LLM, having been trained on vast amounts of text, can accurately predict the next token in a sequence. Arithmetic coding then encodes this sequence using the minimum number of bits required based on the LLM's probability distribution. This method effectively compresses text by "understanding" its structure and context, rather than just finding statistical redundancies like traditional algorithms. The tool demonstrates remarkable performance on standard benchmarks like enwik8, showcasing the potential of AI-driven compression.
>
> **Discussion:** The Hacker News discussion centered on the technical validity and fairness of comparing ts_zip to traditional compressors. A primary point of debate, raised by dmitrygr and elaborated by AnotherGoodName, was that the benchmark results are misleading because they don't include the size of the pre-trained LLM (150MB) in the compressed size. This is a critical issue, as the Large Text Compression Benchmark (LTCB) rules require including the program size to measure Kolmogorov complexity and prevent trivial solutions. Commenters noted that ts_zip's impressive results stem from its massive "head start" in knowledge, unlike other top-ranked LTCB programs that learn from the data as they compress it.

Many users delved into the underlying mechanics, explaining that the process relies on arithmetic coding, which can use fractional bits to encode data based on a model's predictions. The consensus was that the true challenge in compression is not the encoding itself (which is a solved problem) but creating a highly accurate predictive model of the data. The discussion also touched on related concepts, such as how this process is lossless (unlike the "game of telephone" analogy) and its applications in steganography. The thread was filled with admiration for Bellard, with commenters humorously referencing his legendary status in the programming community.

---

## [Iran has now been offline for 96 hours](https://twitter.com/netblocks/status/2010750871274160361)
**Score:** 155 | **Comments:** 161 | **ID:** 46591974

> **Article:** The article links to a tweet from NetBlocks, an internet monitoring group, reporting that Iran has been offline for 96 hours. This indicates a severe, government-imposed internet blackout in response to widespread civil unrest and protests against the regime.
>
> **Discussion:** The discussion centers on the nature of the protests, the effectiveness of the internet blackout, and the geopolitical implications.

Commenters express a mix of hope and pessimism regarding the uprising's chances of success. While some are hopeful that this could signal the end of the current regime, others are more skeptical, pointing to the regime's strong ideological base and the potential for a bloody civil war rather than a peaceful transition.

A significant portion of the conversation focuses on the technological battle for information. Users discuss the potential for Starlink to circumvent the blackout, but it's noted that Iran appears to be jamming the service, possibly by targeting the GPS signals the dishes rely on. The practicality of locating and seizing dishes on the ground is also raised as a challenge for the regime.

Finally, the discussion becomes highly politicized. One user argues that Western powers, particularly the US and Israel, are not genuinely interested in Iranian freedom but are backing the protests to install a pro-Western regime for their own geopolitical benefit. This view is challenged by others who find little evidence for such claims. The conversation also touches on the idea that the timing of the major news event is being overshadowed by domestic political turmoil in the United States.

---

## [Ireland fast tracks Bill to criminalise harmful voice or image misuse](https://www.irishtimes.com/ireland/2026/01/07/call-to-fast-track-bill-targeting-ai-deepfakes-and-identity-hijacking/)
**Score:** 143 | **Comments:** 92 | **ID:** 46588319

> **Article:** The Irish Times article reports that the Irish government is fast-tracking a new bill to criminalize the malicious misuse of a person's voice and image. The legislation is a direct response to a surge in sophisticated AI-generated deepfake scams, particularly those featuring the likeness of politicians like former Taoiseach Simon Harris to promote fraudulent cryptocurrency schemes. The bill aims to create a new criminal offense for knowingly using a person's name, image, or voice without consent for malign purposes, where it causes harm such as alarm, distress, or serious interference with their peace and privacy. The goal is to provide a specific legal tool to combat identity hijacking and AI-driven disinformation that existing laws may not adequately cover.
>
> **Discussion:** The Hacker News discussion reveals a mix of skepticism, concern, and pragmatic analysis of the proposed Irish bill. A central theme is the fear of overreach and vagueness. Several users question how the bill's definitions of "misuse" and "harm" (e.g., causing "alarm or distress") would be applied in practice, worrying it could conflict with freedom of expression, such as journalistic reporting on criminals or political criticism. One commenter pointed out that the bill's broad wording could even make standard newspaper reporting illegal.

However, the context provided by other users grounded the debate. It was clarified that the primary driver is a specific and widespread problem: scam ads using deepfakes of Irish politicians to defraud citizens. This context led to a debate on enforcement. Some cynics argued that existing fraud and advertising laws should already cover these scams, and the real issue is a lack of enforcement against the platforms hosting them. Others countered that the novel nature of AI-generated fakes necessitates new, specific legislation.

The discussion also branched into broader regulatory philosophies. A key point of contention was whether to regulate the tools or the users. Some advocated for criminalizing the harmful *use* of AI, while others argued for stopping the problem at the source by regulating the AI models and platforms themselves. The conversation also touched on the international limitations of such a national law and drew parallels to the UK's approach, with users expressing deep-seated suspicion that such laws could be used as a pretext for censorship and authoritarian control, despite the stated goal of protecting people from harm.

---

## [Launch a Debugging Terminal into GitHub Actions](https://blog.gripdev.xyz/2026/01/10/actions-terminal-on-failure-for-debugging/)
**Score:** 142 | **Comments:** 58 | **ID:** 46587498

> **Article:** The article, "Launch a Debugging Terminal into GitHub Actions," presents a custom tool created by the author to solve a common developer pain point: debugging failing CI/CD workflows. The tool works by using a reverse shell and a browser-based terminal to provide an interactive session directly into a running GitHub Actions runner. This allows developers to inspect the environment, run commands, and diagnose issues in real-time, rather than relying on slow, iterative cycles of pushing code to see logs.
>
> **Discussion:** The Hacker News discussion reveals a strong consensus that debugging CI/CD pipelines is a significant productivity problem, but opinions diverge on the best solution. The core of the conversation revolves around the lack of a native "SSH into runner" feature in GitHub Actions, a capability that was famously pioneered by CircleCI and is seen by many as a "table-stakes" feature. Commenters express frustration that GitHub has failed to address this need, leading to a proliferation of community-built tools like the one in the article and the popular `action-tmate`.

Several distinct viewpoints emerge:
*   **The Self-Hosted Runner Argument:** A prominent school of thought argues that the real solution is to use self-hosted runners. This provides direct access for debugging and offers performance benefits like better caching, completely bypassing the limitations of ephemeral cloud runners.
*   **The Reproducibility Counter-Argument:** A direct rebuttal to the self-hosted approach is that workflows should be made entirely reproducible locally. This avoids the need for remote access altogether but is acknowledged to be difficult, as it doesn't replicate cloud-specific context like authentication tokens and environment variables.
*   **The "Good Enough" Workaround:** Many developers are already using existing third-party tools, primarily `action-tmate`, which is praised for its simplicity and effectiveness. However, a key concern is security and corporate policy, as these unofficial actions are often not "verified," preventing their use in enterprise environments.
*   **The Broader Platform Critique:** The issue is framed as a symptom of a larger problem with GitHub Actions, with some users expressing general dissatisfaction with its complexity and the YAML-heavy configuration, contrasting it with the perceived stability and simplicity of older platforms like CircleCI.

Ultimately, while the author's tool is praised as a clever hack, the discussion highlights a deep-seated desire for a first-party, secure, and officially supported debugging solution from GitHub.

---

