# Hacker News Summary - 2026-01-14

## [Scott Adams has died](https://www.youtube.com/watch?v=Rs_JrOIo3SE)
**Score:** 750 | **Comments:** 1230 | **ID:** 46602102

> **Article:** The article links to a YouTube video announcing the death of Scott Adams, the creator of the Dilbert comic strip. A comment provides details from Wikipedia, stating Adams died at 68 from prostate cancer. His final months were marked by a rapid decline; in late 2025 he publicly sought help accessing a cancer drug, and by January 2026 he announced he was paralyzed, had heart failure, and was entering a "month of transition" before entering hospice.
>
> **Discussion:** The discussion is a mix of immediate reactions and a retrospective on Scott Adams' complex legacy. Many commenters expressed sadness and acknowledged the brilliance of *Dilbert*, noting that it provided timeless and essential insight into corporate culture. However, a recurring theme is the division between his work and his later-life persona; several users noted that his political opinions eventually came to overshadow his creative work. The conversation also touched on the practicalities of mortality, with one user musing on the "Boomer junk" left behind and the fading of cultural icons from previous generations. The swiftness of his decline was noted as particularly shocking.

---

## [AI Generated Music Barred from Bandcamp](https://old.reddit.com/r/BandCamp/comments/1qbw8ba/ai_generated_music_on_bandcamp/)
**Score:** 575 | **Comments:** 436 | **ID:** 46605490

> **Article:** The article links to a Bandcamp blog post announcing a new policy to bar AI-generated music from its platform. The post, titled "Keeping Bandcamp Human," establishes that music uploaded to Bandcamp must be created by humans, not generated by AI. This move is positioned as a commitment to supporting genuine human artistry and preventing the platform from being flooded with low-effort, automated content. The policy aims to preserve Bandcamp's identity as a home for artists and their communities.
>
> **Discussion:** The discussion on Hacker News is largely supportive of Bandcamp's decision, with many commenters expressing frustration over the proliferation of low-quality "AI slop" on other platforms like Spotify. A key theme is the negative impact of AI-generated content on music discovery and the user experience, with some sharing personal anecdotes of being recommended AI music or seeing it used to hijack established artists' pages.

However, the conversation also explores the nuances of AI's role in music creation. Several commenters distinguish between fully AI-generated tracks and music where AI is used as a tool to assist a human creator (analogous to "vibe coding"). This leads to a debate on where the line should be drawn. One prominent viewpoint is that AI assistance is acceptable, especially for amateurs or as a creative tool, while another insists that platforms like Bandcamp should remain exclusive to human-led artistic effort.

The discussion also touches on the practical challenges of enforcement, questioning how Bandcamp will identify AI-generated music. Ultimately, the conversation centers on the value of human intention and effort in art, with many agreeing that Bandcamp's policy helps protect that value and reinforces its position as a curated space for artists, in contrast to the algorithm-driven, volume-focused approach of streaming giants.

---

## [Apple Creator Studio](https://www.apple.com/newsroom/2026/01/introducing-apple-creator-studio-an-inspiring-collection-of-creative-apps/)
**Score:** 475 | **Comments:** 391 | **ID:** 46601157

> **Article:** Apple announced "Apple Creator Studio," a new subscription service for its suite of professional creative applications. The subscription bundles Final Cut Pro, Logic Pro, Pixelmator Pro, Motion, Compressor, and MainStage, and also adds new AI features to Keynote, Pages, and Numbers. The service is priced at $12.99/month or $129/year, with a significant educational discount available at $2.99/month or $29.99/year. Apple clarified that the traditional one-time purchase options for these Mac applications will remain available alongside the new subscription model.
>
> **Discussion:** The announcement sparked a mixed but largely pragmatic discussion. The primary debate centered on the business model, with some users immediately expressing frustration at another subscription service, while others quickly pointed out that one-time purchases are still an option. The price was generally viewed as competitive, especially the educational discount, which many saw as a strong value proposition.

Key themes in the discussion included:
*   **Market Strategy:** Commenters saw this as a direct attempt by Apple to capture market share from Adobe and compete with Microsoft's suite packaging, though some noted it wasn't a direct challenge to MS Office.
*   **Value and Usefulness:** A point of contention was the bundle's utility for individuals who only need one or two of the apps. However, others countered that the individual apps can still be purchased separately.
*   **The iPad/iPadOS Dilemma:** A significant tangent emerged regarding the limitations of iPadOS for professional work. Users expressed frustration that despite the creative focus, Apple has not released a full version of Xcode for iPad, citing the platform's restrictive nature (code signing, containerization) as a major barrier for developers.
*   **General Skepticism:** Underlying the discussion was a general cynicism towards Adobe's subscription model and a concern that Apple might eventually phase out one-time purchases. There was also some nostalgia for discontinued Apple software like Aperture and disappointment that the new Pixelmator suite wasn't more integrated.

---

## [Scott Adams has died](https://www.usatoday.com/story/entertainment/celebrities/2026/01/13/scott-adams-dead-dilbert-creator-prostate-cancer/88158828007/)
**Score:** 417 | **Comments:** 3 | **ID:** 46603431

> **Article:** The article reports that Scott Adams, the creator of the widely syndicated comic strip *Dilbert*, has died at the age of 69. The cause of death was prostate cancer, which he had publicly disclosed diagnosised in 2024. The piece highlights Adams' career, noting *Dilbert's* massive success in depicting office culture and its adaptation into a TV series, while also acknowledging the controversy that led to the strip's cancellation by newspapers in 2022 following Adams' racially charged comments.
>
> **Discussion:** The discussion on Hacker News was minimal due to the post being a duplicate. The few visible comments were administrative notes from moderators confirming that the comments had been moved to the original thread (item 46602102). There were no substantive discussions about Scott Adams' life or work in this specific thread.

---

## [Chromium Has Merged JpegXL](https://chromium-review.googlesource.com/c/chromium/src/+/7184969)
**Score:** 412 | **Comments:** 140 | **ID:** 46597927

> **Article:** The article links to a Chromium code review entry confirming that support for the JPEG XL image format has been merged into the Chromium source code. This marks a significant step for the format, enabling it to be used in Chrome and other Chromium-based browsers. The feature includes support for progressive decoding, wide color gamut, HDR, high bit depth, and animation.
>
> **Discussion:** The discussion is largely positive, with many commenters celebrating the news as a long-awaited improvement for web images. The primary reasons cited for JPEG XL's superiority over WebP and AVIF are its better compression efficiency (smaller file sizes for the same quality) and significantly faster encoding/decoding speeds, especially compared to the notoriously slow AVIF.

A key question raised is why Chromium was so reluctant to adopt JPEG XL for years. The community offers two main explanations:
1.  **Security and Maintenance:** The original C++ reference library (`libjxl`) was considered unmaintained and a potential security risk. The adoption is now possible due to a new, Rust-based implementation (`jxl-rs`), which alleviates these security concerns.
2.  **Corporate Strategy:** Google was accused of arguing that only one next-generation format was needed, and they had already backed their own WebP and AVIF formats.

There is some debate on the topic of Rust and security. While most agree Rust's memory safety is a major benefit, one commenter cautions that it can lead to developer overconfidence and that vigilant C programming with proper threat modeling can still be more secure than "complacent" Rust programming.

Other points of discussion include:
*   **Adoption:** Commenters acknowledge that, like WebP before it, JPEG XL will face a long adoption period. However, its inclusion in Chrome is seen as a critical precondition for it to gain traction on the web.
*   **Practicality:** Some users express frustration with new formats due to a lack of support in their existing software, while others point out that WebP is now a "boringly" safe and universally supported format.
*   **Specs and Standards:** A minor point of criticism is that the official JPEG XL specification is not freely available, which is seen as a "sham."
*   **Future Potential:** Commenters are excited about the possibility of JPEG XL replacing both JPEG and PNG, simplifying the web's image format landscape.

---

## [Local Journalism Is How Democracy Shows Up Close to Home](https://buckscountybeacon.com/2026/01/opinion-local-journalism-is-how-democracy-shows-up-close-to-home/)
**Score:** 361 | **Comments:** 247 | **ID:** 46600850

> **Article:** The article argues that local journalism is the bedrock of a functioning democracy, providing essential, granular coverage of civic life that national outlets cannot. It posits that the decline of local news—driven by the collapse of advertising revenue models and consolidation by large media conglomerates—creates an "accountability vacuum." Without reporters attending city council meetings or covering school boards, local governments and institutions are less scrutinized, leading to a disengaged citizenry and a weakened democratic process at the municipal level.
>
> **Discussion:** The Hacker News community largely concurred with the article's premise, expressing broad concern over the decline of local news. The discussion focused on the economic and structural causes of this trend, as well as potential solutions.

A primary theme was the economic unsustainability of local journalism following the collapse of its traditional revenue streams. Commenters noted that the loss of classified advertising (e.g., property listings, which were usurped by sites like Rightmove in the UK) was a critical blow. This led to consolidation by large media conglomerates, who, unlike local owners, lack accountability and often prioritize engagement-bait or simply shutter unprofitable papers without regard for the community.

The consequences of this decline were also a major point of discussion. Several users observed that the remaining local outlets often produce superficial "puff pieces" due to a reliance on access to power or local advertising, rather than hard-hitting investigative work. There was a debate on whether this results in a specific political bias, with one user claiming a left-leaning slant, while others countered that the bias is more accurately described as being pro-establishment or in favor of power, regardless of ideology.

Finally, the conversation explored potential solutions. Ideas ranged from individual action, such as subscribing to local papers or directly engaging with officials, to systemic changes. The most prominent systemic proposal was public funding for local journalism, with one user offering a detailed model for a municipal tax to fund a local journalist. However, this idea was met with skepticism regarding the potential for government influence over the press. Other suggestions included lean, non-profit models funded by community subscriptions, similar to Patreon, and leveraging social media platforms, though the latter was viewed with caution due to the prevalence of gossip and misinformation.

---

## [Anthropic invests $1.5M in the Python Software Foundation](https://discuss.python.org/t/anthropic-has-made-a-large-contribution-to-the-python-software-foundation-and-open-source-security/105694)
**Score:** 357 | **Comments:** 162 | **ID:** 46601902

> **Article:** Anthropic, the AI company behind the Claude chatbot, is investing $1.5 million into the Python Software Foundation (PSF). The funding is specifically earmarked to improve the security of the Python ecosystem, particularly the Python Package Index (PyPI). The initiative aims to develop new tools for automated, proactive security reviews of all packages uploaded to PyPI, moving beyond the current reactive-only process. This investment is part of a broader trend of major tech companies (like Amazon, Google, and Microsoft) funding the critical open-source infrastructure that their products and services rely on.
>
> **Discussion:** The Hacker News discussion surrounding the donation was multifaceted, with users analyzing the motivations, scale, and context of the investment.

A primary theme was the strategic importance of the donation. Many commenters recognized that this is a crucial investment in the security of the Python ecosystem, which is the foundation of the modern AI industry that Anthropic operates in. The discussion highlighted that PyPI, like NPM, is a major target for supply chain attacks, and this funding is a proactive step to mitigate that risk.

The size of the donation ($1.5 million) was a point of contention. Some users argued that for a company like Anthropic, this sum is "peanuts" and more of a PR move than a substantial contribution. However, others countered that it's a significant amount for a non-profit like the PSF and that shaming the company is counterproductive; it's better to encourage and acknowledge such contributions, even if they could be larger.

There was also a critical examination of the Python Software Foundation itself. One commenter criticized the PSF's past management for allegedly misallocating funds, prioritizing "outreach" over critical technical work like improving packaging, which forced the community to create external solutions. This suggests a concern that the new funds might not be used as effectively as possible.

Finally, the conversation broadened to the general topic of corporate responsibility for open-source infrastructure. Users referenced the book "Roads and Bridges" to argue that large tech companies and venture capitalists have a duty to fund the "unseen labor" of open-source projects that power their businesses. The donation was also contextualized as part of a larger trend of big tech (Google, Amazon, Microsoft) recognizing and funding the critical software they depend on. A tangential but popular thread discussed the value of type hints in Python for AI "agentic programming," linking the technical robustness of the language to the AI ecosystem.

---

## [Influencers and OnlyFans models are dominating U.S. O-1 visa requests](https://www.theguardian.com/us-news/2026/jan/11/onlyfans-influencers-us-o-1-visa)
**Score:** 347 | **Comments:** 248 | **ID:** 46603535

> **Article:** A Guardian article reports that influencers and OnlyFans models are increasingly securing U.S. O-1 visas, traditionally reserved for individuals with "extraordinary ability." The article highlights the case of an OnlyFans creator who successfully applied for the O-1B visa, which is designated for the arts, motion picture, and television industries. The piece notes that while the visa was once the domain of Hollywood stars and elite musicians, its criteria—such as high commercial success and remuneration—are now being met by top-tier social media and adult content creators, reflecting a shift in what constitutes modern cultural influence.
>
> **Discussion:** The Hacker News discussion presents a multifaceted debate on whether social media personalities and adult entertainers should qualify for the O-1 visa. The community's reaction is split between pragmatic acceptance and moral or categorical skepticism.

A significant portion of the discussion focuses on the legal and categorical justification for these visas. Commenters point out that the O-1B visa is broad enough to cover "extraordinary ability in the arts" and "commercial success," criteria that high-earning creators easily meet. Some argue that this is a logical evolution, placing digital entertainers in the same category as traditional actors or musicians. Others, however, express unease, questioning whether these professions align with the spirit of the visa, with one user noting the historical immigration penalties associated with prostitution and expressing surprise at the apparent shift.

A strong counter-argument frames this trend as fundamentally American. Proponents argue that the U.S. has always been a hub for cultural talent, and that today's influencers are simply the "future of culture." This view is supported by economic arguments: these creators are highly mobile, generate significant tax revenue without displacing local workers, and contribute to a balanced demographic profile of immigrants.

Finally, several commenters analyze the systemic implications. Some criticize the visa system for overvaluing popular metrics like views, which are easily gameable and favor public-facing professions over technical expertise. Others see the situation as a cynical but effective way for the government to tax a new form of wealth. A recurring theme is that if traditional entertainers and athletes are eligible, it is inconsistent to exclude modern digital stars, as they all operate within the broader entertainment industry.

---

## [Signal leaders warn agentic AI is an insecure, unreliable surveillance risk](https://coywolf.com/news/productivity/signal-president-and-vp-warn-agentic-ai-is-insecure-unreliable-and-a-surveillance-nightmare/)
**Score:** 321 | **Comments:** 96 | **ID:** 46605553

> **Article:** The article, based on warnings from Signal's president and VP, argues that "agentic AI" (AI systems that can perform actions on a user's behalf) represents a significant and underestimated security threat. The core concerns are twofold: these systems are fundamentally unreliable and insecure, creating a massive new attack surface. Secondly, they function as a "surveillance nightmare" by requiring broad access to user data and systems to be useful, which inevitably leads to the collection and potential misuse of sensitive information. The piece frames this as a critical risk that is being overlooked in the rush to deploy AI agents.
>
> **Discussion:** The Hacker News discussion largely validates the article's security concerns but adds layers of nuance regarding the root causes and practical realities.

A central theme is the debate over whether this is a problem with AI itself or with the underlying systems it operates on. One highly-upvoted comment argues this is fundamentally an "operating systems problem," asserting that AI is merely exposing long-neglected flaws in process isolation and security models that have existed since the days of UNIX. The counterpoint is that even perfect sandboxing is insufficient because for an AI agent to be useful, it must be granted trusted access to sensitive data and functions, creating an inherent conflict between utility and security.

The discussion also explores the tension between ideal security and pragmatic business decisions. One commenter distinguishes between Signal's role (prioritizing absolute security) and an enterprise IT manager's role (managing risk), suggesting their priorities are naturally different. This is echoed by others who note that while "agentic AI" is a powerful sales pitch, its unreliability and data leakage make it a liability for many businesses, especially when the risks are not fully understood or are externalized to the user via Terms of Service.

Finally, the conversation touches on corporate motivations and the difficulty of implementation. Some users are cynical about Signal's warnings, speculating it's a strategic move to promote their own upcoming AI privacy initiatives. Others share firsthand experience that even when companies try to implement secure policies for AI, enforcement is difficult and the "zero trust" principle is often ignored in practice.

---

## [Network of Scottish X accounts go dark amid Iran blackout](https://www.heraldscotland.com/news/25759181.network-scottish-x-accounts-go-dark-amid-iran-blackout/)
**Score:** 301 | **Comments:** 250 | **ID:** 46599574

> **Article:** An article in The Herald reports on a network of X (formerly Twitter) accounts, which posed as Scottish users, going dark during Iran's recent internet blackout. The investigation, originally from the UK Defence Journal and citing data from the disinformation firm Cyabra, suggests these accounts were linked to Iranian actors. The accounts spread outlandish disinformation, such as claims of military coups in Edinburgh, tanks in the streets, and the seizure of Balmoral Estate. The article posits that the blackout in Iran, which took these bot farms offline, provided a clear signal of their foreign origin.
>
> **Discussion:** The Hacker News discussion is highly skeptical of the article's premise and sources. The dominant theme is a debate over the true purpose of the disinformation campaign. While some users initially assume the goal was to influence Scottish people, others argue the outlandish nature of the claims makes that unlikely. The consensus leans towards the campaign being aimed at foreign audiences, particularly Americans, to reinforce pre-existing fears about Western societal collapse or to influence perceptions of Iran's geopolitical rivals.

A significant portion of the conversation focuses on the source of the intelligence. Commenters discovered the report originated from Cyabra, a Tel Aviv-based disinformation analysis firm. This led to widespread skepticism about the report's objectivity, with users questioning the motives of an Israeli company reporting on Iranian disinformation, especially amid the ongoing conflict. This skepticism was framed as a need to "consider the source."

The discussion broadened to a general critique of social media and the prevalence of inauthentic behavior online. Users shared anecdotes about encountering sock puppets on HN and other platforms, discussed the financial incentives for creating divisive content (citing a case of a Sri Lankan influencer making $300k posting racist content), and debated the role of platform algorithms in promoting "rage bait." The conversation also touched on the hypocrisy of focusing solely on Russian or Iranian bots while ignoring evidence of astroturfing by Western nations, with a user citing a historical example of traffic from a US Air Force base being the "most addicted city" on Reddit.

---

## [Text-based web browsers](https://cssence.com/2026/text-based-web-browsers/)
**Score:** 277 | **Comments:** 104 | **ID:** 46597518

> **Article:** The article "Text-based web browsers" argues that these browsers are becoming increasingly obsolete and incompatible with the modern web. It posits that the web's continuous evolution towards complex features, JavaScript-heavy applications (SPAs), and rich media creates an ever-widening gap that text-based browsers like w3m cannot bridge. The author concludes that there is "no success story in sight" for text-based browsing on the conventional web, suggesting that its future lies in entirely separate protocols like Gemini rather than trying to adapt the current web.
>
> **Discussion:** The Hacker News discussion largely validates the article's premise but also explores nuances and alternatives. A central theme is the consensus that the modern web is fundamentally hostile to text-based browsers. One commenter vividly describes the futility of trying to use "lite" versions of sites, as they are just one click away from a JavaScript-heavy SPA that breaks the experience. The general sentiment is that the web's feature-hungry nature makes true text compatibility a losing battle.

However, the conversation pivots to the practical value of text-based browsers, especially for developers and in specific scenarios. Several users champion specific tools:
*   **Chawan** is highlighted as a modern and impressive browser that handles CSS and JS in the terminal, offering a more "real" browsing experience.
*   **edbrowse** is praised for its unique CLI-driven, line-oriented approach, which is valued for its scriptability, accessibility (its main developer is blind), and a different kind of user comfort.

Beyond specific software, the discussion touches on broader challenges and use cases:
*   **Infrastructure Barriers:** A key problem is that text browsers are often blocked by services like Cloudflare or, more recently, Google Search, which now rejects requests from browsers like Lynx.
*   **Developer Responsibility:** Some argue that better web development practices (e.g., placing navigation at the bottom of the HTML) could significantly improve the text-browser experience.
*   **Niche but Essential Use Cases:** Commenters defend the utility of text browsers for critical situations like troubleshooting a broken graphical environment, working on headless servers via SSH, or for automated crawling.

Finally, a few comments touch on potential future solutions, such as using AI to scrape and reformat content for text display, though this is presented as a brainstorm rather than a concrete solution.

---

## [We can't have nice things because of AI scrapers](https://blog.metabrainz.org/2025/12/11/we-cant-have-nice-things-because-of-ai-scrapers/)
**Score:** 265 | **Comments:** 151 | **ID:** 46608840

> **Article:** The article from MetaBrainz, a project that maintains open music metadata (like MusicBrainz), details how they are being forced to restrict access to their services due to aggressive AI web scrapers. These scrapers are overloading their volunteer-run infrastructure by ignoring `robots.txt`, bypassing efficient bulk download options, and hammering individual API endpoints page-by-page. To keep the service running, MetaBrainz is implementing stricter authentication and rate limits, which unfortunately negatively impacts legitimate users and the project's open ethos.
>
> **Discussion:** The Hacker News discussion largely validates the article's premise, with users sharing similar frustrations about AI scrapers degrading the open web. A central theme is the inefficiency and bad etiquette of these scrapers; they ignore provided bulk data dumps (like the one MetaBrainz offers) in favor of hitting individual pages or APIs, which is costly for the host. This is described as a "tragedy of the commons," where AI companies externalize their infrastructure costs onto small, volunteer-run projects.

While some commenters debate the severity of the changes to the API, the consensus is that the scrapers are forcing projects to lock down, hurting legitimate developers and researchers in the process. Several users noted that this is a widespread problem, leading them to close their own public sites or hide them behind paywalls. Proposed solutions ranged from technical fixes like Cloudflare's AI detection and tarpits, to systemic changes like a standardized `/.well-known/` path for data dumps, to a simple economic expectation that AI companies should eventually become more efficient or be forced to cooperate with data providers.

---

## [90M people. 118 hours of silence. One nation erased from the internet](https://state-of-iranblackout.whisper.security/)
**Score:** 255 | **Comments:** 317 | **ID:** 46603910

> **Article:** The linked article, titled "90M people. 118 hours of silence. One nation erased from the internet," reports on a severe internet shutdown in Iran. It details how the government completely cut off internet access for 90 million people for 118 hours in response to protests. The article frames this as a deliberate act to silence dissent and "erase" the nation from the digital world, preventing communication and the sharing of information about the regime's crackdown on protesters.
>
> **Discussion:** The Hacker News discussion is multifaceted, covering the technical, human, and geopolitical dimensions of the situation.

A significant portion of the conversation focuses on the human cost and the brutality of the Iranian regime. Commenters express deep sorrow and depression over the events, referencing unverified but horrifying reports of thousands of protesters being killed, with some figures exceeding the death toll of the Tiananmen Square massacre. There is a strong sense of tragedy and helplessness.

The technical aspect of the shutdown is also a key topic. Users discuss how such a complete internet blackout is a "non-negotiable capability" for any non-democratic state, likely learned from the role social media played in the Arab Spring. There's speculation on how Iran is jamming technologies like Starlink and a call for the development of more resilient, decentralized, peer-to-peer networks to circumvent future shutdowns. However, one commenter pushes back on the idea that this is unique to authoritarian states, arguing that many technologically advanced democracies also possess the capability to shut down their internet for strategic reasons.

Several commenters express frustration with the perceived silence from international human rights activists and media, suggesting that Iranian lives are valued less than others. This leads to a debate about the role of foreign intervention, with some users questioning the motives behind protests and warning that outside involvement could be a net negative for the country.

Finally, there is a meta-discussion about the article itself. Some users find the article's tone sensationalist and propagandistic, feeling it's more like a "submarine ad" for a security startup than objective reporting. Others dismiss this, stating that the gravity of the news (a potential massacre) is what makes it important. A few also note that the text appears to be AI-generated, citing its "slop smell."

---

## [What a year of solar and batteries saved us in 2025](https://scotthelme.co.uk/what-a-year-of-solar-and-batteries-really-saved-us-in-2025/)
**Score:** 233 | **Comments:** 319 | **ID:** 46602532

> **Article:** Scott Helme details his experience installing a 12.8 kWp solar array and 22.5 kWh of battery storage at his UK home in 2025. Over one year, the system generated 12.3 MWh of electricity, of which 8.9 MWh was used directly by the home and 3.4 MWh charged the batteries. The system saved him £3,650 (approx. $4,900) against a grid electricity cost of £4,300, meaning the solar and batteries covered 85% of his energy needs. Helme notes that while the upfront cost was significant, the 9-11 year payback period is attractive given rising energy prices, and he highlights the benefits of smart scheduling, API integrations with his utility (Octopus), and the ability to power his home and two EVs entirely from solar generation.
>
> **Discussion:** The Hacker News discussion focused on the feasibility of Helme’s high energy usage, the economics of battery and solar systems, and the practicalities of DIY versus professional installations.

Commenters immediately questioned the author's reported consumption of over 21 MWh per year (excluding solar production), noting it was significantly higher than typical households, even those with electric vehicles and heating. It was clarified that the author charges two EVs, which explains the elevated usage.

The conversation turned to the financial viability of such systems. Users debated the payback period, with some noting that while 9-11 years is reasonable, maintenance costs (like inverter replacement around year 10) and roof longevity must be factored in. There was significant discussion regarding hardware choices, specifically the preference for Tesla Powerwalls versus cheaper, higher-capacity alternatives like BYD batteries, with some users suggesting buying an EV with a large battery (like an MG4) is a cheaper storage solution than a dedicated Powerwall.

Tax incentives were a major topic, with users clarifying that the US solar tax credit expires at the end of 2025, while the battery storage credit remains until 2032. This led to speculation about a potential influx of used solar equipment on the market.

Finally, the thread explored the viability of "grid cycling" (charging batteries from the grid during off-peak hours and selling back during peak hours) versus solar generation. While users acknowledged that large-scale companies do this, the financial returns for residential users are generally lower than generating their own power. The discussion also touched on the barriers to entry for DIY solar installations, citing regulatory restrictions and the need for certified electricians in many regions.

---

## [The UK is shaping a future of precrime and dissent management (2025)](https://freedomnews.org.uk/2025/04/11/how-the-uk-is-shaping-a-future-of-precrime-and-dissent-management/)
**Score:** 213 | **Comments:** 260 | **ID:** 46600194

> **Article:** The article from Freedom News (2025) argues that the UK is developing a "precrime" framework that combines predictive policing with the management of dissent. It details how new technologies, data analysis, and legislation are being used not just to prevent crime, but to preemptively identify and neutralize political opposition and protest movements. The author contends that this system, justified under the guise of risk management and public safety, effectively criminalizes intent and creates a chilling effect on free speech and assembly, moving the UK towards an authoritarian model of governance.
>
> **Discussion:** The Hacker News discussion is overwhelmingly critical and dystopian, with commenters drawing parallels to science fiction and historical warnings. A dominant theme is the comparison to fiction, with users referencing *Black Mirror* as a modern predictor, while others point to George Orwell's *1984* as the foundational text for these concerns. The concept of "precrime" from *Minority Report* is also directly invoked, leading to a debate on whether laws against conspiracy already represent a form of pre-crime, and questioning the effectiveness of such systems in preventing crime versus suppressing dissent.

Commenters expressed deep skepticism about the motivations behind these policies. One prominent view is that this is a tactic used by unpopular governments to maintain control when they cannot win in open debate. Another key concern, echoing the "who watches the watchers" question, is about the ultimate arbiters of this system, with some pointing to the combined power of corporate and governmental entities.

Overall, the sentiment is one of alarm, with users noting the "unsettling convergence" of different policies and the danger of normalizing action based on suspicion rather than proven wrongdoing. The discussion reflects a consensus that these developments represent a significant and dangerous shift in the relationship between the state and the citizen.

---

## [Games Workshop bans staff from using AI](https://www.ign.com/articles/warhammer-maker-games-workshop-bans-its-staff-from-using-ai-in-its-content-or-designs-says-none-of-its-senior-managers-are-currently-excited-about-the-tech)
**Score:** 204 | **Comments:** 108 | **ID:** 46607681

> **Article:** Games Workshop, the company behind Warhammer, has banned its staff from using AI in content or design. According to an IGN article, none of the company's senior managers are "currently excited about the tech." The policy covers both creative and design processes, signaling a firm stance against integrating generative AI into their workflow for the foreseeable future.
>
> **Discussion:** The Hacker News discussion centered on the business, creative, and cultural reasons behind Games Workshop's decision. A primary theme was the commercial and legal risk management involved. Commenters suggested GW's move is a prudent strategy to protect its highly valuable and meticulously crafted intellectual property. Given the company's history of aggressively copyrighting and trademarking its unique lore and aesthetics, allowing AI could introduce legal ambiguity over ownership and training data, a risk GW is unwilling to take.

A second major theme was the quality and nature of creative work. Several users argued that AI-generated art often looks "generic" and that paying for human designers provides a clear return on investment. However, others countered that AI can be a useful iterative starting point for designers, not just a replacement. This led to a broader debate about whether AI is a tool to augment creativity or a threat to it.

The discussion also took a humorous and cultural turn, with many commenters pointing out the irony of a company that built a universe where "Abominable Intelligence" is a cardinal sin banning AI in real life. This "lore-accurate" decision was seen as a missed PR opportunity by some, while others found it fitting.

Finally, the conversation expanded to the community's perception of AI. One user observed a hypocrisy among non-technical board gamers: they are vehemently against AI for art and game design but would readily use it to replace expensive programmers. This highlights a societal divide in how different creative and technical fields are valued. The consensus was that while many consumers claim to be anti-AI, their purchasing decisions will ultimately be driven by product quality, which AI-generated content has yet to consistently deliver.

---

## [Show HN: Self-host Reddit – 2.38B posts, works offline, yours forever](https://github.com/19-84/redd-archiver)
**Score:** 203 | **Comments:** 50 | **ID:** 46602324

> **Project:** This project, "Self-host Reddit," is a tool for creating a personal, offline archive of Reddit content. The project's goal is to preserve internet history and make it accessible "forever," independent of Reddit's servers or API. The core of the project is a massive dataset, available via torrent, containing 2.38 billion posts and comments from Reddit, as well as data from other platforms like Voat and Ruqqus. The tool provides an API and an MCP server, allowing for various integrations and local access to the archived data.
>
> **Discussion:** The Hacker News community had a mixed but engaged reaction to the project. The discussion revolved around several key themes:

*   **Use Cases and Potential:** Users were excited about the potential for personal archiving and data analysis. Suggestions included using the archive to replace deleted or protest-overwritten comments on Reddit (a major pain point for users seeking old information), integrating it with defunct third-party apps like Apollo, and using it to train AI models. One user expressed a desire for a similar archiving solution for TikTok.

*   **Ethical and Philosophical Debates:** The project sparked a significant debate about content ownership and user consent. Some questioned whether the creator compensated the millions of users who generated the content, while others countered that content posted on a public forum should be considered open for remixing and use. A related discussion emerged about the ethics of restoring comments that users deliberately deleted as a form of protest against Reddit's API changes, with differing views on whether this undermines user autonomy or preserves public knowledge.

*   **Platform Inclusivity:** The inclusion of an archive for Voat, a platform known for hosting extremist communities, drew criticism ("Gross. Why would anyone want to have an archive of Reddit For Neonazis?"). The creator responded by stating they will support any platform for which a complete dataset is available, maintaining a neutral, preservation-focused stance.

*   **Technical Feedback:** A user reported initial difficulties running the project with Docker Compose due to missing configuration files and volume setup. The creator quickly responded by adding the necessary example files and updating the documentation to resolve the issues.

---

## [Indifference is a power](https://aeon.co/essays/why-stoicism-is-one-of-the-best-mind-hacks-ever-devised)
**Score:** 197 | **Comments:** 210 | **ID:** 46601121

> **Article:** The article from Aeon argues that Stoicism is a powerful "mind hack" for modern life. It posits that the core Stoic principle of "indifference" is not about apathy, but about focusing one's energy only on what is within our control (our judgments, choices, and actions) while remaining calm and accepting of external events that are not. This practice, the author suggests, builds resilience, reduces anxiety, and provides a stable framework for navigating a chaotic world, effectively reframing it as a practical psychological tool for emotional regulation and well-being.
>
> **Discussion:** The Hacker News discussion presents a multifaceted and often critical view of modern Stoicism. A central theme is the distinction between authentic Stoicism and its popular, often distorted, interpretation. Several users express concern that "pop Stoicism" is misused to promote emotional suppression, particularly within certain online communities, where it becomes a justification for "sucking it up" and ignoring genuine psychological distress. This is contrasted with a more nuanced view from users with personal experience, who warn that simply setting aside emotions without later processing them creates "emotional debt" and leads to dissociation or burnout. They argue that true Stoic practice involves managing and integrating emotions, not eliminating them.

The discussion also explores practical applications and related concepts. The connection between Stoicism and modern Cognitive Behavioral Therapy (CBT) is highlighted, with one user recommending David Burns' "Feeling Good" as an effective handbook for implementing the Stoic mindset. There is also debate over the core tenets, with one user arguing that Stoicism's indifference to outcomes can stifle ambition, while another counters that it teaches indifference only to what one cannot control, not to the pursuit of values. The conversation concludes with a variety of perspectives, from a darkly humorous reading of Epictetus's advice on grief to a recommendation of alternative philosophical frameworks like Samkhya and Buddhist practices.

---

## [The Tulip Creative Computer](https://github.com/shorepine/tulipcc)
**Score:** 187 | **Comments:** 38 | **ID:** 46603995

> **Article:** The article links to the GitHub repository for "Tulip Creative Computer," an open-source, portable, and programmable device. It is built on an ESP32-S3 microcontroller and features a color screen, a keyboard, and speakers. The device is programmed in a version of MicroPython, providing an integrated environment for creating music (synthesizers), graphics, games, and text. The project emphasizes a minimalist, self-contained computing experience, contrasting with modern, complex software stacks like web browsers.
>
> **Discussion:** The Hacker News discussion is largely positive but also explores the project's identity and potential. A key theme is the appreciation for its minimalist design, with one user praising its reduction in complexity compared to modern development stacks (e.g., Rust/WASM). Experienced users share their satisfaction, mentioning its use for creating sequencers and interfacing with external hardware like rotary encoders.

Several commenters focus on the name "Tulip," noting its coincidence with a defunct Dutch PC manufacturer of the same name, sparking a minor side discussion about trademarks and developer awareness.

There is also some debate about the device's purpose and target audience. While some find the marketing claims ("make music, code, art, games") to be vague and aspirational, others defend the project for encouraging creative, non-traditional forms of computing. The discussion also touches on its technical capabilities, with users asking about support for livecoding environments like TidalCycles, which is deemed a "tall order" for the device's CPU. Overall, the project is received as a cool and well-executed piece of creative hardware.

---

## [Mozilla's open source AI strategy](https://blog.mozilla.org/en/mozilla/mozilla-open-source-ai-strategy/)
**Score:** 182 | **Comments:** 181 | **ID:** 46599897

> **Article:** Mozilla has announced a new open-source AI strategy focused on building a "trustworthy" AI ecosystem. The initiative is built on three pillars: 1) **Mozilla.ai**, a platform for developing AI agents and tools, positioned as an open-source alternative to proprietary systems like LangChain; 2) **Mozilla Data Collective**, an effort to address the data licensing and sourcing challenges in AI development; and 3) **Real Deployments**, aiming to partner with public and private entities to implement these solutions. The strategy is framed as a move to ensure AI is developed in a user-centric, transparent, and open manner, countering the dominance of big tech companies.
>
> **Discussion:** The Hacker News discussion is largely skeptical of Mozilla's new AI initiative, reflecting a broader sentiment that the organization has lost its way. Many commenters express doubt about Mozilla's ability to execute, citing its reliance on funding from Google (its primary competitor) and a perceived lack of recent impactful achievements. The criticism is multi-faceted: some dismiss the move as a "consulting grift" or a "closed-source SaaS" play that contradicts Mozilla's open-source ethos, while others question the financial sustainability of such ambitious projects.

A significant portion of the debate circles back to Mozilla's core product, the Firefox browser. Commenters point to Firefox's declining market share and technical shortcomings (e.g., performance, compatibility issues) as evidence that Mozilla should focus on improving its browser rather than venturing into the crowded AI space. However, a few defenders argue that Firefox remains the only viable alternative to the Chrome-dominated web and that Mozilla's efforts to foster an open AI ecosystem are a necessary and worthwhile endeavor, even if success is not guaranteed.

---

