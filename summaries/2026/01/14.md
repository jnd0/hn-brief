# Hacker News Summary - 2026-01-14

## [AI generated music barred from Bandcamp](https://old.reddit.com/r/BandCamp/comments/1qbw8ba/ai_generated_music_on_bandcamp/)
**Score:** 899 | **Comments:** 678 | **ID:** 46605490

> **Article:** Bandcamp has announced a new policy to bar AI-generated music from its platform. The decision is framed as an effort to keep the platform "human," prioritizing authentic, human-created art and protecting the community of musicians and fans. The move is positioned as a stand against the rising tide of low-effort, AI-generated content that is becoming prevalent on other streaming services.
>
> **Discussion:** The discussion on Hacker News is largely supportive of Bandcamp's decision, with many commenters expressing frustration with the proliferation of low-quality, AI-generated "slop" on platforms like Spotify. A key theme is the negative impact on music discovery and the user experience, with some users reporting that Spotify's algorithm pushes AI-generated tracks onto their feeds, and in one egregious case, an AI song was used to hijack the page of a deceased artist.

However, the conversation also explores the nuances of AI in the creative process. A significant distinction is drawn between purely AI-generated content and AI-assisted creation. Many commenters, including some musicians, see AI as a powerful tool that can augment human creativity (e.g., generating drum tracks for a guitarist to build upon), comparing it to "vibe coding." The debate then centers on where to draw the line. Some argue for a hard-line ban to maintain clarity and support human artists, while others suggest a middle ground where AI-assisted work is allowed as long as it undergoes significant human processing and intention. The core of the disagreement lies in defining "human intention" versus simply providing a text prompt, with many feeling that the latter does not constitute true artistry.

---

## [FBI raids Washington Post reporter's home](https://www.theguardian.com/us-news/2026/jan/14/fbi-raid-washington-post-hannah-natanson)
**Score:** 632 | **Comments:** 371 | **ID:** 46616745

> **Article:** The Guardian reports that the FBI raided the home of Washington Post reporter Hannah Natanson as part of an inquiry tied to a classified materials case. The raid involved seizing devices. Natanson recently published a feature detailing her work gathering stories from thousands of current and former federal employees regarding the impact of Trump administration policies on the civil service. The article suggests the raid is an attempt to identify her sources, which she estimated at 1,169 individuals.
>
> **Discussion:** The Hacker News discussion is highly critical of the FBI's actions, viewing the raid as a significant escalation against press freedom and a symptom of authoritarian overreach. Commenters express alarm that the government will use the seized devices to identify and potentially prosecute the reporter's sources, described as "whistleblowers" and civil servants sharing "small leaks" of misbehavior rather than a single Snowden-style bombshell.

A central theme is the weaponization of the "classified materials" designation. Users argue that this vague label allows the government to target journalists and suppress investigations without transparency, as the evidence does not need to be made public. There is broad consensus that this is not a partisan issue but a result of decades of unchecked executive power accumulation, often referred to as the "Imperial Presidency."

The discussion also highlights a perceived hypocrisy regarding constitutional rights. Several commenters note that while Second Amendment (gun rights) advocates are vocal about government tyranny, they remain silent on First Amendment (press freedom) violations, with some suggesting this is because they actually support the current administration's crackdown. Finally, the "boiling frog" analogy was frequently used to describe the gradual erosion of civil liberties, alongside references to the show *Andor* to illustrate how authoritarian regimes provoke citizens to fuel their own oppression.

---

## [We can't have nice things because of AI scrapers](https://blog.metabrainz.org/2025/12/11/we-cant-have-nice-things-because-of-ai-scrapers/)
**Score:** 436 | **Comments:** 237 | **ID:** 46608840

> **Article:** The article, from the MetaBrainz blog, details how the project is being forced to restrict access to its APIs due to aggressive and inefficient scraping by AI companies. MetaBrainz, which maintains open music metadata databases like MusicBrainz and ListenBrainz, provides bulk data dumps specifically for large-scale data acquisition. However, AI scrapers are ignoring this efficient method and instead hammering their web servers and APIs with page-by-page requests, overloading volunteer-run infrastructure. To cope, the project is implementing mandatory authentication (API tokens) for previously open endpoints and removing debugging APIs. The author argues that this "enshittification" of access harms legitimate users and is a direct result of AI companies externalizing their data acquisition costs onto the open-source community.
>
> **Discussion:** The Hacker News discussion strongly sympathizes with MetaBrainz, framing the issue as a classic tragedy of the commons where AI companies are destroying valuable, community-maintained resources through sheer carelessness and inefficiency. The core consensus is that the AI scrapers are not just aggressive but also "dumb," ignoring readily available bulk downloads in favor of hammering live sites, which forces projects to lock down and harm their legitimate users.

Several key themes emerged:
*   **Inefficiency and Bad Faith:** Commenters repeatedly point out the irony of scrapers bypassing the exact data dumps designed for them. The behavior is described as "traversing search facets" and being "exhaustively" repetitive, akin to early, primitive bots. There's a strong feeling that scrapers operate on an adversarial assumption that sites are hiding data, rather than cooperating.
*   **The Loss of the Open Web:** Many lament that this is part of a broader trend destroying the "old web," where small sites and APIs were easily and respectfully scrapable by individuals. The result is a more locked-down internet, forcing projects to add authentication that creates friction for hobbyists and researchers.
*   **Solutions and Mitigations:** A variety of solutions were debated. Some mentioned technical tools like Cloudflare's AI-specific tarpits. Others proposed better coordination, such as a `/.well-known/` standard for advertising data dumps. A recurring idea was that scrapers should be forced to use intermediaries like Common Crawl, which could centralize and manage the load.
*   **Nuance and Counterpoints:** Not all scraping was condemned. Some users shared personal stories of using AI assistants to write scripts for "harmless" scraping of niche sites for personal research or archival purposes. This highlights a gray area: the technology makes scraping trivial for everyone, not just large corporations. The discussion also touched on the "signal-to-noise" problem, questioning why scrapers would even want the open web's data when it's increasingly contaminated with AI-generated content.
*   **Economic Reality:** A few commenters noted that with the current "bubble money," the cost of this inefficient scraping is likely a rounding error for major AI labs, meaning there's little economic incentive for them to change their behavior.

---

## [When hardware goes end-of-life, companies need to open-source the software](https://www.marcia.no/words/eol)
**Score:** 359 | **Comments:** 112 | **ID:** 46609492

> **Article:** The article argues for a "right to repair" for software, proposing that when a hardware product reaches its end-of-life (EOL) and is no longer supported by its manufacturer, the company should release the necessary software and specifications to the public. The author uses the example of a smart kitchen scale that became a "brick" after its app was discontinued. The core request is not for full open-source of the entire codebase, but for the release of basic information like hardware specs and connection protocols on a platform like GitHub. This would empower the community to build their own applications, extend the device's lifespan, and prevent e-waste, turning a worthless purchase into a valuable open-source project.
>
> **Discussion:** The Hacker News discussion presents a nuanced and largely skeptical view of the article's proposal, focusing on the technical and economic complexities. A central theme is the conflict between security and user control. Several users pointed out that modern devices with secure boot and code signing chains "fail closed," making it impossible to run custom software without the manufacturer's keys. While one commenter suggested escrowing these keys, others immediately countered that releasing signing keys would be a security disaster, creating a massive risk for botnets. A more favored alternative was the idea of a "fail open" mechanism, such as a physical button press, that would allow a user to explicitly opt-in to running third-party firmware.

Other key points of discussion questioned the practicality of the article's core request. One user argued that publishing hardware specs is largely redundant, as they can be reverse-engineered, and that the real challenge lies in complex, proprietary protocols. The idea of dumping responsibility onto "the community" was also criticized as a potential form of entitlement that could backfire, with one user noting that community projects often drop support for older hardware anyway.

Finally, the conversation touched on real-world examples and the economic barriers to such a mandate. The Aura Frame was cited as a product where users fear being left with a brick if the company disappears. A user shared a personal anecdote about the Spotify Car Thing, which was the subject of a recent HN front-page post, as a perfect case study. The discussion concluded with a debate on whether mandating such a policy would result in unusable software, with one user arguing it would be FUD (fear, uncertainty, and doubt) if it were a legal requirement.

---

## [A 40-line fix eliminated a 400x performance gap](https://questdb.com/blog/jvm-current-thread-user-time/)
**Score:** 337 | **Comments:** 71 | **ID:** 46609630

> **Article:** The article details a performance bottleneck in the JVM where obtaining the user CPU time for a thread was extremely expensive (around 28 microseconds). The author discovered this was due to the JVM using the `getrusage(RUSAGE_THREAD, ...)` syscall, which is slow. A 40-line patch changed the implementation to use `clock_gettime(CLOCK_THREAD_CPUTIME_ID, ...)`, which is significantly faster (around 70 nanoseconds), closing a 400x performance gap. This change is now included in recent JDK versions.
>
> **Discussion:** The discussion was highly technical, with users analyzing the kernel-level mechanics of the fix. Key points included:

*   **Kernel Internals:** Commenters confirmed that `clock_gettime` for this specific clock ID (`CLOCK_THREAD_CPUTIME_ID`) cannot be serviced by the vDSO (a fast user-space mechanism) and still requires a syscall to fetch per-thread data from the kernel's task struct.
*   **Measurement Accuracy:** One user raised a valid concern about the stability and accuracy of the micro-benchmarks used, suggesting that without a very precise clock, the absolute time claims might be unreliable.
*   **Even Faster Alternatives:** A commenter proposed an even more performant method using software perf events (`PERF_COUNT_SW_TASK_CLOCK`) read through a shared memory page, which could potentially avoid syscalls entirely and achieve nanosecond-level reads, though it has setup overhead and permission requirements.
*   **General Performance Takeaways:** Users expressed shock at how slow "organic" code can be before performance issues are discovered and praised the power of flamegraphs for uncovering hidden bottlenecks like expensive logging or redundant computations.
*   **Longevity of the Bug:** Several users noted the surprisingly long time (seven years from the initial bug report) it took for this significant performance issue to be resolved.

---

## [Signal leaders warn agentic AI is an insecure, unreliable surveillance risk](https://coywolf.com/news/productivity/signal-president-and-vp-warn-agentic-ai-is-insecure-unreliable-and-a-surveillance-nightmare/)
**Score:** 334 | **Comments:** 102 | **ID:** 46605553

> **Article:** The article, based on warnings from Signal's president and VP, argues that "agentic AI" (AI systems that can take actions on a user's behalf) presents an enormous and underestimated security risk. They contend that these AI agents are inherently unreliable and insecure, creating a massive new attack surface. The core problem is that to be useful, these agents require broad access to user data, emails, and applications, effectively acting as a "surveillance nightmare." This makes them a prime target for exploitation and a fundamental threat to user privacy and security.
>
> **Discussion:** The Hacker News discussion reveals a deep skepticism about the motivations behind the article, while largely agreeing with the technical and security concerns raised. The conversation is split between questioning Signal's intent and analyzing the fundamental, systemic problems with AI security.

A significant portion of the initial discussion is cynical about the article's timing, with one user pointing to a recent announcement that Signal's creator, Moxie Marlinspike, is launching a new AI venture. This led many to interpret the warnings as a potential marketing tactic for their upcoming product. However, other commenters defended Signal's long-standing privacy-focused mission, arguing they have no obvious conflict of interest and are simply doing their job of highlighting security risks.

Beyond the debate over motives, the conversation delves into the root causes of the problem. One prominent theme is that this is not an AI problem, but an operating systems problem. These commenters argue that AI is simply exposing the long-ignored weaknesses in OS security models (like process isolation) that were never designed for a world of networked, untrusted software. The counterpoint is that robust security (like microkernels or sandboxing) is too expensive and complex for widespread adoption, which is why it hasn't happened.

Several participants shared real-world experiences, confirming that enterprise adoption of AI tools is chaotic and dangerous. They described a landscape where "zero trust" policies are ignored, AI tools create massive RCE (Remote Code Execution) vulnerabilities, and companies are willing to accept huge risks for the promise of cost reduction. The consensus from this perspective is that current AI agents are a "liability," not a feature, and that "human-in-the-loop" is a necessary safeguard, not a bug. The discussion concludes with a call for "verified privacy at inference," but with the grim acknowledgment that the only truly secure way to handle sensitive data is to run models locally, a solution that is not practical for most.

---

## [1000 Blank White Cards](https://en.wikipedia.org/wiki/1000_Blank_White_Cards)
**Score:** 323 | **Comments:** 58 | **ID:** 46611823

> **Article:** The Wikipedia article describes "1000 Blank White Cards" (1KBWC) as a party game where players create the rules and cards as they play. The game starts with a deck of blank cards and pens. On a player's turn, they draw a card. If it's blank, they invent a rule and/or a point value, write it on the card, and leave it face up for others to see. If it's an existing card, they follow its instructions. The game is chaotic, creative, and has no fixed ruleset, with the game's culture and history evolving from session to session. It is often compared to other creative games like "Nomic" and "Calvinball."
>
> **Discussion:** The HN discussion frames "1000 Blank White Cards" as a classic example of a creative, emergent, and self-referential game system. The conversation flows through several key themes:

*   **Analogous Games:** Users immediately draw parallels to other games. The most frequent mentions are "We Didn't Playtest This At All" (a chaotic card game with pre-written, unbalanced effects), "Fluxx" (a commercial game where the rules themselves are cards that change over time), and "Calvinball" (the quintessential example of a game with constantly invented rules). A separate but related anecdote describes a drinking game called "Pizza Box," where players flip a coin into a box and draw circles to write rules in.

*   **The "Mao" Variant:** A significant thread explores "Mao," a game where the winner of each round invents a new, secret rule that other players must discover or be penalized. This is described as a game with a "culture" rather than a written ruleset, and users share personal stories of its addictive and sometimes frustrating nature.

*   **Metagame and Emergent Narrative:** One commenter provides a detailed analysis of the game's "metagame," explaining how players vote on which new cards to keep for the next session. This creates a collaborative storytelling element, where the deck evolves with an internal logic and history (e.g., the "Sheep Herder" and "Goat Herder" cards).

*   **Broader Concepts:** The discussion touches on more abstract ideas, with one user connecting the game to game theory concepts like "Constitutional Economics" and "Mechanism Design." Another user links to a programmer-focused version called "Nomyx," extending the concept of self-modifying rules into a coding context.

---

## [The truth behind the 2026 J.P. Morgan Healthcare Conference](https://www.owlposting.com/p/the-truth-behind-the-2026-jp-morgan)
**Score:** 311 | **Comments:** 77 | **ID:** 46605332

> **Article:** The article is a satirical piece that humorously reimagines the J.P. Morgan Healthcare Conference, a massive annual industry event in San Francisco, as a ritualistic gathering for a fictional cosmic entity. It posits that the conference's true purpose is not business, but to appease this entity, which is metaphorically (and then literally) described as a giant organism living beneath the city. The author uses this absurd premise to poke fun at the conference's intense, often chaotic, and sometimes meaningless nature, where the actual scheduled talks are secondary to the frantic networking, deal-making, and social events that define the experience. The piece transitions from a plausible critique of industry conferences into a full-blown mythological narrative, celebrating the absurdity of the entire affair.
>
> **Discussion:** The HN discussion overwhelmingly praises the article for its humor and unique narrative style. Commenters describe it as an "absolute cinema" and a "fun read," with many appreciating its slow descent from a coherent critique into an absurd, Vonnegut-esque fantasy. The conversation also serves to ground the satire in reality, with several users confirming that the article correctly identifies the conference's true value: the networking, deal-making, and side meetings, rather than the official presentations. One user with direct experience notes that the talks are forgettable and the event is dominated by "puffery" and dealmakers. A minor point of clarification arises about the conference's official venue, but this doesn't detract from the general agreement that the article successfully captures the bizarre and intense atmosphere of the event.

---

## [ASCII Clouds](https://caidan.dev/portfolio/ascii_clouds/)
**Score:** 308 | **Comments:** 55 | **ID:** 46611507

> **Article:** The article links to a portfolio piece titled "ASCII Clouds," which is a visual demonstration of a 3D scene (a dynamic, cloudy landscape) rendered in an ASCII art style. The effect is achieved by applying a post-processing shader that converts the final rendered image into a grid of text characters, where character density or type represents the brightness and detail of the underlying scene. It's presented as a visually appealing technical showcase of combining 3D graphics with a retro ASCII aesthetic.
>
> **Discussion:** The Hacker News community's reaction is largely positive, with users appreciating the visual quality of the demonstration. However, the conversation quickly splits into two main threads: one discussing the technical implementation and another debating the artistic execution.

Several commenters point out that the core technique is a well-established concept. They explain that it's a standard post-processing shader effect that can be applied to any 3D scene or video, and they provide links to existing libraries and tutorials for Three.js, Babylon.js, and other frameworks that implement similar ASCII filters. One user even shares their own related project: a "shader" that runs directly in the Emacs text editor.

The second thread focuses on the specific artistic choices of the "ASCII Clouds" piece. A point of contention is the use of color. Some users argue that using a different color for each character or brightness level is redundant and "defeats the purpose" of a pure ASCII aesthetic, which traditionally relies on the shape and density of monochrome characters to convey an image. Others counter that this is an artistic piece and such creative liberties are acceptable. The piece is also praised for its subtle details and as an inspiration for other projects, such as integrating live ASCII video feeds.

---

## [SparkFun Officially Dropping AdaFruit due to CoC Violation](https://www.sparkfun.com/official-response)
**Score:** 285 | **Comments:** 268 | **ID:** 46616488

> **Article:** SparkFun, a major electronics distributor, announced it is officially dropping AdaFruit as a partner and will no longer carry their products. The announcement, framed as an "Official Response," cites a "Code of Conduct violation" and alleges that AdaFruit engaged in "offensive, antagonistic, and derogatory emails" and inappropriately involved a SparkFun customer in a private matter. The statement is notably vague, providing no specific details about the events that led to the decision.
>
> **Discussion:** The Hacker News discussion is dominated by speculation and a "he said, she said" dynamic, with users expressing disappointment and confusion over the public nature of the dispute. The conversation quickly evolved after a key comment linked to a counter-narrative from AdaFruit co-founder Phil Torrone.

The core of the discussion revolves around two conflicting accounts:
*   **SparkFun's Position (as stated):** SparkFun is terminating the relationship due to a Code of Conduct violation by AdaFruit, specifically citing inappropriate communication and involving a SparkFun customer in a private matter. Many commenters found SparkFun's public statement vague, unprofessional, and an "invitation for speculation."
*   **AdaFruit's Position (as revealed in the comments):** Torrone claims the conflict began when he reported SparkFun's founder for a "long-term harassment campaign" targeting AdaFruit's founder, Limor Fried. He alleges that instead of addressing the harassment, SparkFun retaliated by cutting off AdaFruit's supply of the Teensy microcontroller, a product SparkFun exclusively manufactures. AdaFruit's response is to develop an open-source alternative.

Key discussion points include:
*   **Criticism of Public Statements:** Many users felt SparkFun's vague public post was unprofessional and designed to create drama, while others defended their right to explain why they were dropping a major brand.
*   **The "Teensy" Angle:** The discovery that SparkFun has an exclusive manufacturing and distribution deal for the popular Teensy product is seen as a critical piece of context, suggesting a business dispute may be a major factor.
*   **Competitive Tensions:** Commenters acknowledge the long-standing rivalry between the two companies and view this public fallout as a significant escalation.
*   **Call for Open Source:** AdaFruit's stated plan to create an open-source alternative to the Teensy was widely praised by the HN audience as a constructive response that aligns with open-source principles and removes SparkFun's leverage.
*   **Skepticism of Both Sides:** While many were initially sympathetic to SparkFun's statement, the counter-narrative led to widespread skepticism of both companies' motives, with many concluding that this is a messy corporate dispute that shouldn't have been made public.

---

## [No management needed: anti-patterns in early-stage engineering teams](https://www.ablg.io/blog/no-management-needed)
**Score:** 282 | **Comments:** 299 | **ID:** 46605854

> **Article:** The article "No management needed: anti-patterns in early-stage engineering teams" argues that early-stage startups often mistakenly apply large-company management structures too soon. The author contends that for small teams (5-15 engineers), traditional management layers, formal 1:1s, and complex processes like Scrum are unnecessary and counterproductive. Instead, the focus should be on hiring intrinsically motivated, autonomous engineers and giving them direct access to users and business context. The article posits that motivation is a trait you hire for, not something managers create, and that the primary role of a founder in this phase is to provide clarity on the "what" and "why," trusting the team to handle the "how" without micromanagement.
>
> **Discussion:** The discussion on Hacker News revealed a mix of agreement with the article's spirit and significant debate over its specific prescriptions. A central point of contention was the claim that motivation is an inherent trait you hire for, not a quality managers can foster. Many commenters argued that while you should hire for drive, it's very easy for poor management, lack of ownership, or a toxic environment to demotivate even the most ambitious people. Trust and a sense of ownership were highlighted as crucial motivators.

Another major theme was the practical limit of a single manager's span of control. While the article suggested a founder could manage up to 15 engineers, several experienced commenters pushed back, stating that this is unrealistic and leads to chaos. They argued that beyond 8-10 reports, the founder becomes a bottleneck, and senior engineers are forced into unofficial, unaccountable management roles, hindering their own productivity.

The debate also touched on process. While there was a consensus that heavy-handed corporate processes like JIRA and formal Scrum are detrimental for small teams, many disagreed with the article's apparent dismissal of all structure. Commenters advocated for lightweight, essential processes like regular check-ins (1:1s) and simple task tracking (e.g., a shared document or Post-it notes) to ensure alignment and prevent a "race to the bottom" in code quality and documentation.

Finally, the discussion branched into related startup cultural topics, with commenters agreeing that founders obsessed with "competitors" or "disruption" are a red flag, and a debate on work-life balance, where some European commenters championed a 32-40 hour week while others noted this can lead to companies hiring in lower-cost regions instead.

---

## [I Hate GitHub Actions with Passion](https://xlii.space/eng/i-hate-github-actions-with-passion/)
**Score:** 258 | **Comments:** 213 | **ID:** 46614558

> **Article:** The article "I Hate GitHub Actions with Passion" is a developer's rant about the frustrations of debugging CI/CD pipelines on GitHub Actions. The author describes a specific, painful experience where a workflow failed on one platform (Linux ARM) but not others. The core issue was an inability to install a required tool (`cuelang`) within the GitHub Actions runner environment. The author argues that the feedback loop for fixing such issues is terrible: it involves pushing commits and waiting for remote runners to execute, which is slow and inefficient. The post concludes with a strong recommendation: developers should not embed complex logic directly into GitHub Actions workflow files. Instead, they should keep all logic in their own scripts (e.g., Makefiles, shell scripts) and use GitHub Actions merely as a wrapper to execute those scripts, making the CI process more predictable and locally testable.
>
> **Discussion:** The Hacker News discussion largely validates the author's frustrations while offering a variety of solutions and critiques. The most prominent theme is the recommended best practice of keeping logic out of CI configuration files. Many commenters echo the article's conclusion, advising to "call a sane script" from the workflow, which makes the process portable and easier to debug locally.

Several tools are proposed to directly address the author's pain points:
*   **`act`**: Frequently mentioned as a tool for running GitHub Actions locally, but with the major caveat that it's not a perfect replica of the GitHub environment and can fail for complex workflows.
*   **SSH Debugging**: A highly requested feature. Commenters point to tools like `action-tmate` (and its successor `upterm`) and services like SourceHut or Semaphore CI that offer "Rebuild with SSH" capabilities, allowing developers to inspect a failed runner environment interactively.
*   **Local Scripting**: One commenter suggests offloading all logic to a tool like `mise` to manage dependencies and tasks, keeping the CI file simple.

A significant counter-argument emerged, suggesting the problem isn't GitHub Actions itself but how it's used. One commenter argued the author's issue was a "skill issue" of relying on the CI tool to install dependencies instead of using a reproducible environment manager like Nix or Mise. This highlights a debate between "CI as a dumb executor" versus "CI as a managed environment." Other smaller themes included critiques of the article's ranting tone and suggestions for alternative tools like `gg` for interacting with Actions.

---

## [The $LANG Programming Language](https://news.ycombinator.com/item?id=46610557)
**Score:** 250 | **Comments:** 55 | **ID:** 46610557

> **Article:** The article is a new HN feature page at `https://news.ycombinator.com/showlang`. It is a curated, automatically generated list of all posts on Hacker News that have been submitted with a "Show HN" prefix and whose titles suggest they are about a programming language (e.g., "Show HN: The X Programming Language"). The page serves as a directory for new programming language projects shared on the platform.
>
> **Discussion:** The discussion was initiated by the HN admin (dang), who posted the link but quickly discovered it caused a significant performance issue on the site due to the way it loaded many old threads. He temporarily removed the direct link to mitigate the problem while considering a fix.

Users reacted with a mix of humor, confusion, and constructive feedback. Some initially mistook the title "$LANG" for an actual programming language name. A key theme emerged around the challenges of getting new projects noticed on HN. One user reported their own "Show HN" post for a new language had failed to appear on the /show page, leading to a broader conversation about the visibility of new submissions. The admin clarified that this was due to a software glitch that dropped upvotes and offered to manually feature the user's project after they improved the post's description.

The conversation also touched on the technical implementation of the new page, with users suggesting that an LLM could be better than a simple regex for identifying relevant posts. The admin acknowledged a "false positive" had been included and discussed the criteria for a post to be automatically added to the list, such as adhering to the "Show HN: The [Language Name] Programming Language" title convention.

---

## [The insecure evangelism of LLM maximalists](https://lewiscampbell.tech/blog/260114.html)
**Score:** 240 | **Comments:** 249 | **ID:** 46609591

> **Article:** The article "The insecure evangelism of LLM maximalists" argues that the aggressive promotion of Large Language Models (LLMs) for programming often stems from insecurity. The author posits that if a tool truly made someone significantly better, they wouldn't feel the need to evangelize it so hostilely; instead, they would simply use it. The piece suggests that the fervor of LLM advocates is a defense mechanism against the fear that these tools might render their skills obsolete. It contrasts this with the "hacker ethos," which is driven by a desire to understand systems deeply, whereas LLMs often encourage a superficial "make it work" approach without comprehension. The author admits LLMs are useful as "digital clerks" for research and simple tasks but questions whether they genuinely increase productivity or just output, concluding that the evangelism is more about social validation than technical utility.
>
> **Discussion:** The Hacker News discussion reveals a complex and polarized debate on the role of LLMs in software development, moving beyond a simple pro/con split. A central theme is the tension between code quality and business velocity. Some commenters argue that in a competitive market, the developer who delivers features faster—even with "slop"—is often more valued than the one who crafts perfect code, suggesting that business incentives reward rapid output over long-term stability. This is countered by the view that LLMs are best used as assistants for specific tasks like boilerplate, research, or handling unfamiliar syntax, rather than as replacements for skilled developers who must still oversee quality and architecture.

A significant portion of the discussion focuses on the skill of the user. Several experienced developers contend that if an LLM consistently produces code better than a programmer, it may indicate the programmer's own limitations. This leads to a fear that over-reliance on LLMs could stunt the growth of new developers, preventing them from gaining the deep understanding necessary for effective design and debugging. The conversation also touches on the nature of the developer's role, with some expressing concern that it will devolve into a tedious cycle of reviewing and correcting AI-generated output, losing the creative and problem-solving aspects of the job. Ultimately, many commenters express "debate fatigue," wishing for a shift from ideological arguments to practical demonstrations of how these tools are being used effectively.

---

## [I’m leaving Redis for SolidQueue](https://www.simplethread.com/redis-solidqueue/)
**Score:** 239 | **Comments:** 96 | **ID:** 46614037

> **Article:** The article "I’m leaving Redis for SolidQueue" argues that for many Rails applications, using a PostgreSQL-backed job queue (SolidQueue) is a simpler and more operationally sound choice than the traditional Redis-based setup (e.g., Sidekiq). The author contends that the added complexity of running and maintaining a separate Redis instance is often unnecessary overhead. They highlight the benefit of transactional job creation, where a job is enqueued within the same database transaction as the business logic, ensuring atomicity. While acknowledging that Redis will always be faster for raw throughput, the author concludes that SolidQueue's simplicity and integration with the existing database make it an excellent default for the majority of applications that do not have extreme performance requirements.
>
> **Discussion:** Discussion unavailable.

---

## [Games Workshop bans staff from using AI](https://www.ign.com/articles/warhammer-maker-games-workshop-bans-its-staff-from-using-ai-in-its-content-or-designs-says-none-of-its-senior-managers-are-currently-excited-about-the-tech)
**Score:** 227 | **Comments:** 122 | **ID:** 46607681

> **Article:** Games Workshop, the company behind Warhammer, has banned its staff from using AI in content or design. According to an IGN article, none of the company's senior managers are currently "excited" about the technology. The policy covers both creative output and design processes, signaling a firm stance against integrating generative AI into their workflow for the foreseeable future.
>
> **Discussion:** The Hacker News discussion centered on the business, cultural, and legal motivations behind Games Workshop's decision, with a notable side-thread on the hypocrisy of anti-AI sentiment in creative fields versus technical ones.

A primary theme was the clash between creative authenticity and efficiency. Several commenters, including the top-voted user, argued that banning AI is a sound business decision for a premium brand. They suggested that using AI would produce "generic" art and that paying human designers for original work provides better value and a distinct, non-generic style that is crucial for a company with a deep, established lore like Warhammer.

Another major theme was legal and intellectual property risk. Users pointed out that Games Workshop has invested heavily in making its IP uniquely copyrightable. Allowing AI, which is trained on vast datasets of existing art and could create derivative or legally ambiguous work, would be a significant liability. This was framed as a prudent move to protect their valuable, decades-built franchise from future copyright lawsuits.

The discussion also had a strong "lore-accurate" contingent. Many commenters humorously noted that banning AI is perfectly in line with Warhammer's universe, where AI is known as "Abominable Intelligence" and is a technological heresy. This led to jokes about Tech-Priests and in-universe characters using forbidden AI.

Finally, a significant sub-discussion emerged about the differing public perception of AI in creative versus technical jobs. Users observed that while the tabletop community is fiercely anti-AI for art and game design, the same people often express a desire to use AI to replace expensive programmers for their own projects. Commenters theorized this is because people view programming as a non-creative, high-paid technical task deserving less sympathy, whereas artists are seen as struggling creatives. The consensus was that while many people claim to be anti-AI, their consumer behavior will ultimately be dictated by the quality of the final product, regardless of how it was made.

---

## [The Gleam Programming Language](https://gleam.run/)
**Score:** 225 | **Comments:** 138 | **ID:** 46611667

> **Article:** The article introduces Gleam, a statically typed functional programming language that compiles to both Erlang (for the BEAM virtual machine) and JavaScript. It highlights the language's focus on simplicity, developer experience, and its ability to bring type safety to the robust concurrency model of the Erlang ecosystem or to full-stack JavaScript development.
>
> **Discussion:** The Hacker News discussion reveals a community intrigued by Gleam but also grappling with its trade-offs compared to its host ecosystems (Erlang/Elixir and JavaScript). The conversation centers on a few key themes:

A primary point of debate is the value and practicality of a static type system in the context of distributed systems. One commenter argued that types are less useful for applications dealing with the inherent uncertainty of network communication, where data is ultimately just bits. This view was strongly countered by others who asserted that types are the ultimate tool for defining and validating data contracts and communication protocols between services, preventing errors at the point of ingress.

Practicality and ecosystem maturity were also major topics. A user migrating from Elixir expressed significant frustration with the lack of built-in features like ad-hoc polymorphism (protocols) and macros, which led to manual implementation of common tasks like JSON serialization. They also noted the absence of a standard filesystem library due to Gleam's dual-target nature (Erlang/JS). However, another user countered that Gleam can seamlessly interoperate with the entire BEAM ecosystem (including Elixir libraries) via external function calls, challenging the idea that it's isolated. The dual-targeting itself was seen by some as a confusing compromise, while others viewed it as a powerful feature for full-stack development, despite potential pitfalls like differing number types between targets.

Finally, there was a sense of skepticism about Gleam's potential for widespread adoption, with many commenters noting they have no professional need for the Erlang ecosystem. This was balanced by personal anecdotes from users who found Gleam to be a joyful and refreshing language that revitalized their interest in programming, particularly for its clean syntax and robust type system.

---

## [Let's be honest, Generative AI isn't going all that well](https://garymarcus.substack.com/p/lets-be-honest-generative-ai-isnt)
**Score:** 212 | **Comments:** 276 | **ID:** 46605587

> **Article:** The article, titled "Let's be honest, Generative AI isn't going all that well," is a very brief post by Gary Marcus. It consists of only two main elements: four screenshots of other articles or headlines that highlight negative aspects or challenges of Generative AI, and a concluding sentence arguing that it is a mistake to orient economic and geopolitical policy around this "shoddy technology" based on unproven hopes of dramatic improvement.
>
> **Discussion:** The discussion on Hacker News is sharply divided, with most commenters criticizing the article's low effort and substance while also debating the actual state of Generative AI.

A significant portion of the criticism was aimed at the post itself. Many users found it to be lazy and unsubstantial, pointing out that it was merely four screenshots with minimal original commentary. Several commenters ironically noted that the article's own brevity and lack of depth undermined its credibility, with one stating that a five-sentence article making such grand claims was less effort than a 4th-grade essay.

On the other hand, the core topic sparked a lively debate about whether AI is truly "going well." Supporters of the technology, particularly developers, shared powerful personal anecdotes of productivity gains. They described using AI to rewrite millions of dollars worth of code in weeks, saving a "small fortune" on design and photography, and completing complex documentation tasks in hours instead of weeks. For them, the tangible benefits were undeniable.

Conversely, skeptics and those with more nuanced views argued that the current hype is disconnected from reality. They shared experiences of AI models failing at basic tasks, getting stuck in loops, and being unreliable for anything beyond simple examples. A key theme was the distinction between the technology's potential and its market reality. One commenter suggested the issue isn't a failure of the underlying technology, but a failure of Product-Market Fit (PMF) for broad, general-purpose tools like copilots. Others argued that while AI is a useful tool, it is not the world-changing paradigm shift or precursor to AGI that it is often marketed as, and that expectations have been set unrealistically high by industry leaders.

---

## [Show HN: OSS AI agent that indexes and searches the Epstein files](https://epstein.trynia.ai/)
**Score:** 179 | **Comments:** 86 | **ID:** 46611348

> **Project:** The project is an open-source AI agent that provides semantic search across the publicly available Epstein legal documents. Hosted at epstein.trynia.ai, it uses vector embeddings to allow users to query the dataset. The creator describes it as a quick build, though they plan to update it as more files are released.
>
> **Discussion:** Discussion unavailable.

---

## [Minor says ICE took his iPhone, later found in used-electronics vending machine](https://www.propublica.org/article/videos-ice-dhs-immigration-agents-using-chokeholds-citizens)
**Score:** 159 | **Comments:** 57 | **ID:** 46611375

> **Article:** An article by ProPublica details allegations of excessive force by U.S. Immigration and Customs Enforcement (ICE) agents against U.S. citizens. The report focuses on several incidents, including one where a teenager named Arnoldo was allegedly put in a chokehold and had his iPhone confiscated by agents after filming their interaction. Using the "Find My" feature, the phone was later located in a used-electronics vending machine near an ICE detention center, and the recovered footage supported the family's account of the events. The article compiles video evidence and claims that these aggressive tactics, which are officially banned, are being used against citizens during minor encounters.
>
> **Discussion:** The Hacker News discussion surrounding the article is multifaceted, focusing on the systemic nature of the alleged misconduct, the role of technology, and broader concerns about the state of American democracy.

Many commenters viewed the incidents not as isolated "bad apples" but as evidence of a systemic failure where official policies are consistently ignored on the ground. This led to a wider debate about the rule of law, with some users expressing cynicism that laws are no longer being enforced consistently in the U.S. The conversation escalated into a direct debate about the potential necessity of political violence to counter authoritarianism, sparked by a German user's urgent warning about the erosion of democratic institutions. This specific thread saw a strong counter-argument favoring non-violent, mass-mobilization strategies.

Other points of discussion included:
*   **Technology:** Users noted the irony that Apple's security features ("Find My" and device locking) helped the victim while also rendering the theft of the phone for its data or parts largely pointless for the thieves.
*   **Moderation and Censorship:** A user expressed concern that such critical posts might be censored, a sentiment that reflects broader anxieties about platform governance.
*   **Meta-Commentary:** One user criticized the HN submission's title for editorializing and deviating from the original article's headline, sparking a brief debate on submission standards.

---

