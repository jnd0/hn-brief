# Hacker News Summary - 2026-01-14

## [Scott Adams has died](https://www.youtube.com/watch?v=Rs_JrOIo3SE)
**Score:** 798 | **Comments:** 1309 | **ID:** 46602102

> **Article:** The article is a YouTube video announcing the death of Scott Adams, the creator of the Dilbert comic strip. A top comment provides context from Wikipedia, noting that Adams died of prostate cancer at age 68. It details his rapid health decline in late 2025, including paralysis and heart failure, and his public requests for help accessing a cancer drug. He had publicly stated that January 2026 would be a "month of transition" and was in hospice care at the time of his passing.
>
> **Discussion:** The discussion on Hacker News is a mix of mourning, critical reflection, and cultural commentary. Many users expressed sadness and chose to remember Adams for the significant cultural impact of Dilbert, which was widely praised as a brilliant and insightful satire of corporate life that taught them valuable lessons about the workplace. There was a recurring sentiment to separate his creative legacy from his later, more controversial political opinions, which several commenters noted had come to overshadow his earlier work.

Beyond personal tributes, the conversation touched on broader themes. Some users discussed the specific, tragic details of his final months, including his battle with cancer and his engagement with political figures. A notable thread explored the nature of fame and legacy, questioning how cultural icons of the 90s like Adams might be remembered by younger generations in an era where older media formats are less relevant. The discussion concluded with a shared sentiment of "fuck cancer" and a reflection on the swiftness with which life moves on after a person's passing.

---

## [AI generated music barred from Bandcamp](https://old.reddit.com/r/BandCamp/comments/1qbw8ba/ai_generated_music_on_bandcamp/)
**Score:** 637 | **Comments:** 468 | **ID:** 46605490

> **Article:** The article links to a Reddit post discussing Bandcamp's official policy to bar AI-generated music from its platform. The stated goal is to maintain Bandcamp as a space for human-created art and to support artists. This move is positioned as a direct contrast to platforms like Spotify, which are seen as increasingly overrun with low-effort, AI-generated content ("AI slop").
>
> **Discussion:** The discussion on Hacker News is largely supportive of Bandcamp's decision, viewing it as a necessary step to preserve quality and authenticity in a market flooded with low-effort AI content. However, the conversation explores several nuances and tensions.

A central theme is the distinction between AI as a tool versus AI as a replacement for human creativity. Many commenters differentiate between "purely AI-generated" music, which is often dismissed as "slop," and "AI-assisted" work where a human artist uses AI tools as part of a larger creative process, similar to "vibe coding." There's a concern that a blanket ban could inadvertently punish artists who skillfully integrate AI into their workflow.

The conversation also touches on the practical challenges of enforcement and the definition of "human intention." Some argue that the line is blurry, while others insist that a hard-line rule is necessary to avoid subjectivity and maintain the platform's integrity. The discussion highlights a growing frustration with streaming services like Spotify, which are criticized for promoting AI-generated tracks and even allowing them to hijack existing artist pages. This has led some users to see Bandcamp as a refuge for authentic music discovery and collection, reinforcing their support for its strict policy.

---

## [Apple Creator Studio](https://www.apple.com/newsroom/2026/01/introducing-apple-creator-studio-an-inspiring-collection-of-creative-apps/)
**Score:** 480 | **Comments:** 393 | **ID:** 46601157

> **Article:** Apple announced "Apple Creator Studio," a new subscription bundle for macOS. This subscription provides access to a suite of professional creative applications including Final Cut Pro, Logic Pro, Pixelmator Pro, Motion, Compressor, and MainStage. It also adds new AI features and premium content to the iWork suite (Keynote, Pages, Numbers). The subscription is priced at $12.99/month or $129/year, with a significant educational discount available at $2.99/month or $29.99/year. Importantly, Apple clarified that the traditional one-time purchase options for these individual apps will remain available on the Mac App Store.
>
> **Discussion:** The announcement sparked a varied reaction, focusing on Apple's business strategy, pricing, and the broader ecosystem.

A central theme was the shift to a subscription model. While some users cynically viewed this as Apple "slapping a subscription on existing apps," others defended the move, noting that one-time purchases are still an option. The discussion compared this to Adobe's model, with some seeing it as a direct competitive play. However, a counterpoint was raised that this was more akin to Microsoft's historical suite packaging. The pricing was generally viewed as competitive, especially the educational discount, though concerns were raised about the value for users who only need one or two of the applications.

Beyond the business model, the conversation broadened to Apple's overall strategy for creative professionals. A significant thread lamented the lack of "XCode for iPadOS," which led to a deeper critique of the iPad's identity crisis. One commenter argued that the iPad is caught between being a simple, locked-down device and a potential Mac replacement, with Apple's restrictive policies (like code signing) preventing it from becoming a true development platform. This was linked to the challenges facing the Vision Pro, which also lacks essential developer tools.

Finally, there were several miscellaneous reactions, including nostalgia for discontinued Apple software like Aperture, disappointment over the new "flat" icon design, and questions about the future of updates for the individual professional apps.

---

## [Chromium Has Merged JpegXL](https://chromium-review.googlesource.com/c/chromium/src/+/7184969)
**Score:** 417 | **Comments:** 141 | **ID:** 46597927

> **Article:** The article links to a Chromium code review entry confirming that support for the JPEG XL image format has been merged into the Chromium source code. This marks a significant step in making the modern image format available by default in Chrome and other Chromium-based browsers, reversing a previous decision by Google to remove the feature.
>
> **Discussion:** The discussion is overwhelmingly positive, with users celebrating the reversal of a previous decision to remove JPEG XL (JXL) support. The primary reasons cited for the past reluctance were security concerns related to the original C++ library (`libjxl`) and Google's argument that the web only needed one next-generation format (favoring AVIF).

A key turning point mentioned by commenters is the development of a new, memory-safe implementation of the JPEG XL decoder written in Rust (`jxl-rs`), which alleviates the security fears that previously blocked its adoption.

Commenters compare the formats on several metrics:
*   **Performance:** JXL is seen as a "Pareto-optimal" format, offering a superior balance of compression speed and file size compared to AVIF (which is noted for being very slow to encode) and WebP.
*   **Features:** The new implementation supports animations, progressive decoding, and high dynamic range (HDR), making it a powerful replacement for both JPEG and PNG.
*   **Adoption:** While there is concern about the slow pace of new format adoption (referencing the long journey of WebP), the consensus is that this move by Chromium is a critical step for JXL to gain traction on the web. Some also express disappointment that the JXL specification itself is not freely available.

Overall, the community views this as a major win for web performance and image quality, positioning JXL as a potential "one codec to rule them all" for replacing legacy image formats.

---

## [Scott Adams has died](https://www.usatoday.com/story/entertainment/celebrities/2026/01/13/scott-adams-dead-dilbert-creator-prostate-cancer/88158828007/)
**Score:** 417 | **Comments:** 3 | **ID:** 46603431

> **Article:** This article reports the death of Scott Adams, the creator of the comic strip *Dilbert*, at the age of 69. The cause of death was prostate cancer, which he had been publicly battling. The piece highlights Adams's significant career, noting that *Dilbert* ran for over 30 years and was syndicated in thousands of newspapers worldwide. It also touches upon his controversial public persona and political commentary in later years, which often overshadowed his creative work.
>
> **Discussion:** The discussion on Hacker News was exceptionally brief, as the post was quickly identified as a duplicate of an existing thread. The comments consisted almost entirely of users flagging the repost and moderators consolidating the discussion by moving the comments to the original, older post. There were no substantive comments about Scott Adams's life or work within this specific thread, as all conversation was happening in the duplicate.

---

## [Anthropic invests $1.5M in the Python Software Foundation](https://discuss.python.org/t/anthropic-has-made-a-large-contribution-to-the-python-software-foundation-and-open-source-security/105694)
**Score:** 367 | **Comments:** 164 | **ID:** 46601902

> **Article:** Anthropic is investing $1.5 million into the Python Software Foundation (PSF) over three years. The funding is specifically earmarked to improve the security of the Python ecosystem, including developing new tools for automated proactive review of packages uploaded to PyPI and creating a dataset of known malware. This follows previous donations to the PSF from companies like Google, Amazon, and Microsoft.
>
> **Discussion:** The HN community largely viewed the donation as a positive and pragmatic step, acknowledging Python's critical role in the current AI ecosystem, which is heavily driven by companies like Anthropic. The discussion centered on a few key themes:

*   **Security Focus:** Many commenters recognized that the donation is a strategic move to bolster the security of PyPI, a vital piece of infrastructure that is a frequent target for attacks. This was seen as a necessary investment to protect the entire ecosystem.
*   **The "Roads and Bridges" Argument:** The donation sparked a broader conversation about the chronic underfunding of critical open-source infrastructure. Several users referenced the concept that big tech companies, which build their products on these free resources, have a responsibility to fund their maintenance, framing this as a step in the right direction.
*   **Skepticism and Nuance:** While the sentiment was mostly positive, there was a mix of skepticism. Some users pointed out that $1.5 million is a relatively small sum for a company of Anthropic's size and questioned if it was more for PR. Others noted that the donation is conditional (earmarked for security), which is common for non-profits but worth noting. There was also some criticism directed at the PSF's past management decisions, suggesting that funding needs to be allocated effectively.

---

## [Local Journalism Is How Democracy Shows Up Close to Home](https://buckscountybeacon.com/2026/01/opinion-local-journalism-is-how-democracy-shows-up-close-to-home/)
**Score:** 362 | **Comments:** 247 | **ID:** 46600850

> **Article:** The article argues that local journalism is the bedrock of a functioning democracy, providing essential oversight of local government and community issues that national outlets cannot. It posits that the decline of local news—driven by the collapse of advertising revenue models (especially classifieds) and the rise of digital platforms—has created "news deserts" where citizens are uninformed about critical local matters. The author frames supporting local journalism, whether through subscriptions or civic engagement, as a direct investment in democratic health and tangible community improvement.
>
> **Discussion:** The Hacker News discussion largely validates the article's premise, agreeing that the decline of local journalism is a serious problem, but diverges on the causes and potential solutions.

There is a consensus that the business model for local news is broken. Commenters point to the internet's destruction of lucrative classified ad revenue (specifically citing Rightmove in the UK) and the subsequent inability of local papers to fund the expensive work of attending city council meetings and holding power accountable. This has led to a consolidation of ownership by large media conglomerates, who lack local accountability and often shut down papers for financial reasons.

The conversation splits into two main camps regarding solutions:

1.  **The Public Funding Model:** Several users propose treating local journalism as a public good, funded either through direct government grants or a mandatory fee based on municipal budgets. However, this is immediately met with skepticism about how to ensure independence and prevent the government from controlling the watchdog meant to oversee it. The BBC's regional coverage is mentioned as an imperfect example.

2.  **The Grassroots/Lean Model:** Others suggest a more bottom-up approach, such as lean, one-person operations funded by community subscriptions (akin to Patreon) or volunteer efforts. There's a desire for platforms that could facilitate this, with some lamenting that social media groups (like Nextdoor or Discord) have failed to become venues for substantive local debate, instead devolving into gossip or complaint forums.

Finally, the discussion touches on the quality of existing local journalism. One commenter argues that it has stagnated, becoming biased and serving as a "shill" for local power structures, while others counter that this is a long-standing issue of access journalism, not a new phenomenon caused by financial decline.

---

## [Influencers and OnlyFans models are dominating U.S. O-1 visa requests](https://www.theguardian.com/us-news/2026/jan/11/onlyfans-influencers-us-o-1-visa)
**Score:** 361 | **Comments:** 259 | **ID:** 46603535

> **Article:** A Guardian article reports a significant increase in U.S. O-1 visa applications from influencers and OnlyFans models. The O-1 visa is designated for individuals with "extraordinary ability," traditionally associated with elite scientists, artists, and athletes. The article highlights how the criteria for this visa, which includes evidence of high earnings and major commercial success, are now being met by top-tier social media personalities and adult content creators. This trend is reframing the visa's purpose from one reserved for traditional high culture to one that embraces the modern, and often controversial, digital creator economy.
>
> **Discussion:** The Hacker News discussion presents a multifaceted debate on this trend, with opinions ranging from pragmatic acceptance to moral and systemic concern.

A significant portion of the commenters see this as a logical and even positive evolution. They argue that if the visa exists to attract individuals who export American culture, then top influencers are prime candidates. From this economic viewpoint, they are ideal migrants: they are highly paid, pay taxes without displacing local workers, and are young contributors to the tax base. Many dismiss the controversy, equating modern digital creators with traditional entertainers like actors and models, arguing that the medium has changed but the profession of entertainment has not.

However, other users raise objections on several grounds. A common theme is the perceived dilution of the visa's prestige, with some lamenting that it should be for "scientists" over "influencers." A more pointed legal and moral argument is raised by those surprised that O-1 visas are granted to sex workers, noting that immigration history has been hostile to such professions. This leads to a debate on whether online adult content constitutes prostitution. Finally, some commenters express cynicism, viewing the policy as a cynical government move to tax a lucrative industry, while others see it as a symptom of a "late-stage empire" prioritizing entertainment over substance.

---

## [Signal leaders warn agentic AI is an insecure, unreliable surveillance risk](https://coywolf.com/news/productivity/signal-president-and-vp-warn-agentic-ai-is-insecure-unreliable-and-a-surveillance-nightmare/)
**Score:** 323 | **Comments:** 96 | **ID:** 46605553

> **Article:** The article, based on warnings from Signal's leadership, argues that "agentic AI" (AI systems that can perform actions on a user's behalf) represents a significant and underestimated threat. The core concerns are twofold: security and surveillance. From a security perspective, these AI agents are unreliable and insecure, creating a massive new attack surface. From a surveillance perspective, granting an AI broad access to a user's files and activities to make it "useful" is tantamount to building a perfect, inescapable surveillance system that feeds personal and corporate data to AI vendors. The article frames this as a fundamental conflict between the functionality required for useful agents and the privacy/security principles that companies like Signal champion.
>
> **Discussion:** The Hacker News discussion reveals a community that largely agrees with the premise that agentic AI is a major risk, but debates the root causes, the motivations behind the warnings, and potential solutions.

A central theme is the debate over whether this is an "AI problem" or an "operating system problem." One prominent viewpoint argues that AI is simply exposing long-standing, fundamental flaws in operating system security models. These systems were not designed for the modern, networked world, and their process isolation and sandboxing capabilities are inadequate. This perspective suggests the real issue is a "widespread poor taste" among decision-makers who have historically prioritized convenience over robust security. A counter-argument is that even perfect sandboxing is insufficient because for an AI to be useful, it must be granted access to sensitive data and systems, creating an inherent trust dilemma. Furthermore, enforcing strict isolation is expensive and complex, which is why it hasn't been widely adopted.

There was also some skepticism regarding Signal's motives. One commenter questioned "what is Signal trying to sell us?", suggesting a potential ulterior motive. This was quickly countered by another user who pointed to a recent article about Signal's creator, Moxie Marlinspike, planning to enter the AI space, implying the warnings are a strategic positioning for a future privacy-focused AI product.

Many commenters shared practical, real-world concerns about enterprise adoption. The consensus is that the risks are not theoretical. One user described the current state as a "race to the bottom," where years of security research are being undone by piping all data through AI with an "infinite attack surface." Another noted that while the "human-in-the-loop" model is currently a necessity for reliability, businesses are tempted by cost-cutting to externalize these risks, often without fully understanding them. The discussion concluded with a call for "verified privacy at inference," with many agreeing that the only truly secure solution is to run these models locally, ensuring data never leaves the user's control.

---

## [We can't have nice things because of AI scrapers](https://blog.metabrainz.org/2025/12/11/we-cant-have-nice-things-because-of-ai-scrapers/)
**Score:** 313 | **Comments:** 169 | **ID:** 46608840

> **Article:** The article from MetaBrainz, a project that maintains open music metadata, details how aggressive AI data scrapers are forcing them to lock down their previously open APIs. To manage overwhelming server load and costs caused by these scrapers, MetaBrainz is implementing several changes: requiring authorization tokens for key API endpoints, removing debugging endpoints, and forcing authentication for features like LB Radio. The author argues that this is a "tragedy of the commons," where AI companies are externalizing their data acquisition costs onto volunteer-run, open-source projects, ultimately damaging the open web for everyone.
>
> **Discussion:** The Hacker News discussion is largely sympathetic to MetaBrainz, with a consensus that AI scrapers are causing significant damage to open web projects. The core theme is the frustration that AI companies, instead of collaborating with open data projects, are aggressively scraping them inefficiently, which forces these projects to implement barriers that harm legitimate users. Many commenters share personal anecdotes of shutting down public-facing services or adding authentication due to unsustainable server loads from scrapers.

Several solutions and observations were debated. Some users noted that AI companies have so much funding that the cost of scraping is negligible to them, removing any economic incentive to be more efficient or cooperative. A recurring point was that the problem isn't just the scraping, but its inefficiency; scrapers often ignore readily available bulk data dumps in favor of hammering APIs and websites page-by-page. One commenter suggested a middle ground: a standardized `/.well-known/` path for sites to advertise data dumps, but others countered that scrapers are unlikely to change their behavior. While some argued that adding authentication is a reasonable and necessary response, others worried it would lead to a more locked-down, less accessible internet. The discussion also touched on the difficulty for smaller researchers to access data legitimately, contrasting them with large, well-funded AI companies that act irresponsibly.

---

## [Network of Scottish X accounts go dark amid Iran blackout](https://www.heraldscotland.com/news/25759181.network-scottish-x-accounts-go-dark-amid-iran-blackout/)
**Score:** 306 | **Comments:** 253 | **ID:** 46599574

> **Article:** This article from The Herald reports on a network of X (formerly Twitter) accounts, which posed as Scottish users, that went dark during Iran's internet blackout in June 2025. The accounts, which had previously posted about Scottish independence and other local issues, were identified by the UK Defence Journal and analyzed by the disinformation firm Cyabra as being linked to Iranian influence operations. The article suggests that the blackout inadvertently revealed the network's reliance on infrastructure within Iran. The disinformation spread by these accounts included fabricated, outlandish claims of political and civil unrest in Scotland, such as the seizure of Balmoral Estate and tanks in Edinburgh. The article also notes that the network had previously been observed attempting to sow division around Scottish independence, with Cyabra having claimed that up to 26% of profiles discussing the topic were fake.
>
> **Discussion:** The Hacker News discussion largely validates the article's premise but expands the scope to question the nature, purpose, and broader context of online disinformation.

There was a strong consensus that the primary goal of such fake accounts is not to influence local populations, but rather to manipulate international audiences. Commenters argued that these networks are designed to create a false reality for foreign observers—particularly Americans—to reinforce pre-existing political narratives or to make geopolitical rivals appear unstable. This was compared to other known disinformation campaigns, such as the myth of "no-go zones" in the UK.

The conversation also highlighted a deep skepticism regarding the sources of the information itself. One prominent thread pointed out that the analysis originated from Cyabra, an Israeli-based firm, and questioned the objectivity of a report about Iran from a company with significant ties to the US and Israeli governments. This skepticism was framed as a caution against accepting one state-sponsored narrative at face value, with commenters noting that other nations, including the US, also engage in online astroturfing and influence operations.

Finally, the discussion broadened into a general reflection on the health of online discourse. Several users expressed concern about the prevalence of "sock puppet" accounts on all platforms, including HN, and the difficulty of distinguishing genuine (though perhaps extreme) opinions from manufactured ones. This led to a critique of social media algorithms that reward rage-bait and engagement over nuance, contributing to a more polarized and less intelligent public square.

---

## [Text-based web browsers](https://cssence.com/2026/text-based-web-browsers/)
**Score:** 279 | **Comments:** 106 | **ID:** 46597518

> **Article:** The article "Text-based web browsers" on cssence.com argues that text-based browsers like w3m are facing an increasingly bleak future. The author contends that the modern web's relentless drive towards complex, JavaScript-heavy technologies (like SPAs, WASM, WebRTC) and features (like popovers) creates a widening gap that text-based browsers cannot bridge. While acknowledging that the web *could* technically support lightweight content, the author asserts that it *won't* because the ecosystem consistently chooses not to. The article suggests that attempts to "fix" the web for text browsing are futile and that it's better to embrace the web for its advanced capabilities or turn to dedicated alternative protocols like Gemini, which are designed from the ground up for text-based interaction.
>
> **Discussion:** The Hacker News discussion largely validates the article's pessimistic conclusion, with most users agreeing that the modern web is fundamentally hostile to text-based browsers. The consensus is that the gap is indeed widening and becoming insurmountable.

Key themes from the discussion include:

*   **The Futility of Taming the Modern Web:** Many commenters echo the article's sentiment, describing the effort to use text-browsers on the modern web as a "futile" and losing battle. They point to JavaScript-heavy Single Page Applications (SPAs), mandatory cookie consent banners, and the general complexity of modern sites as insurmountable obstacles. One user noted that even "lite" versions of sites often link back to the full, unusable version. The blocking of text-browsers by services like Google Search and Cloudflare was cited as a major practical barrier.

*   **Alternative Protocols and Tools:** The discussion prominently featured alternatives. The Gemini protocol was brought up as a working, purpose-built solution for a text-centric internet. In terms of software, users praised more advanced or unique tools like `chawan` (a modern terminal browser with CSS/JS support), `edbrowse` (a powerful, scriptable CLI browser with mail/SQL clients), and Emacs' EWW. The idea of using an LLM to summarize web pages for consumption in a text browser was also floated as a potential future approach.

*   **Niche but Critical Use Cases:** Several users defended the continued relevance of text-browsers, not for daily browsing, but for critical, niche scenarios. These include system administration on headless servers, troubleshooting when a graphical environment is broken or inaccessible, and for users with specific accessibility needs (a developer of `edbrowse` is blind).

*   **Web Design and Philosophy:** A few commenters touched on web design practices that could improve the text-browser experience, such as placing navigation after content in the HTML. The conversation also highlighted the philosophical divide between "TUI" (a graphical interface rendered in a terminal) and "CLI" (a purely command-and-response interface), with `edbrowse` being a prime example of the latter's appeal for its linearity and scriptability.

---

## [90M people. 118 hours of silence. One nation erased from the internet](https://state-of-iranblackout.whisper.security/)
**Score:** 257 | **Comments:** 320 | **ID:** 46603910

> **Article:** The linked article, "90M people. 118 hours of silence. One nation erased from the internet," details a massive, multi-day internet shutdown in Iran. It frames the event not just as a technical outage but as a deliberate act by the state to silence 90 million people, effectively "erasing" the nation from the global internet during a period of intense internal conflict and protest. The article highlights the duration (118 hours) and scale of the blackout, linking it to the government's violent crackdown on demonstrators.
>
> **Discussion:** The Hacker News discussion on the Iranian internet shutdown is multifaceted, touching on the technical, political, and human aspects of the event.

A significant portion of the conversation focused on the political and human rights context. Users expressed deep sorrow and anger over the violence against protestors, with some citing unverified but alarming casualty figures, comparing the scale to historical massacres like Tiananmen Square. There was a recurring sentiment of frustration and disillusionment regarding the perceived silence of international human rights organizations and media, with one user starkly suggesting "Iranian blood is worth less." This perceived lack of attention was also linked to broader public ignorance, such as the statistic that many Americans cannot locate Iran on a map, though another user countered that this is common for any non-allied nation.

The technical and strategic implications of the shutdown were also a key topic. Commenters noted that the ability to completely sever a country's internet is a "non-negotiable capability" for any authoritarian regime, learned from the role social media played in the Arab Spring. A debate emerged on whether democratic nations possess similar capabilities, with several users asserting that advanced states have strategic plans to disable critical infrastructure, including the internet, in a crisis.

Finally, the discussion included meta-commentary on the article itself and the nature of the conflict. Some users were skeptical of the source, describing the article's prose as "AI slop" and suggesting it read like a "submarine ad" for a security startup. Others questioned the simplistic "good vs. evil" narrative, pointing to the complex geopolitical realities, such as Iran's network of regional proxies, and warning against the potential negative consequences of foreign intervention.

---

## [What a year of solar and batteries saved us in 2025](https://scotthelme.co.uk/what-a-year-of-solar-and-batteries-really-saved-us-in-2025/)
**Score:** 234 | **Comments:** 326 | **ID:** 46602532

> **Article:** Scott Helme details his experience installing a 10kW solar array and two Tesla Powerwall 2 batteries at his UK home. Over the course of 2025, the system generated 9.9 MWh of electricity. He calculated that the system saved him £4,200 (approximately $5,300) in the first year by avoiding grid purchases and selling surplus energy back to the utility. The article breaks down the system's performance, the financial return on investment, and the significant reduction in his reliance on the national grid.
>
> **Discussion:** The Hacker News discussion centered on the author's high energy consumption, the economics of solar/battery storage, and the practicalities of DIY versus professional installation.

A primary point of contention was the author's baseline energy usage, which many commenters found exceptionally high. Several users noted that his annual consumption of over 21 MWh (excluding solar generation) is likely due to charging two electric vehicles at home. This sparked a side debate about whether such high usage negates some of the environmental benefits (a Jevon's paradox discussion), though the financial savings for the homeowner are clear.

The conversation also delved into the cost and components of these systems. Commenters debated the value of Tesla Powerwalls versus cheaper, higher-capacity alternatives like BYD batteries. There was significant excitement around the falling cost of batteries, with one user detailing a DIY 15kWh system they built for under €1,600. This led to a practical discussion about the barriers to DIY, including technical complexity, utility regulations, and safety codes that often require certified electricians.

Finally, the community offered advice and shared experiences. Topics included the impact of changing government tax credits on the used equipment market, the importance of replacing a roof before installing panels, and the potential of bidirectional EV charging to turn cars into home battery assets. For those feeling overwhelmed, users recommended services like EnergySage to simplify the process of getting professional quotes.

---

## [The UK is shaping a future of precrime and dissent management (2025)](https://freedomnews.org.uk/2025/04/11/how-the-uk-is-shaping-a-future-of-precrime-and-dissent-management/)
**Score:** 217 | **Comments:** 266 | **ID:** 46600194

> **Article:** The article from Freedom News (2025) argues that the UK is developing a system of "precrime" and "dissent management." It posits that the government is moving beyond traditional law enforcement to a model based on predictive policing and risk management. This involves using data and surveillance to identify and neutralize potential threats—both criminal and political—before they materialize. The author suggests this framework is being implemented to manage a population the government knows it is increasingly out of touch with, effectively bypassing open debate in favor of institutional control and enforcement.
>
> **Discussion:** The Hacker News discussion largely mirrors the article's dystopian tone, with commenters expressing concern and drawing parallels to science fiction and history. A central theme is the fear of a "Minority Report" scenario, which leads to a debate on the distinction between punishing conspiracy versus acting on predictive data. While some note that laws against conspiracy already exist, others question whether the goal is crime prevention or the suppression of dissent.

Many users referenced dystopian media, with *Black Mirror* cited as a modern leading indicator and George Orwell's *1984* as the foundational text for these concerns. Commenters also worried about the "watchers," identifying both government and corporations as the entities wielding this power.

Underlying the discussion was a political critique. One user argued this is a tactic for a government that knows it cannot win an open debate, while another countered that the trend is long-standing and not specific to the current administration. A recurring sentiment was the danger of creating powerful frameworks that could be abused by future, potentially worse, governments.

---

## [Show HN: Self-host Reddit – 2.38B posts, works offline, yours forever](https://github.com/19-84/redd-archiver)
**Score:** 214 | **Comments:** 52 | **ID:** 46602324

> **Project:** This project, "Self-host Reddit," is a tool that allows users to download and host a massive offline archive of Reddit content. The project provides a torrent link to a dataset containing 2.38 billion posts and comments from Reddit, as well as from the now-defunct platforms Voat and Ruqqus. The system is built to be self-hosted using Docker and includes an API and an MCP (Model Context Protocol) server, making the data accessible for personal use, local browsing, or integration with other applications like AI models.
>
> **Discussion:** The Hacker News community response was a mix of technical feedback, philosophical debate, and use-case brainstorming. A key theme was the ethical and social implications of archiving user-generated content. One user expressed frustration that deleted or protest-overwritten comments on Reddit make old, useful information inaccessible, and suggested a plugin to restore them from archives. This sparked a debate on user autonomy versus the public good of preserving information, with some arguing that users have the right to delete their contributions, while others see the archive as a vital resource.

Another major point of discussion was the use of this data for training AI, with several users noting that this is the likely primary use case, raising questions about whether content creators should be compensated. The project's inclusion of archives from controversial platforms like Voat was also questioned, but the creator defended their position by stating they will support any platform for which a complete dataset is available. On the technical side, a user reported initial issues with the Docker setup, which the creator quickly addressed by updating the documentation and adding missing configuration files. Finally, users also shared alternative data sources and discussed potential integrations, such as using the archive with the discontinued Apollo app.

---

## [When hardware goes end-of-life, companies need to open-source the software](https://www.marcia.no/words/eol)
**Score:** 212 | **Comments:** 55 | **ID:** 46609492

> **Article:** The article argues that when hardware reaches its "end-of-life" (EOL) and companies cease support, they should be required to open-source the necessary software and specifications. The author uses the example of a smart kitchen scale that became a "brick" after its app was discontinued, rendering a perfectly functional device useless. The proposed solution is not to open-source the entire codebase, but to publish a basic GitHub repository containing hardware specs and connection protocols. This would empower the community to build their own apps and firmware, allowing the hardware to be repurposed and preventing electronic waste.
>
> **Discussion:** Discussion unavailable.

---

## [Games Workshop bans staff from using AI](https://www.ign.com/articles/warhammer-maker-games-workshop-bans-its-staff-from-using-ai-in-its-content-or-designs-says-none-of-its-senior-managers-are-currently-excited-about-the-tech)
**Score:** 209 | **Comments:** 111 | **ID:** 46607681

> **Article:** IGN reports that Games Workshop (GW), the maker of Warhammer, has banned its staff from using AI in content or design. According to the article, none of GW's senior managers are currently "excited" about the technology. The policy appears to be a proactive measure to protect the company's intellectual property and maintain the unique, handcrafted aesthetic that defines their brand and justifies their premium pricing. The article suggests that while the company may be internally cautious, the ban is framed as a lack of excitement from leadership rather than a blanket prohibition on future exploration.
>
> **Discussion:** The Hacker News discussion centered on the business, creative, and cultural implications of Games Workshop's anti-AI stance. The conversation can be grouped into several key themes:

**Lore and Community Alignment**
Many commenters found the decision humorously "lore-accurate," noting that the Warhammer universe refers to AI as "Abominable Intelligences" and treats it as a tech-heresy. This was seen as a smart PR move that aligns perfectly with their established world-building and caters to a fanbase that is often skeptical of new technology.

**Business and Legal Strategy**
The consensus is that this is a sound business decision. Commenters pointed out that GW has invested heavily in creating a unique, copyrightable art style and lore. Using AI, which is trained on external data, would introduce significant legal risks regarding copyright infringement and dilute the brand's distinct identity. The policy is viewed as a way to protect their high-value IP and avoid future lawsuits.

**The "Anti-AI" Hypocrisy**
A major point of debate was the apparent hypocrisy in the tabletop community. While many hobbyists are vocally against AI for art and game design, they often express a desire to use AI to replace expensive programmers for building websites or software. Commenters attributed this to a lack of respect for programming as a creative endeavor and greater public sympathy for struggling artists versus well-paid engineers.

**AI as a Tool vs. a Replacement**
Several users argued that GW is missing an opportunity by not using AI as an *assistant* for iterative design, background concepts, or tedious tasks like optimizing sprue layouts. However, the prevailing view was that the current quality of AI-generated content is too generic and "obvious" for a premium brand like Warhammer, and that the risk of losing creative control and legal battles outweighs any potential efficiency gains.

---

## [Indifference is a power](https://aeon.co/essays/why-stoicism-is-one-of-the-best-mind-hacks-ever-devised)
**Score:** 200 | **Comments:** 211 | **ID:** 46601121

> **Article:** The article argues that Stoicism is a powerful "mind hack" for modern life, centered on the principle of "indifference" to things outside our control. It posits that by distinguishing between what we can influence (our judgments, reactions, and character) and what we cannot (external events, others' opinions), we can achieve a state of tranquility and resilience. The author presents Stoicism not as an emotionless void, but as a practical framework for navigating adversity, maintaining inner peace, and focusing our energy effectively. It is framed as an ancient philosophy with timeless relevance for managing the chaos and stress of the contemporary world.
>
> **Discussion:** The Hacker News discussion presents a nuanced and often critical view of modern Stoicism, revealing a significant gap between its popular perception and its philosophical roots. A central theme is the danger of misinterpreting Stoicism as emotional suppression. The top comment warns against becoming a "dissociated" stoic who runs up an "emotional debt," arguing that the true practice involves acknowledging and integrating emotions, not ignoring them. This sentiment is echoed by others who fear that pop-Stoicism, particularly in online "manosphere" circles, is used to repackage unhealthy masculine traits like "sucking it up" and bottling up feelings.

There is a clear distinction drawn between "pop Stoicism" and the more complex original philosophy. One commenter provides a stark quote from Epictetus about treating the death of a loved one with the same indifference as a broken cup, highlighting how ancient Stoicism can seem dark or inhuman to a modern reader. However, others defend this as a form of cognitive reframing, a tool for managing perspective rather than a literal command to feel nothing.

Several commenters offer practical advice or alternatives. A popular thread connects Stoic principles to Cognitive Behavioral Therapy (CBT), suggesting that books like "Feeling Good" provide a modern, actionable handbook for the Stoic mindset. Another user critiques Stoicism as a potentially harmful oversimplification, comparing it to recommending alcohol to a social drinker—useful for some, but dangerous for others. Finally, some users offer their own interpretations, such as the "gray rock" tactic for dealing with conflict, or clarify that Stoicism is about committing to one's values while remaining indifferent to outcomes, not about lobotomizing ambition.

---

## [The insecure evangelism of LLM maximalists](https://lewiscampbell.tech/blog/260114.html)
**Score:** 199 | **Comments:** 186 | **ID:** 46609591

> **Article:** The article "The insecure evangelism of LLM maximalists" argues that the aggressive promotion of Large Language Models (LLMs) for coding often stems from insecurity. The author posits that if a tool truly makes you significantly more productive and effective, you wouldn't need to evangelize it so forcefully; the results would speak for themselves. The piece suggests that this evangelism is often an attempt to convince both others and themselves that their skills are not being devalued. The author contrasts this with their own experience, finding LLMs useful as a "digital clerk" for specific, limited tasks but not as a revolutionary force that has dramatically boosted their productivity, concluding that the "insecure" push is a reaction to a perceived threat to the value of programming skills.
>
> **Discussion:** The Hacker News discussion is a multifaceted debate on the role and impact of LLMs in programming, with many users expressing nuanced or mixed feelings. A central theme is the tension between productivity and quality. Some commenters argue that in a competitive business environment, the ability to rapidly generate features with LLMs, even if the code is "slop," can be an advantage. Others counter that this creates a "liability" of hidden bugs and technical debt, and that true productivity isn't just about lines of code produced but about creating robust, maintainable systems.

There is a strong consensus that LLMs are best suited for specific use cases rather than as a universal solution. They are praised for handling boilerplate, exploring unfamiliar languages, and acting as an assistant for tasks like searching documentation or writing SQL queries. However, they are widely seen as failing when given large, nuanced, or highly specific problems, which require deep domain knowledge and architectural thinking.

The discussion also touches on the philosophical and career-oriented implications. Several users expressed a fear that over-reliance on LLMs will stunt the growth of junior developers, preventing them from gaining a fundamental understanding of how systems work. This led to a debate on whether using these tools is a sign of a poor programmer or simply a pragmatic craftsman using a new tool. Finally, a recurring sentiment was "debate fatigue," with some users wishing the community would move past the endless pro-vs-anti-LLM arguments and focus on sharing concrete examples of work and achievements.

---

