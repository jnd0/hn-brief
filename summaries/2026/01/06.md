# Hacker News Summary - 2026-01-06

## [It's hard to justify Tahoe icons](https://tonsky.me/blog/tahoe-icons/)
**Score:** 2099 | **Comments:** 818 | **ID:** 46497712

> **Article:** The article "It's hard to justify Tahoe icons" by Anton Troynikov argues that Apple's recent UI changes in macOS, specifically the inconsistent and often removed icons in menu items, represent a decline in user experience design. He contrasts the "Tahoe" style (e.g., in the latest macOS) with older, more functional interfaces like Windows 2000 and early macOS versions, where icons were consistently used to aid visual scanning and usability. The author points out that removing icons doesn't save space effectively and leads to a less readable, "flat" interface. He posits that this trend is driven by a desire for constant visual change rather than genuine usability improvements, which is frustrating for users who rely on these visual cues.
>
> **Discussion:** The Hacker News discussion is dominated by a significant irony pointed out by numerous users: the author's blog post about unnecessary UI clutter and distraction features a prominent, full-screen animated snow effect that readers found distracting and hard to read. Many commenters noted they had to use browser reader modes or turn off the animation to comfortably consume the article. This led to a debate about the difference between a personal blog (where such "fun" distractions are permissible and can be disabled) versus a commercial operating system (where usability is paramount).

Beyond the site's design, the conversation largely agrees with the article's core thesis. Users reminisced about the "peak" of UI design in Windows 2000/XP and older macOS versions, lamenting that modern UI changes often prioritize aesthetics or developer KPIs over user productivity. There was a broader sentiment that as computers became necessities, the evolutionary pressure to maintain high usability has decreased, leading to "enshittification." Some commenters also offered technical solutions, like trying Linux desktop environments (KDE) which they feel handle these UI details better.

---

## [Anna's Archive loses .org domain after surprise suspension](https://torrentfreak.com/annas-archive-loses-org-domain-after-surprise-suspension/)
**Score:** 600 | **Comments:** 311 | **ID:** 46497164

> **Article:** The article from TorrentFreak reports that Anna's Archive, a major search engine for pirated books and academic papers, has lost its `annas-archive.org` domain. The domain was suspended unexpectedly with a "ServerHold" status, a measure typically enacted by registries during legal disputes. The suspension is widely believed to be the result of pressure from major music labels and other rights holders. The project's team has advised users to find their current domains via their Wikipedia page, a practice that has sparked discussion about using Wikipedia as a decentralized DNS system. The article also mentions that the site remains accessible through its `.se` domain and other mirrors.
>
> **Discussion:** The Hacker News discussion centered on the implications of the domain seizure, strategies for censorship resistance, and the Streisand effect.

A primary theme was the "Streisand Effect," where users noted that the high-profile takedown attempt serves as great publicity, likely increasing awareness and traffic for Anna's Archive. Many commenters who were previously unaware of the service expressed interest in checking it out and supporting its mission of digital preservation, comparing it to seed vaults for cultural heritage.

Technical and decentralized solutions were a major point of discussion. Users suggested alternatives like using the Yggdrasil network, Tor `.onion` services, and especially torrenting the archive's content to make it resilient to takedowns. The use of Wikipedia as a "DNS" to list current domains was debated; one side saw it as a clever workaround, while another warned it could invite legal action against Wikipedia itself. Nostr was also proposed as a decentralized communication channel, though this led to a side discussion about the platform's own controversies.

Finally, there was a technical deep-dive into the `serverHold` status code, with commenters confirming it's a common tool used by registries in response to legal pressure. The consensus was that while domain seizures are a predictable consequence of challenging large industries, they are ultimately ineffective at stopping the distribution of information once it's in the wild.

---

## [Databases in 2025: A Year in Review](https://www.cs.cmu.edu/~pavlo/blog/2026/01/2025-databases-retrospective.html)
**Score:** 520 | **Comments:** 150 | **ID:** 46496103

> **Article:** This article, "Databases in 2025: A Year in Review" by Andy Pavlo of CMU, provides a retrospective on the significant developments in the database landscape during 2025. The post is structured around several key trends. A major theme is the rise of "AI-Native Databases," which are designed to integrate with LLMs and AI agents, exemplified by technologies like Model Context Protocol (MCP). Pavlo also discusses the continued evolution of established database categories, noting improvements in analytical and transactional systems. He highlights the growing importance of "Database-as-a-Service" (DBaaS) platforms and the increasing relevance of specialized databases for time-series and immutable data. The article also touches on notable industry movements, such as acquisitions and the rebranding of projects like EdgeDB to Gel. Pavlo's analysis is presented with a mix of technical insight and his characteristic, often humorous, style.
>
> **Discussion:** The Hacker News discussion centered on a few key themes. A significant portion of the conversation revolved around the security implications of AI-integrated database protocols like MCP. Commenters expressed skepticism, arguing that MCP's philosophy of maximizing context availability directly conflicts with the principle of least privilege and could reintroduce SQL injection-style vulnerabilities via LLM hallucinations. One user shared a link to a project they built to mitigate this risk.

Another major topic was the omission of certain database technologies. Several users were surprised that the article did not mention SQLite, DuckDB, or time-series databases. The author, Pavlo, actively responded to these comments, clarifying that these topics were indeed covered in the article, suggesting that readers may have skimmed or missed those sections. This led to a side discussion on the perception of SQLite's production-readiness versus its widespread use.

Finally, the conversation included a nostalgic and appreciative tone. Some commenters reminisced about the CMU database group's unique and energetic teaching style, sharing links to their famous "gangsta intros" and lectures. Others simply thanked Pavlo for the comprehensive annual review, highlighting its value to the community.

---

## [Murder-suicide case shows OpenAI selectively hides data after users die](https://arstechnica.com/tech-policy/2025/12/openai-refuses-to-say-where-chatgpt-logs-go-when-users-die/)
**Score:** 417 | **Comments:** 251 | **ID:** 46499983

> **Article:** An article from Ars Technica reports on a legal case involving a murder-suicide where the victim's estate is seeking ChatGPT logs from OpenAI as evidence. The estate's lawyers argue the logs could show how the AI may have contributed to the user's state of mind. OpenAI is resisting the discovery request, stating it will only release data in specific, limited circumstances and not as part of a broad "fishing expedition." The article highlights the growing tension between user privacy, corporate secrecy, and the need for transparency when AI is implicated in real-world harm.
>
> **Discussion:** The Hacker News discussion is highly critical of both OpenAI's data policies and the inherent risks of current AI models. A dominant theme is the critique of OpenAI's "Orwellian" approach to data, with users noting the irony of a company named "OpenAI" being secretive, especially in a tragic legal case. Commenters express concern that the company's refusal to provide data obstructs justice and accountability.

Many users also focused on the AI's behavior, pointing to a pattern of "sycophantic" and delusional responses that can dangerously validate a user's spiraling mental state. Several commenters shared links to videos and other reports documenting this phenomenon, suggesting it's a known and dangerous flaw.

A significant counter-argument emerged, questioning whether AI is the primary cause of such tragedies. Some commenters suggested that underlying mental health issues or other factors (like substance abuse mentioned in the case) were more likely the root cause, and that blaming AI is a sensationalist narrative. This led to a broader debate on regulation, with some arguing that technology with "clear potential for harm" should be more strictly controlled, while others countered that this logic would outlaw many common items. The discussion concluded with a sense of deep skepticism about the industry's goal of building "superintelligence," with many commenters feeling that if current models are unsafe, future ones will be even more so.

---

## [RevisionDojo, a YC startup, is running astroturfing campaigns targeting kids](https://news.ycombinator.com/item?id=46499976)
**Score:** 389 | **Comments:** 66 | **ID:** 46499976

> **Article:** The article (likely from a source like 404 Media) accuses RevisionDojo, a Y Combinator-backed startup, of running astroturfing campaigns. The startup, which provides study tools for students, is allegedly using fake social media accounts to promote its products and target children. The post frames this as an unethical marketing practice specifically aimed at a vulnerable demographic.
>
> **Discussion:** The Hacker News community reacted with cynicism and outrage, viewing the accusation as emblematic of broader issues within the startup ecosystem. The prevailing sentiment is that unethical behavior is common among Y Combinator-backed companies, with users citing a culture of "fake it till you make it" that often blurs the line into fraud.

Discussion quickly expanded beyond RevisionDojo to include other startups accused of deceptive practices, such as the AR device company Pickle and the browser extension Honey. Commenters also generalized the issue to the wider internet, noting that astroturfing and sockpuppeting are rampant on platforms like Reddit, where it has become a commoditized business model. While some debated the ethics of the test-prep market itself, the core consensus was a deep skepticism toward startup ethics and the effectiveness of self-regulation on social media.

---

## [There were BGP anomalies during the Venezuela blackout](https://loworbitsecurity.com/radar/radar16/)
**Score:** 359 | **Comments:** 180 | **ID:** 46504963

> **Article:** The article by Low Orbit Security analyzes BGP (Border Gateway Protocol) routing data to argue that the Venezuelan power grid blackout on March 7, 2019, was likely the result of a sophisticated state-sponsored cyberattack, rather than a domestic accident as claimed by the Maduro regime. The author points to a specific BGP anomaly occurring approximately 24 hours before the blackout, where internet traffic from Venezuela's state-owned ISP (CANTV) was briefly rerouted through Telecom Italia Sparkle, a major international transit provider. The article suggests this reroute could have been used to intercept traffic, map network infrastructure, or prepare for the subsequent disruption of the power grid. The analysis frames the event as a demonstration of modern hybrid warfare capabilities, where digital infrastructure is targeted to create physical chaos.
>
> **Discussion:** The Hacker News discussion primarily focused on the geopolitical implications of the alleged cyberattack and the nature of modern cyber warfare. Many commenters expressed shock at the brazenness of the operation, debating whether it was a calculated US military action or a reckless gamble that could have escalated into open conflict. The conversation quickly broadened to include current geopolitical tensions, with users drawing parallels to the Trump administration's threats to purchase Greenland, suggesting a pattern of aggressive foreign policy.

Technical discussions centered on the mechanics of BGP and the potential goals of the attack. Users speculated that the rerouting could have been used for passive surveillance of Venezuelan internet traffic or, more disruptively, to sever communication channels like WhatsApp and Telegram to prevent citizens from organizing. A counter-theory was raised that the BGP anomalies might have been a side effect of the power outage rather than a precursor to it, though the timeline of events makes this less likely in the eyes of most observers.

Finally, the discussion touched on the broader strategic consequences of such attacks. There was a consensus that this event reinforces the incentive for nations to develop nuclear deterrents as a safeguard against "snatch operations" and cyber-kinetic strikes. The dependency on foreign technology—whether American or otherwise—was also debated, with some seeing it as a critical vulnerability and others noting that for many nations, there is no viable alternative to the dominant US tech stack.

---

## [During Helene, I just wanted a plain text website](https://sparkbox.com/foundry/helene_and_mobile_web_performance)
**Score:** 330 | **Comments:** 183 | **ID:** 46494734

> **Article:** The article, "During Helene, I just wanted a plain text website," is a personal account from a web developer who experienced the aftermath of Hurricane Helene with severely limited mobile internet access. Frustrated by news and information websites that were slow to load, unresponsive, and consumed precious data, the author makes a plea for developers to build simpler, more performant, and resilient websites. The core argument is that while modern web features are valuable, they should not come at the cost of basic accessibility, especially during a crisis when information is critical and connectivity is scarce. The author advocates for a "mobile-first" philosophy that truly prioritizes performance and data efficiency over bloated frameworks and heavy assets.
>
> **Discussion:** The Hacker News discussion largely validates the author's experience, expanding on the themes of web bloat, resilience, and the economic drivers behind poor web design. A central theme is the critique of the modern web stack. Several commenters pointed out the irony of the author's own site (built with Next.js and laden with trackers) being an example of the very problem it describes, highlighting how difficult it is to escape modern web bloat. Solutions proposed by users include using text-only versions of news sites (like CNN Lite), employing browser extensions like NoScript to block bloat, and a general call for CMSs to normalize offering a lightweight, text-only mode.

The conversation also touched upon the reliability of information systems during disasters. One commenter shared a detailed anecdote about the failure of amateur radio repeaters during a hurricane, which led them to conclude that traditional AM radio remains a more dependable medium. Another thread discussed the economic reasons why companies don't prioritize fixing bad websites, noting that for many, a poor user experience has no direct impact on their bottom line. Finally, a debate emerged on whether technology should be designed for "edge cases" like disasters, with many arguing that for crisis-related information, resilience and accessibility should be a primary design goal, not an afterthought. The discussion concluded with practical, real-world advice on disaster preparedness, such as carrying cash and having multiple mobile network options.

---

## [California residents can now request all data brokers delete personal info](https://consumer.drop.privacy.ca.gov/)
**Score:** 288 | **Comments:** 78 | **ID:** 46495220

> **Article:** The article announces that California residents can now use a new state-run portal to request that all registered data brokers delete their personal information. This service is part of the California Delete Act, which builds upon the existing California Consumer Privacy Act (CCPA). The state also maintains a public registry of data brokers, enabling residents to submit a single, comprehensive deletion request to all of them at once, rather than contacting each one individually.
>
> **Discussion:** The Hacker News discussion reveals a mix of appreciation for the law's intent and significant skepticism about its practical effectiveness. A key clarification is that while the right to delete existed before, the new state-provided platform simplifies the process by leveraging a mandatory state registry of data brokers, allowing for a one-to-many request.

However, several major concerns were raised:
*   **Enforcement and Loopholes:** Many users doubt the law's ability to be enforced. They point out that data brokers can simply repurchase the same data from other sources, creating a "catch-22" where a "do not track" list requires keeping some data. The 45-day compliance window is also seen as a loophole, allowing brokers to hold data for nearly a month andtime their data sales accordingly.
*   **The Root Problem:** A recurring theme is that deletion is a reactive solution. The fundamental issue, as many commenters see it, is that data collection without explicit consent is the default. They argue that an "opt-in" system would be far more effective than an "opt-out" one.
*   **Practical Impact:** The value of the law was debated. Some shared personal anecdotes of how personal data can be weaponized by malicious individuals (e.g., jealous ex-partners), highlighting a real safety benefit. Others, however, questioned how much this impacts the average person's daily life.
*   **Technical and Political Hurdles:** Users also noted practical issues, such as being blocked by Cloudflare's bot detection. Politically, there was pessimism about the possibility of a similar federal law, with one user cynically suggesting that corporate lobbying prevents it.

---

## [All AI Videos Are Harmful (2025)](https://idiallo.com/blog/all-ai-videos-are-harmful)
**Score:** 285 | **Comments:** 296 | **ID:** 46498651

> **Article:** The article "All AI Videos Are Harmful" argues that AI-generated video content is fundamentally damaging. The author contends that it is not a tool for genuine creativity but rather a mechanism for mass-producing low-quality, derivative content. Key harms identified include the erosion of human creative craft, the proliferation of misinformation and scams, and the creation of a visually jarring "uncanny valley" effect that is unpleasant for viewers. The article also points to the unethical foundation of these models, which are trained on vast amounts of uncredited, copyrighted material, and the societal risks of a "race to the bottom" in media quality and trust.
>
> **Discussion:** The Hacker News discussion reveals a deeply divided audience, with most users engaging critically with the article's premise. A central theme is the debate over whether AI video is a tool for or a replacement of human creativity. Many commenters argue that most AI video output is low-effort "slop" that removes the craft and intention from the creative process, leading to a flood of misinformation and a "race to the bottom" in advertising and media quality. The visceral, negative reaction to the "AI aesthetic" or "uncanny valley" was noted by several users, with some viewing it as an adaptive defense mechanism against inauthentic content.

Conversely, a significant counter-argument emerged, defending AI video as a democratizing tool for aspiring creators who lack the technical skills or resources to realize their visions. Proponents cited specific examples of artists and channels using AI in innovative ways, often by combining it with traditional editing, scripting, and performance, or by leaning into the technology's unique aesthetic. Skepticism about the article's alarmist tone was also present, with some commenters suggesting that the perceived problems are either overstated or a temporary phase that will resolve as the technology matures and becomes indistinguishable from human-made content. Finally, a pragmatic view suggested that the solution lies not in banning the technology but in developing better critical thinking and media literacy skills to navigate a polluted information ecosystem.

---

## [Microsoft Office renamed to “Microsoft 365 Copilot app”](https://www.office.com)
**Score:** 270 | **Comments:** 225 | **ID:** 46496465

> **Article:** The article reports that Microsoft has rebranded its Office mobile and web application to the "Microsoft 365 Copilot app." The title on office.com now reflects this change, explicitly stating "Welcome to the Microsoft 365 Copilot app" and noting it is the new name for the former "Office" app. This change appears to apply specifically to the unified application interface rather than the entire Office suite product line.
>
> **Discussion:** The HN community reaction is overwhelmingly negative, characterizing the rebrand as "bizarre," "desperate," and "confusing." Users express disbelief that Microsoft would dilute the globally recognized "Office" brand—which one commenter notes has 50 years of equity—in favor of the "Copilot" AI branding. The consensus is that the name "Microsoft 365 Copilot app" is a mouthful that fails to describe the product's function, with sarcastic remarks suggesting the marketing department has been renamed "Copilot Human Incentivizing."

Several cynical theories emerged regarding the motivation behind the change. The most prominent is that Microsoft is artificially inflating Copilot's adoption metrics by forcing the app on users who are simply trying to access Office. Others noted that this rebrand actually occurred six months ago, but the confusion persists. Commenters compared the move to other infamous rebrands like Twitter becoming "X," viewing it as a case study in destroying brand value to chase AI hype.

---

## [Show HN: DoNotNotify – log and intelligently block notifications on Android](https://donotnotify.com/)
**Score:** 269 | **Comments:** 114 | **ID:** 46499646

> **Project:** DoNotNotify is an Android application designed to give users granular control over their notifications. It allows users to log notifications and create intelligent, rule-based filters to automatically block or dismiss them. The primary goal is to help users eliminate spam, marketing, and other unwanted notifications from apps that they cannot or do not wish to uninstall, thereby reducing digital distraction and improving focus.
>
> **Discussion:** The Hacker News community response was broadly positive, with users expressing a shared frustration over notification spam, particularly from essential apps that mix utility alerts with marketing. The discussion highlighted several key themes:

Many users shared their existing solutions, with a recurring mention of the Android app **BuzzKill** as a mature and feature-rich alternative. Other strategies included simply putting the phone on silent, disabling notifications entirely for most apps, or using separate user profiles to isolate work apps.

A significant portion of the conversation centered on the root cause: **app developers abusing notification permissions**. Commenters criticized major apps like Facebook, Uber, and DoorDash for pushing ads and promotions through the same notification channels used for critical user information. This was described as a "dark pattern," with users wishing for stricter enforcement from app stores.

The discussion also touched on platform differences, with Android users appreciating features like notification channels and user profiles, which are not available on iOS. A practical limitation of the Android OS was noted: persistent notifications (like those from VPNs or system services) cannot be programmatically dismissed by a third-party app, though DoNotNotify can still log them. Finally, a forward-looking suggestion was made to use local Large Language Models (LLMs) for more sophisticated, context-aware notification filtering.

---

## [A spider web unlike any seen before](https://www.nytimes.com/2025/11/08/science/biggest-spiderweb-sulfur-cave.html)
**Score:** 268 | **Comments:** 133 | **ID:** 46496054

> **Article:** The New York Times article reports the discovery of the world's largest spider web, located inside a remote, pitch-black cave in the remote mountains of the Amazon. The web spans a massive area and is home to an estimated 111,000 spiders from a single species. The ecosystem is sustained by a unique food chain: the cave's high concentration of hydrogen sulfide gas supports a massive population of midges (over 2.4 million), which in turn serve as the primary food source for the spiders. The article highlights the sheer scale of this hidden biological wonder and the extreme environment that protects it.
>
> **Discussion:** The Hacker News community reaction ranged from visceral to deeply curious. Many users expressed a "nope" reaction to the sheer number of spiders, while others shared personal anecdotes about cohabitating with house spiders. The primary scientific curiosity focused on the ecosystem's sustainability: users quickly identified the midge population as the food source and debated how such a massive insect population thrives in a toxic, sulfur-filled environment.

There was also a discussion regarding the spiders' behavior. While spiders are typically solitary, commenters noted that hundreds of species are actually social, and the extreme isolation of the cave likely necessitates cooperative living. A minor controversy arose regarding the safety of the researchers in the video, with one user questioning why they weren't wearing gas masks, though others pointed out that the article explicitly states the researchers were wearing masks and eventually acclimated to the smell. Finally, technical users discussed the limitations of the archiving service used to bypass the NYT paywall, specifically its inability to properly archive the article's embedded video.

---

## [X blames users for Grok-generated CSAM; no fixes announced](https://arstechnica.com/tech-policy/2026/01/x-blames-users-for-grok-generated-csam-no-fixes-announced/)
**Score:** 258 | **Comments:** 483 | **ID:** 46503199

> **Article:** An article on Ars Technica reports that X (formerly Twitter) is blaming users for generating Child Sexual Abuse Material (CSAM) using its AI chatbot, Grok, and has announced no technical fixes to prevent this. The article highlights that despite X's safety team stating they will take action against users who prompt Grok to create illegal content, they have not implemented basic safeguards, such as system prompts, to stop the AI from generating such material. The piece notes that Grok is also being widely used to create non-consensual sexual images of public figures and everyday users, and questions whether X's legal liability shield, Section 230, applies to content created by its own AI.
>
> **Discussion:** The Hacker News discussion is overwhelmingly critical of X's position, with commenters expressing a mix of outrage, cynicism, and legal analysis. The dominant sentiment is that X is shirking its responsibility by blaming users for a problem it created and could easily mitigate. A common analogy used was that X's stance is akin to "hiring someone to draw CSAM and then telling people to stop asking them for it."

Several key themes emerged from the discussion:

*   **Inadequate Safeguards:** Many users argued that X has failed to implement even the most basic technical guardrails, such as instructing Grok in its system prompt not to generate illegal or sexualized content. The failure to do so is seen as a deliberate choice.
*   **Widespread Misuse:** Beyond CSAM, commenters pointed to the rampant use of Grok to generate non-consensual sexual images of women and other users, creating a toxic and unsafe environment. One user provided links as evidence of this problem, and others noted it was a major reason they had left the platform.
*   **Legal Liability:** A significant portion of the debate centered on the legal implications. Commenters argued that Section 230, which typically shields platforms from liability for user-generated content, should not apply here because Grok is an agent of X itself. There was speculation that X could face civil liability (e.g., for slander) and even criminal investigation, though many were pessimistic about any real consequences given the current political climate.
*   **Platform Decline and Broader Culture:** The conversation frequently drifted to the overall decline of X, with users citing issues like paid "verified" comments promoting extremist views and a general increase in vitriol. The CSAM issue was framed by some as part of a larger, more troubling cultural shift where far-right movements provide cover for pedophilia and other extremist ideologies, questioning why app stores and payment processors continue to support the platform.

---

## [Jensen: 'We've done our country a great disservice' by offshoring](https://www.barchart.com/story/news/36862423/weve-done-our-country-a-great-disservice-by-offshoring-nvidias-jensen-huang-says-we-have-to-create-prosperity-for-all-not-just-phds)
**Score:** 247 | **Comments:** 450 | **ID:** 46498309

> **Article:** The article reports on NVIDIA CEO Jensen Huang's statement that the US "did our country a great disservice" by offshoring manufacturing. Huang advocates for bringing these jobs back, specifically by using government incentives and "force" to compel companies to build AI infrastructure (like data centers) within the United States. His stated goal is to create prosperity for a broader segment of the population, not just highly educated elites.
>
> **Discussion:** The HN discussion is largely skeptical of Jensen Huang's motives and the feasibility of his proposals. The prevailing sentiment is that Huang's sudden patriotism is self-serving—a strategy to secure government subsidies and favorable regulations for NVIDIA's data center expansion, rather than a genuine concern for the working class.

The debate centers on three main themes:

*   **Wealth Distribution vs. Job Creation:** Many commenters argue that the core issue is not a lack of wealth, but extreme inequality. They contend that bringing back jobs without addressing how profits are distributed will only enrich shareholders and executives like Huang, not the average worker.
*   **The Nature of Modern Jobs:** There is significant skepticism about the quality of jobs being promised. Users point out that modern data centers require far fewer employees than traditional factories, and that the jobs created may not be accessible to the "non-PhD" workforce Huang claims to want to help.
*   **Historical Context and Political Cynicism:** The discussion frequently references Ross Perot's 1992 "giant sucking sound" warning about NAFTA, framing Huang's comments as a late realization of a long-standing problem. Ultimately, most commenters view his statement as a political maneuver ("kissing the ring") to align with the current political climate and secure NVIDIA's position.

---

## [I switched from VSCode to Zed](https://tenthousandmeters.com/blog/i-switched-from-vscode-to-zed/)
**Score:** 220 | **Comments:** 230 | **ID:** 46498735

> **Article:** The article is a personal blog post detailing the author's experience switching from VS Code to the Zed code editor. The author outlines their motivations, which include Zed's superior performance, its modern and clean user interface, and the integrated AI features. They compare specific workflows like file searching and multi-cursor editing, concluding that while there is a minor learning curve, the overall benefits, especially speed and the "feel" of the editor, made the switch worthwhile for them.
>
> **Discussion:** The Hacker News discussion largely validates the author's positive experience but highlights several key adoption barriers and points of contention. A significant portion of the conversation revolves around ecosystem lock-in and compatibility. One user in the embedded systems field states they are unable to switch because chip manufacturers have standardized on VS Code as a platform for their toolchains. Another user, a former WebStorm user, notes the lack of a vertical tab feature, a workflow they are so committed to that they maintain their own patched version of Zed.

Technical polish and platform support are also major themes. Several users point to lingering issues that prevent them from switching, such as poor font rendering on low-DPI monitors, which some commenters express surprise still exists, and sub-par Emacs keybinding support compared to VS Code extensions. The discussion also touches on the tension between Zed's focus on cutting-edge features like AI and the community's desire for foundational improvements. One user wishes the team would prioritize basic editor features (like semantic highlighting) over AI, while another notes that the AI features are already quite stable and useful.

Finally, there are differing views on the editor's ecosystem. While some lament the lack of features like a built-in REPL for Lisp, others suggest that Zed's integration with modern development tools like Nix and Direnv is a major strength. The conversation also reveals a divide in hardware, with users on modern high-DPI displays being confused by complaints from those on older, low-DPI screens.

---

## [ICE is using facial-recognition technology to quickly arrest people](https://www.wsj.com/politics/policy/ice-facial-recognition-app-mobile-fortify-dfdd00bf)
**Score:** 217 | **Comments:** 187 | **ID:** 46495560

> **Article:** The Wall Street Journal article reports that U.S. Immigration and Customs Enforcement (ICE) has developed and deployed a sophisticated mobile facial recognition application. This tool allows agents in the field to quickly identify individuals by taking a photo and matching it against vast databases, including driver's license photos and other government records. The technology, part of a system internally called "FORTIFY," has significantly accelerated arrests by providing instant identification capabilities that were previously unavailable. The use of this technology has expanded rapidly, with ICE agents using it hundreds of times a day for immigration enforcement.
>
> **Discussion:** The Hacker News discussion is overwhelmingly critical of ICE's use of facial recognition, framing it as a dangerous expansion of state surveillance and a violation of civil liberties. A central theme is the concept of "scope creep," where powerful surveillance tools, initially justified for extreme cases like murder or terrorism, are gradually normalized and applied to less severe offenses, such as immigration violations. Commenters express concern that this technology, once established, will inevitably expand to other areas of life, including credit scoring, employment, and social services.

Many users draw parallels to surveillance practices in other countries, particularly China, noting the hypocrisy of condemning such technology abroad while adopting it domestically. The discussion also touches on the technical aspects, questioning the sources of biometric data (iris scans, gait recognition) and the potential for individuals to be tracked through multiple metrics. Several commenters place the current situation in a historical context, comparing modern biometric tracking to the racially motivated fingerprinting practices of the Civil Rights era. While one user argues that the legality of immigration is a matter of law, not opinion, the prevailing sentiment is a deep-seated fear that the trade-off between security and liberty is being made without adequate public debate and that the tools of a surveillance state are becoming permanent.

---

## [Show HN: Tailsnitch – A security auditor for Tailscale](https://github.com/Adversis/tailsnitch)
**Score:** 191 | **Comments:** 18 | **ID:** 46501137

> **Project:** Tailsnitch is an open-source security auditing tool for Tailscale networks (tailnets). It acts as a configuration linter, designed to scan Tailscale ACLs (Access Control Lists) to identify potential security misconfigurations and vulnerabilities. The tool is intended for security administrators managing growing networks, helping them validate complex ACL rules and ensure compliance. It can be integrated into CI/CD pipelines for automated checks.
>
> **Discussion:** The Hacker News community reacted positively to Tailsnitch, validating the need for such a tool as Tailscale networks grow in complexity. Several key themes emerged:

*   **Growing Pains of ACLs:** Multiple users expressed anxiety about managing large, complex ACL files ("HuJSON"), fearing that a single mistake could leave resources overly exposed. Tailsnitch is seen as a solution to this "low-level anxiety."
*   **Desire for Native Features:** There was a strong sentiment that Tailscale should offer this functionality natively. Users suggested a "scan now" button in the GUI and API access for automated compliance systems (like Vanta) to help with SOC2 and other audits.
*   **Security & Trust Concerns:** One user humorously but seriously pointed out the irony of a security tool requiring users to bypass macOS security (`xattr -rd com.apple.quarantine`) to run it. The consensus was that such tools should be run in a sandboxed VM to avoid adding risk.
*   **Scope & Feature Requests:** Discussion expanded beyond configuration linting. One user expressed a need for live SSH connection auditing (who is logging into what), a feature Tailscale currently lacks but which tools like Teleport offer. Others asked about support for Headscale (the open-source Tailscale control server).
*   **Best Practices:** A user pointed out that Tailscale already has built-in policy testing features, suggesting that Tailsnitch complements rather than replaces existing workflows.

---

## [Google broke my heart](https://perishablepress.com/google-broke-my-heart/)
**Score:** 173 | **Comments:** 72 | **ID:** 46505518

> **Article:** The article "Google broke my heart" by Jeff Starr details his frustrating and unsuccessful attempts to resolve a DMCA takedown request against his own website. A third party filed a DMCA notice against one of Starr's articles, causing it to be removed from Google's search results. When Starr tried to file a counter-notice to restore his content, he was met with a seemingly automated and circular process from Google. He was repeatedly asked to provide "proof of ownership" without any clear guidance on what documents or forms of evidence would be acceptable. Despite providing various forms of proof, including his books and website history, his requests were denied, leaving him unable to get his legitimate content re-indexed and feeling powerless against the impersonal corporate system.
>
> **Discussion:** The Hacker News discussion centered on the broken nature of the DMCA takedown process as handled by large platforms like Google. Many commenters expressed sympathy, sharing similar experiences and advising the author that direct engagement with Google's support is futile and that legal action is the only effective path forward. A key theme was the inadequacy of Google's verification process; while some argued that stricter verification is necessary to combat the surge in fraudulent DMCA claims (used as a "dislike button" or to suppress competition), most felt that Google's implementation is opaque and unhelpful. Commenters pointed out that the company fails to specify what constitutes acceptable proof of ownership, creating a catch-22 for creators. The discussion also touched on the impersonal nature of large corporations, with some suggesting that automation and cost-cutting have replaced human oversight, while others argued that creators should treat these companies as bureaucratic machines rather than "trusted allies." Practical, though often pessimistic, advice included hiring a lawyer and ensuring copyright registration to create a clear paper trail.

---

## [Decorative Cryptography](https://www.dlp.rip/decorative-cryptography)
**Score:** 158 | **Comments:** 50 | **ID:** 46496494

> **Article:** The article "Decorative Cryptography" argues that much of what is marketed as security is merely "security theater"—a decorative facade that offers a false sense of safety without addressing the real threat model. The author posits that security is only meaningful when the cost of an attack significantly exceeds the value of the protected asset. They explore this concept across several domains:

*   **Software:** Anti-tampering and license protection in software are often futile. A determined attacker with control over the execution environment (CPU, OS) can eventually bypass any software-based protection, as the hardware is a known quantity that can be emulated.
*   **Hardware:** Physical interposers can compromise communication between components, even if the data is encrypted. The author argues that an integrated root-of-trust within the CPU is necessary to solve this, as discrete components like TPMs over a bus are inherently insecure against such physical attacks.
*   **Cryptography:** The article critiques the misuse of cryptographic terms, noting that "end-to-end encryption" is meaningless if you don't trust the "ends" (e.g., the device or service provider). It also touches on how security features can be misused for lock-in or surveillance.

Ultimately, the piece is a call for realistic threat modeling, warning that unexplainable or overly complex security features are often just marketing.
>
> **Discussion:** The Hacker News discussion largely validates the article's premise, focusing on the practical difficulties and nuances of implementing real security. The conversation can be broken down into a few key themes:

A central point of agreement is the futility of software-only protection. One commenter shared a detailed, week-long account of bypassing layers of anti-tampering and obfuscation on an application, concluding that such measures are a war of attrition that ultimately favors the attacker. This echoes the article's sentiment that software is beholden to hardware, and that truly robust security requires hardware-level protection, like that found in specialized devices (e.g., YubiKeys).

The debate over hardware security was robust. While the article and some commenters advocate for an integrated root-of-trust (like an on-CPU TPM) to defeat physical interposers, others raised critical counterpoints. One user noted that this still requires trusting the CPU vendor, who could potentially build their own backdoors. Another commenter provided a more nuanced technical solution, explaining that a discrete TPM can still be secure if the CPU has a unique secret and derives keys for a secure channel with the TPM, thus thwarting any interposers.

The discussion also branched into the "security theater" of modern consumer electronics. A prominent thread debated Apple's on-device content scanning for iMessage. One commenter used this as a prime example of "decorative" E2EE, where the provider still has access. However, this claim was challenged and "debunked" by others, who cited evidence that the concerning process was a bug and has since been fixed, highlighting the difficulty in ascertaining the true threat model of closed-source systems.

Finally, the conversation touched on the usability and transparency of security features. Commenters expressed frustration that powerful tools like TPMs and Trusted Execution Environments (TEEs) are often poorly documented, forcing reliance on academic research to understand their true capabilities and limitations. The phrase "threat model gerrymandering" was highlighted as a fantastic summary of the practice of defining security problems in a way that conveniently aligns with a product's features rather than the user's actual risks.

---

## [Sega co-founder David Rosen has died](https://www.theguardian.com/games/2026/jan/05/sega-co-founder-david-rosen-dies)
**Score:** 157 | **Comments:** 22 | **ID:** 46502239

> **Article:** An article from The Guardian reports the death of David Rosen, the co-founder of Sega. The article details Rosen's background as an American GI who founded an arcade machine import business in Japan in 1954, which eventually evolved into the global video game giant Sega.
>
> **Discussion:** The Hacker News community reacted with a mix of surprise, nostalgia, and historical inquiry. Many users expressed shock to learn that Sega, a company they had always considered quintessentially Japanese, was actually founded by an American. This led to a discussion about the company's origins, with users noting that "Sega" is an abbreviation for "Service Games."

Tributes poured in from users who remembered Sega's significant cultural impact, particularly its "stellar" arcade output and influential home consoles from the 80s and 90s. The conversation also touched on Sega's history, with one user recommending the book "Console Wars," while another pointed out that Rosen himself had later disputed the book's narrative of internal conflict. A minor point of clarification was also made to distinguish David Rosen from a younger developer of the same name who co-founded Humble Bundle.

---

