# Hacker News Summary - 2026-01-23

## [Show HN: isometric.nyc – giant isometric pixel art map of NYC](https://cannoneyed.com/isometric-nyc/)
**Score:** 985 | **Comments:** 189 | **ID:** 46721802

> **Project:** The project is an interactive, giant isometric pixel art map of New York City, created using generative AI models. The creator, a Google employee, used tools like Cursor and Gemini-CLI to automate the generation of the massive amount of art required, a task they argue would be impractical for a single person otherwise. The project is presented with a detailed write-up that discusses the process, the challenges of AI-generated art, and the philosophical implications of "slop vs. art," concluding that when technical skill becomes a commodity, the differentiator becomes "love" and intent.
>
> **Discussion:** The discussion was multifaceted, with users expressing admiration for the technical achievement, curiosity about the creator's tools, and significant debate over the role of generative AI in art.

Many commenters praised the project's visual result and the depth of the creator's write-up. There was a strong interest in seeing similar maps for other major cities like San Francisco, Tokyo, and Paris. Technical issues were also noted, with several users reporting that the site was initially down due to rate limiting or CORS errors, though the creator later confirmed it was back online.

The core of the debate centered on the creator's use of AI. One prominent comment expressed concern about the "scale" of AI's impact, questioning the value of projects that couldn't exist without generative models and worrying about the diminished opportunities for human artists. This sentiment was challenged by another user with a counter-analogy about automation in other industries. The creator responded by acknowledging the dual-edged nature of the technology, expressing both excitement for its creative potential and sadness for the crafts it makes obsolete.

A key point of discussion was the creator's philosophy on "slop vs. art," which resonated with some commenters who found the framing insightful. However, others were more critical, questioning whether a project completed over a weekend could be considered art in the same way as a masterwork created over a lifetime. The conversation also touched on the creator's choice of development tools and included comparisons to other large-scale, human-made projects like a physical miniature model of NYC and a 1:1 scale recreation in Minecraft, highlighting the ongoing tension between human effort and AI-assisted creation.

---

## [GPTZero finds 100 new hallucinations in NeurIPS 2025 accepted papers](https://gptzero.me/news/neurips/)
**Score:** 857 | **Comments:** 452 | **ID:** 46720395

> **Article:** The article from GPTZero claims to have identified 100 instances of AI-generated "hallucinations" (fabricated data, references, and citations) within papers accepted to the prestigious NeurIPS 2025 AI conference. The findings highlight a critical failure in the academic peer-review system, where obviously fake references—such as citations to non-existent authors like "John Doe" and "Jane Smith"—were not caught by reviewers. This suggests that generative AI is being used to produce plausible-sounding but factually incorrect scientific content that is bypassing current quality control measures.
>
> **Discussion:** The Hacker News discussion expresses significant alarm and cynicism regarding the article's findings, focusing on the implications for scientific integrity and the systemic failures that allowed this to happen.

**Impact on Scientific Integrity**
Commenters view this as a harmful degradation of scientific research. There is a fear that LLMs make it easier to falsify data and produce "plausible" but fraudulent papers, exacerbating existing issues like p-hacking and data manipulation. Many argue that this behavior constitutes fraud and should be punished severely. The sentiment is that "making shit up isn't science," and there is a call for stricter enforcement and reproducibility standards, such as requiring code for all accepted papers.

**Systemic Failure of Peer Review**
A major theme is the breakdown of the peer-review process. Users debate whether reviewers are expected to verify every reference; while some argue that reviewers rely on trust and focus on methodology rather than citation accuracy, others are alarmed that obvious fabrications passed through. The consensus is that the academic system is overwhelmed. With massive submission volumes (e.g., NeurIPS receiving 20,000 papers) and a limited pool of qualified reviewers, the "unit economics" of thorough review have collapsed, creating a vacuum that AI slop is filling.

**Skepticism and Methodology**
There is significant skepticism toward the detection method itself. Users question the validity of AI detectors (like GPTZero) and request baseline comparisons to determine if hallucination rates have actually increased or if this is a pre-existing problem. There is concern that attributing these errors solely to AI is speculative without data on pre-2020 error rates, though the consensus acknowledges that LLMs likely amplify the issue.

**Cynicism Regarding Academic Culture**
Finally, the discussion reflects a deep cynicism about the culture of AI/ML research. Several commenters describe the field as prioritizing "optics, posturing, and connections" over substance. The acceptance of these flawed papers is seen as proof that peer review often prioritizes the *appearance* of innovation over rigorous verification, a problem that existed long before the advent of generative AI.

---

## [Bugs Apple Loves](https://www.bugsappleloves.com)
**Score:** 697 | **Comments:** 311 | **ID:** 46727587

> **Article:** The article "Bugs Apple Loves" is a website that catalogues a list of persistent, long-standing software bugs within Apple's ecosystem. It details specific issues across macOS, iOS, and other Apple services that have remained unfixed across multiple software releases, frustrating users. The site serves as a public repository of these recurring software quality problems.
>
> **Discussion:** The Hacker News discussion is largely positive, with commenters appreciating the "petty" and specific nature of the site's list. Many users shared their own personal experiences with similar bugs, validating the article's claims. Key discussion points revolve around the root causes of Apple's software quality issues.

A central theme is that the problem isn't a lack of engineering talent but a matter of corporate priorities. As one commenter noted, large tech companies have plenty of engineers, but they are often directed toward new features and "10X" projects rather than paying down technical debt. This is contrasted with Apple's past reputation for polish, exemplified by the "Snow Leopard" era, which was a bug-fix-only release. Commenters speculate that the current release cycle, which prioritizes new features annually, leaves no time for fixing old bugs.

Personal frustrations were a major part of the conversation. Users shared specific, recurring problems such as Spotlight search freezing, Bluetooth audio stuttering on macOS, issues with creating Apple developer accounts, and poor search functionality in the native Mail app. One user mentioned they keep the Gmail app on their iPhone specifically because Apple's native search is so unreliable. The discussion also touched on systemic issues like bugs in contact syncing and the difficulty of managing separate developer and personal Apple IDs.

---

## [In Europe, wind and solar overtake fossil fuels](https://e360.yale.edu/digest/europe-wind-solar-fossil-fuels)
**Score:** 647 | **Comments:** 658 | **ID:** 46719491

> **Article:** A Yale Environment 360 article reports a landmark achievement for Europe's energy sector: for the first time, wind and solar power combined have generated more electricity than all fossil fuels (coal, gas, and oil) in a single year. The article highlights that this transition has been driven by a decade of steady, compounding growth in renewable capacity rather than sudden, disruptive changes. It also notes the increasing role of battery storage in managing the intermittency of renewables, particularly in shifting solar power to meet evening peak demand.
>
> **Discussion:** The Hacker News discussion is multifaceted, with commenters analyzing the news from geopolitical, economic, and technical perspectives. A significant portion of the debate centers on the economic implications and cost of the energy transition. While some commenters argue that Europe's high electricity prices are making its industries less competitive compared to the US and China, others counter that this overlooks Europe's lack of domestic fossil fuel reserves and that energy independence provides long-term security benefits that are not easily quantified in monetary terms.

A recurring theme is the distinction between electricity generation and total energy consumption. Several users pointed out that the article's headline refers only to the electricity sector, which accounts for a fraction of total energy use, as transportation and heating still rely heavily on fossil fuels. However, others noted that the increasing adoption of electric vehicles (EVs) and heat pumps is beginning to shift these sectors onto the electrical grid, making this milestone a critical step toward broader decarbonization.

The discussion also delves into geopolitics, particularly China's relationship with Russia. One perspective suggests that China benefits from Russia's economic isolation, as it gives China exclusive access to Russia's vast natural resources. Another view posits that China has an incentive to keep the war in Ukraine ongoing, as a Russian victory would set a precedent for China's own territorial ambitions, such as with Taiwan.

Finally, commenters expressed optimism about the future of renewable energy, focusing on the rapidly falling costs of battery storage. There was a consensus that batteries are beginning to displace natural gas for managing evening peak demand, which has long been a key criticism of solar power. The potential for low-cost sodium-ion batteries, largely driven by Chinese manufacturing, was highlighted as a development that could accelerate this trend significantly.

---

## [Qwen3-TTS family is now open sourced: Voice design, clone, and generation](https://qwen.ai/blog?id=qwen3tts-0115)
**Score:** 626 | **Comments:** 195 | **ID:** 46719229

> **Article:** The article announces the open-sourcing of the Qwen3-TTS family, a suite of text-to-speech models from the Qwen team. The release includes capabilities for voice design, voice cloning, and speech generation. The official blog post provides audio samples demonstrating the quality and versatility of the models, which are now available on platforms like Hugging Face.
>
> **Discussion:** The Hacker News community reacted with a mix of technical curiosity, amazement at the quality, and significant ethical concerns.

The quality of the voice generation was a primary topic. Many commenters noted that the English audio samples had a distinct, recognizable style, with several users independently describing them as sounding like "anime voices" or similar to popular YouTubers. Despite this stylistic observation, the underlying technology was widely praised. One user, who had used AI TTS tools since 2018, was so impressed that they described getting "chills," believing the technology is now advanced enough for practical applications like restoring old, degraded audio from historical radio plays.

Voice cloning capabilities were a major point of discussion. Users found the results to be "uncanny good," with one tester reporting that their own cloned voice sounded exactly like them. This fidelity sparked significant ethical alarm. Commenters described the technology as "terrifying" and warned that we are "sleepwalking" into a reality where everything on a screen should be considered fake unless cryptographically proven otherwise. The potential for abuse, such as in scams, was explicitly mentioned, alongside more benign or positive use cases like creating podcasts or having a deceased relative read a bedtime story.

On the technical implementation front, users discussed running the models locally. Several commenters provided resources, including links to Hugging Face pages with code examples and a third-party command-line interface (CLI) tool. A key technical hurdle mentioned was the model's reliance on CUDA and FlashAttention, which are optimized for NVIDIA GPUs. This led to questions about running the models on other hardware, such as Macs (using Metal/MPS) or Windows machines, with users sharing workarounds like disabling FlashAttention.

Finally, the discussion briefly touched on related topics, including the quality of the Japanese language samples (which one user found a pronunciation error in) and a tangential, politically charged request for the Qwen team to release a model that outperforms a competitor's coding model.

---

## [I was banned from Claude for scaffolding a Claude.md file?](https://hugodaniel.com/posts/claude-code-banned-me/)
**Score:** 567 | **Comments:** 504 | **ID:** 46723384

> **Article:** The article details the author's experience of being banned from using Claude Code after attempting to scaffold a `Claude.md` file. The author describes setting up a process where multiple instances of Claude were interacting with and potentially updating each other's configuration files. When the account was disabled, Anthropic support provided a refund but no explanation or recourse. The author speculates that this circular prompt injection behavior triggered the safety heuristics, highlighting the "black box" nature of AI moderation where users are banned without specific reasons or a path to appeal.
>
> **Discussion:** The Hacker News discussion focused on the broader implications of opaque platform bans and the lack of support from AI companies. While some commenters were confused by the technical details of the author's setup—suggesting the circular prompt process might have triggered safety filters—others pointed out that the author was merely guessing at the cause. The conversation quickly shifted to the general unreliability of relying on third-party AI services. Several users shared their own negative experiences with Anthropic's support, noting that accounts are often disabled automatically with no recourse. A recurring theme was the contrast between the high cost of these services and the non-existent customer support, leading many to advocate for running local LLMs to maintain control and avoid sudden disruptions. There was also a critique of the article's writing style, with some finding it overly verbose, and cynical humor regarding the inevitability of being banned by "our new overlords."

---

## [Why does SSH send 100 packets per keystroke?](https://eieio.games/blog/ssh-sends-100-packets-per-keystroke/)
**Score:** 505 | **Comments:** 268 | **ID:** 46723990

> **Article:** The article investigates why SSH sends approximately 100 packets for every keystroke when used for a terminal-based game. The author, "eieio," initially suspected a bug but discovered the cause is SSH's keystroke timing obfuscation feature. This security mechanism intentionally adds "chaff" packets and delays to mask the timing between keystrokes, preventing attackers from inferring what a user is typing based on network traffic patterns. The author found that disabling this feature (via `IPQoS 0x10` in the config) drastically reduced packet count and CPU usage, making the high-performance game viable over SSH, albeit at the cost of security.
>
> **Discussion:** The Hacker News discussion centered on the technical details of SSH packet behavior, the security implications of the article's findings, and the unconventional choice to use SSH for gaming.

Key themes included:
*   **SSH Performance and Optimization:** Users debated the performance cost of SSH's packet handling. One user suggested using `TCP_CORK` or disabling `TCP_NODELAY` to reduce packet count, while another questioned if SSH's encryption overhead was the true bottleneck. The author responded that `TCP_NODELAY` introduced unacceptable latency for their use case.
*   **Security vs. Utility:** Several commenters strongly warned against disabling keystroke obfuscation, citing past vulnerabilities where typing patterns could be deduced from traffic. Others defended the author's choice, noting the trade-off was acceptable for their specific, non-sensitive gaming application. There was also a suggestion that the ability to disable this feature should be an upstream option in SSH libraries for situations where security is less critical.
*   **AI Language Patterns:** A side discussion emerged about the author's use of the phrase "smoking gun," with some commenters noting it's a common stylistic tic of AI assistants like Claude, which they found "nauseating."
*   **Choice of Protocol:** Some users questioned the decision to build a high-performance game over SSH, suggesting UDP-based solutions like QUIC or specialized libraries (e.g., GameNetworkingSockets) would be more appropriate. The author defended their choice by stating the "obtuseness is the point" and that the problems encountered are part of the fun.

---

## [Douglas Adams on the English–American cultural divide over "heroes"](https://shreevatsa.net/post/douglas-adams-cultural-divide/)
**Score:** 457 | **Comments:** 466 | **ID:** 46719222

> **Article:** The article, sourced from a personal blog, shares a quote from author Douglas Adams about the cultural difference between American and British storytelling. Adams posits that American heroes are defined by their competence, autonomy, and ability to overcome any obstacle, embodying an ideal of success. In contrast, British heroes are often defined by their failures, their perseverance in the face of insurmountable odds, and their ability to maintain their humanity despite not "winning" in a traditional sense. The article frames this as a fundamental difference in cultural values, where American stories celebrate mastery and victory, while British stories find humor and pathos in struggle and imperfection.
>
> **Discussion:** The Hacker News discussion largely validates and expands upon Douglas Adams' observation, with users exploring its manifestations across various media and cultures. The general consensus is that the distinction is real, though not absolute.

Many commenters used television and film as primary examples. The difference between the UK and US versions of "The Office" was cited as a perfect illustration: the UK version is bleak and centers on a delusional failure, while the US version is warmer and more optimistic, with its "loser" protagonist ultimately being more sympathetic and capable of growth. Similarly, users noted that modern American shows like "It's Always Sunny in Philadelphia" have found success with a British-style humor centered on terrible people facing comeuppance, suggesting a cultural convergence.

The discussion also branched into other media. Some pointed to the success of British-authored stories like "Harry Potter" and "Alex Rider" in the US, arguing they were popular precisely because their protagonists embodied the "American hero" archetype of autonomy and mastery. Others countered that the "reluctant hero" (like Frodo Baggins) is a classic British trope and that the success of these stories was more due to marketing and publishing power. The Peanuts character Charlie Brown was brought up as a quintessential American "lovable loser," though another commenter argued that Americans view him with contempt rather than sympathy, reinforcing the original thesis.

Finally, the conversation touched on broader cultural perspectives. Some users compared the American/British divide to the moral complexity found in Japanese animation by Hayao Miyazaki. Others cautioned against over-generalizing two diverse nations, but the prevailing sentiment was that Adams' insight remains a valuable lens for understanding cultural differences in storytelling.

---

## [Capital One to acquire Brex for $5.15B](https://www.reuters.com/legal/transactional/capital-one-buy-fintech-firm-brex-515-billion-deal-2026-01-22/)
**Score:** 309 | **Comments:** 240 | **ID:** 46725288

> **Article:** Capital One is acquiring the fintech company Brex for $5.15 billion. This represents a significant decrease from Brex's peak valuation of $12.3 billion in 2022, marking a roughly 58% discount. The deal is positioned as Capital One expanding its business customer portfolio by acquiring Brex's customer base and infrastructure.
>
> **Discussion:** The Hacker News discussion centers on the financial implications of the acquisition, particularly the disparity between Brex's peak valuation and the final sale price. Commenters widely view this as a "bad deal" for Brex's later investors and employees, attributing the lower valuation to the end of the Zero Interest Rate Policy (ZIRP) era which previously fueled fintech exuberance.

A significant portion of the debate focuses on the mechanics of startup exits, specifically liquidation preferences. One commenter provided a detailed breakdown explaining how these preferences ensure that late-stage investors recoup their capital before common stockholders (founders and employees) see any payout. Given that Brex raised hundreds of millions at its $12.3 billion peak, the consensus is that the $5.15 billion sale price likely leaves common stockholders with little to nothing, despite the company's reported revenue growth.

There is also speculation regarding Brex's internal trajectory, with some noting that competitors like Ramp have outperformed them, particularly in pivoting to AI. While the sale price is a steep discount from the peak, some users noted it is still a substantial multiple of Brex's reported revenue, suggesting a strategic win for Capital One. However, others argued that if Brex's growth was truly robust, investors would not have permitted a sale at this price.

---

## [It looks like the status/need-triage label was removed](https://github.com/google-gemini/gemini-cli/issues/16728)
**Score:** 289 | **Comments:** 75 | **ID:** 46721179

> **Article:** The article links to a GitHub issue in the `google-gemini/gemini-cli` repository where an automated bot, `gemini-cli`, appears to have entered an infinite loop. The bot repeatedly added and removed the `status/need-triage` label from the issue, generating thousands of comments and actions in a short period. The issue title, "It looks like the status/need-triage label was removed," ironically became the subject of the bot's repetitive behavior.
>
> **Discussion:** The Hacker News discussion focused on the absurdity of the situation and the technical implications of AI-driven automation failures. Commenters were largely amused and critical, describing the event as a "stupid" future where AI bots squabble with themselves. A key point of analysis was the scale of the error: one user noted that the bot performed roughly 4,600 actions, potentially generating tens of thousands of email notifications for repository watchers and incurring significant inference costs for whoever is paying for the Gemini API calls.

Technically, users debated whether this was a "classic CI bug" or a specific failure of the LLM's logic. While some argued that loop detection is a fundamental step in bot development, others noted that LLMs lack a sense of self or context, making them prone to such loops when interacting with their own outputs. Several commenters pointed out that this was a recurring issue in the repository, linking to similar previous incidents. The discussion also included analogies to other automation failures, such as a Salesforce loop that created infinite tickets, highlighting that while the technology (LLMs) is new, the logic errors are timeless.

---

## [Tree-sitter vs. Language Servers](https://lambdaland.org/posts/2026-01-21_tree-sitter_vs_lsp/)
**Score:** 241 | **Comments:** 63 | **ID:** 46719899

> **Article:** The article "Tree-sitter vs. Language Servers" compares two technologies used in modern code editors. Tree-sitter is a parser generator tool that creates fast, error-tolerant parsers, primarily used for tasks like syntax highlighting and structural code navigation. It operates on the syntax of the code (Concrete Syntax Tree). A Language Server, using the Language Server Protocol (LSP), is a separate process that provides rich, language-specific intelligence like autocompletion, type information, and "go to definition" by analyzing the code's semantics (meaning and context). The author concludes that while both can be used for syntax highlighting, Tree-sitter excels at speed and responsiveness for immediate visual feedback, whereas LSP provides deeper, semantically-aware features. The two are not mutually exclusive and can be used together for an optimal editor experience.
>
> **Discussion:** The Hacker News discussion largely validates the article's premise but adds significant depth, particularly regarding performance and the specific advantages of semantic features. A key theme is the complementary nature of the two technologies. Several commenters, including one of the article's authors, explain the ideal setup: using Tree-sitter for instant, high-speed lexical syntax highlighting and layering on LSP's semantic highlighting asynchronously for more context-aware coloring (e.g., distinguishing mutable vs. immutable variables in Rust).

A major point of debate arose around performance. One commenter argued that relying on an LSP for highlighting introduces latency and visual "shifting" due to network round-trips. This was directly countered by a lead architect of Microsoft's Roslyn (the C# compiler and LSP backend), who explained that high-performance language servers use incremental parsing and multi-threaded processing to achieve microsecond-level response times, ensuring the editor remains responsive. He clarified that LSPs can be designed to avoid the sluggishness described.

Other key discussion points included:
*   **Practical Use Cases:** Users praised Tree-sitter for its role in enabling advanced features like structured editing and refactoring tools in editors like Emacs. It's also highlighted as a valuable tool for developers creating their own programming languages.
*   **Ecosystem and Availability:** A minor thread addressed the availability of parsers, with commenters clarifying that a lack of a specific package in a Linux distribution doesn't mean a Tree-sitter parser doesn't exist for that language.
*   **Meta-Discussion on Content:** The conversation touched on the value of human-written articles versus AI-generated content, with several commenters appreciating the author's explicit note about not using AI, as it implies a higher degree of thought and distillation.
*   **Beginner Guidance:** A commenter new to the field asked for more foundational resources, prompting a detailed response that linked to the LSP specification, Tree-sitter documentation, and tutorials on parsing techniques, effectively supplementing the original article's high-level overview.

---

## [Proton Spam and the AI Consent Problem](https://dbushell.com/2026/01/22/proton-spam/)
**Score:** 226 | **Comments:** 126 | **ID:** 46729368

> **Article:** The article "Proton Spam and the AI Consent Problem" by David Bushell criticizes the tech industry, specifically Proton, for aggressively pushing AI features without user consent. Bushell recounts receiving an unsolicited marketing email from Proton promoting their new "Lumo" AI assistant, despite having no interest in AI and having previously opted out of marketing communications. He argues that this reflects a broader industry trend where "no" is not accepted, and AI is forced upon users in every corner of technology. He views this intrusive marketing as circumstantial evidence of an AI bubble, where top-down priorities to "pump those numbers" override user experience and respect for preferences.
>
> **Discussion:** The Hacker News discussion largely validates the article's premise, with users expressing widespread frustration over the lack of consent in tech marketing, particularly regarding AI. The conversation can be grouped into several key themes:

*   **Systemic Disregard for Consent:** Many commenters agree that the tech industry struggles to accept "no" for an answer. This is seen not just with AI but across the board, with services like LinkedIn being cited as notorious offenders for re-enabling marketing preferences. The discussion highlights a common pattern where consent is assumed by default or difficult to maintain, with one user summarizing the dynamic as a checkbox that asks you to "Ask me again in a few days."

*   **The AI Bubble and Poor Implementation:** A significant point of contention is the hasty and often poor implementation of AI features. Users noted that many AI products are functionally flawed, providing incorrect information (e.g., Amazon's Q&A) or generating inefficient code (e.g., Shopify's assistant). This leads to speculation that such rollouts are driven by a bubble mentality, where the appearance of innovation is prioritized over product quality and user value.

*   **Criticism of Proton's Actions:** Several users expressed disappointment with Proton, a company known for its privacy-first stance. Commenters found it hypocritical for a privacy-focused company to engage in intrusive marketing. This action has led some long-term users to consider switching providers, feeling that Proton's principles are eroding as it grows.

*   **Legal and Practical Solutions:** The discussion touched on potential solutions, primarily the need for stronger regulations and financial penalties for non-compliance, with the EU's GDPR cited as a positive example. On a practical level, some users shared personal strategies for tracking data misuse, such as using unique email addresses for each service.

*   **Nuance and Counterpoints:** Not all commenters saw the incident as a major issue. Some suggested it might be a simple marketing classification error (e.g., sending a business newsletter to a personal account) rather than a systemic disease. Others noted they hadn't received the email, suggesting the rollout may have been targeted or inconsistent.

---

## [I built a light that reacts to radio waves [video]](https://www.youtube.com/watch?v=moBCOEiqiPs)
**Score:** 208 | **Comments:** 52 | **ID:** 46728808

> **Article:** The article links to a YouTube video demonstrating a custom-built device that visualizes radio waves as light. The creator built a light that reacts in real-time to ambient radio frequency (RF) signals, such as Wi-Fi and Bluetooth, effectively making invisible electromagnetic fields visible. The project serves as an artistic and technical exploration of the "sea of radiation" we live in, translating RF intensity into light intensity.
>
> **Discussion:** The community response was overwhelmingly positive, with commenters describing the project as "fantastic," "mesmerizing," and "beautiful." The discussion focused on the project's potential to give humans a new sensory dimension for perceiving the invisible RF environment that surrounds us.

Technical and conceptual extensions were a major theme. Users debated the accuracy of visualizing RF data, with one asking about conversion tables for human visualization while another inquired about the specific hardware used. Several commenters expanded on the concept of "seeing" radio waves, discussing the possibility of creating 3D directional overlays that map specific frequencies to colors. One user noted that similar technology exists in other fields, such as military applications for detecting drone signals or artist installations using RF labs.

There was also a desire for more practical experimentation. One commenter suggested taking the device "war driving" to map RF signals in different environments (urban vs. rural), while another hoped to see "edge cases" like walking toward the device with a phone to trigger a reaction. The conversation concluded with a call to commercialize the idea, with one user suggesting a Kickstarter campaign to bring the technology to a wider audience.

---

## [Scaling PostgreSQL to power 800M ChatGPT users](https://openai.com/index/scaling-postgresql/)
**Score:** 204 | **Comments:** 95 | **ID:** 46725300

> **Article:** OpenAI published a blog post detailing how they scaled their PostgreSQL infrastructure to support over 800 million ChatGPT users. The architecture relies heavily on a combination of read replicas and sharding to handle the massive load. For read-heavy workloads, they scaled vertically and added nearly 50 read replicas to distribute the traffic, keeping replication lag near zero. For write-heavy workloads, which PostgreSQL's MVCC implementation handles less efficiently due to write amplification and table bloat, they migrated shardable writes to Azure CosmosDB. The post emphasizes that PostgreSQL remains the core of their architecture, but specific workloads were offloaded to specialized systems to maintain performance at scale.
>
> **Discussion:** The Hacker News discussion focused on the technical trade-offs of using PostgreSQL at extreme scale, the validity of OpenAI's architectural choices, and the nature of the blog post itself.

A central theme was the critique of PostgreSQL's write scalability. Commenters noted that OpenAI's solution—offloading write-heavy workloads to a NoSQL database like CosmosDB—is a common pattern. Several users suggested alternative database technologies that might handle high write throughput natively, such as TiDB (which uses LSM trees) or Rockset (an OpenAI acquisition built on RocksDB), questioning why these weren't used instead.

There was also a debate regarding PostgreSQL's native sharding capabilities. While the article implied sharding required moving away from Postgres, some commenters argued that Postgres supports sharding out-of-the-box via table partitioning and Foreign Data Wrappers (FDW), suggesting OpenAI's architecture might have been a choice rather than a necessity.

The tone of the discussion was mixed. Some users praised the engineering approach as mature and pragmatic, avoiding a full database migration in favor of optimizing the existing stack. Others found the blog post generic and lacking in novel technical depth, viewing the described architecture as a standard solution for high-scale systems rather than a unique innovation. Finally, there were minor tangents regarding the blog's authorship and links to Azure resources, as well as skepticism about OpenAI's financial stability.

---

## [CSS Optical Illusions](https://alvaromontoro.com/blog/68091/css-optical-illusions)
**Score:** 189 | **Comments:** 16 | **ID:** 46722570

> **Article:** The article "CSS Optical Illusions" by Alvaro Montoro showcases a collection of visual illusions created entirely with CSS. The post demonstrates how modern CSS techniques, such as gradients, shadows, and animations, can be used to replicate well-known perceptual phenomena like the Hermann grid, motion aftereffects, and color constancy illusions. The examples highlight the creative potential of CSS beyond simple layout and styling, turning the browser into a canvas for interactive visual experiments.
>
> **Discussion:** The Hacker News community reacted positively to the post, with commenters expressing admiration for the technical creativity and the visual impact of the illusions. Several users noted the practical applications, suggesting they could be integrated into UIs or even used to create novel CAPTCHAs.

The discussion also touched on the technical execution and user experience. One commenter pointed out that the CodePen previews appeared dark, which was clarified as a side effect of the preview embed rather than the illusions themselves. Another user shared a personal anecdote about unintentionally creating similar visual artifacts while building UIs.

A significant portion of the conversation focused on the specific illusions and their scientific context. Users identified the "appearing and disappearing dots" examples by name—McAnany's and Ninio's extinction illusions—and provided links to academic sources and their own recreations. This sparked a deeper dialogue about the nature of these illusions, with one user noting they could "force" themselves to see through most of them, while the induced gradients remained unshakeable. The conversation also branched out to related topics, such as the Ames window illusion and the Coca-Cola color illusion, further illustrating the community's interest in the intersection of CSS, perception, and neuroscience.

---

## [Macron says €300B in EU savings sent to the US every year will be invested in EU](https://old.reddit.com/r/europe/comments/1qjtvtl/macron_says_300_billion_in_european_savings_flown/)
**Score:** 177 | **Comments:** 198 | **ID:** 46722594

> **Article:** French President Emmanuel Macron, speaking at the World Economic Forum in Davos, claimed that €300 billion in European savings are sent to the United States annually. He announced a plan to reverse this flow by investing those savings within the European Union instead, aiming to create a more competitive European financial market and retain capital domestically.
>
> **Discussion:** The Hacker News discussion is largely skeptical of Macron's claims and the feasibility of his proposal. Commenters question the accuracy of the €300 billion figure, with some suggesting it is exaggerated or politically motivated rhetoric aimed at the Trump administration rather than a reflection of economic reality. Several users argue that capital naturally flows to where returns are highest, and unless the EU improves its investment climate and regulatory environment, simply stating an intention to invest locally will not change market behavior.

There is a broader sentiment that the EU struggles with economic growth and competitiveness compared to the US. Users point to structural issues, such as high taxes and a lack of attractive investment opportunities, as reasons for capital flight. The discussion also touches on the EU's difficulty in finalizing trade deals, like the Mercosur agreement, as evidence of bureaucratic inertia that might hinder Macron's ambitions.

On a secondary thread, users analyze European versus American savings rates, noting that Europeans save a significantly higher percentage of their income. This leads to a discussion about financial habits and the stark contrast in living standards and financial security between the two regions. While some commenters debate the specifics of these statistics, the general consensus is that the EU has a strong savings base but fails to channel it effectively into high-growth domestic investments.

---

## [Why medieval city-builder video games are historically inaccurate (2020)](https://www.leidenmedievalistsblog.nl/articles/why-medieval-city-builder-video-games-are-historically-inaccurate)
**Score:** 153 | **Comments:** 95 | **ID:** 46726857

> **Article:** The article argues that medieval city-builder video games are historically inaccurate because they prioritize gameplay and modern player expectations over historical reality. Key inaccuracies include the prevalence of winding, organic streets in games versus the straight, planned roads of actual medieval towns; the underrepresentation of the massive agricultural workforce needed to sustain a city (historically a ~29:1 farmer-to-non-farmer ratio); and the lack of color in clothing, which was actually common in the Middle Ages. The author notes that players often reject strict realism because it feels unnatural or "glitchy," preferring the romanticized, "wholesome" aesthetic of fantasy medievalism. The article highlights games like *Banished* and *Manor Lords* as steps toward more authentic simulations of subsistence living and village economies.
>
> **Discussion:** The discussion largely agrees with the article’s premise but focuses on the tension between historical accuracy and entertainment value. Several commenters argue that strict realism would make for tedious or frustrating gameplay, citing examples from other genres like realistic military shooters or farming simulators. There is a consensus that players prefer a "feeling" of the past rather than the data-driven reality, noting that straight roads or the misery of early medieval life would break immersion.

The conversation highlights specific games that attempt greater accuracy. *Banished* is praised for capturing the slow struggle of subsistence, though some lament that its developer abandoned it. *Manor Lords* is frequently mentioned as a modern title that successfully simulates medieval village life, including the economic significance of women’s work like gardening and clothing production. Commenters also point out that different genres have different expectations; while RTS games like *Age of Empires* prioritize combat balance, city builders like *Pharaoh* or *The Settlers* allow for more planning.

Finally, the discussion touches on broader misconceptions, such as the assumption that medieval clothing was drab and earth-toned, with one user noting that humans have always liked colors and that dyes were accessible. The thread concludes with the general sentiment that while historical accuracy is interesting, "fun" is the primary metric for game design.

---

## [Recent discoveries on the acquisition of the highest levels of human performance](https://www.science.org/doi/abs/10.1126/science.adt7790)
**Score:** 133 | **Comments:** 66 | **ID:** 46722853

> **Article:** The article, "The counterintuitive path to greatness," synthesizes research on elite performance across domains like chess, science, and sports. It argues that the highest levels of achievement are rarely predicted by early, specialized success. Instead, top performers often follow a "sampling period" in their youth, exploring diverse interests and accumulating broad experiences before eventually specializing. The research indicates that early high achievers and later top performers are often different individuals, with many world-class experts demonstrating only average or below-average performance in their early years. The path to expertise is characterized by delayed specialization and varied experience rather than intense, early focus on a single skill.
>
> **Discussion:** The Hacker News discussion reveals a mix of agreement, skepticism, and debate around the article's findings. Many commenters found the research relatable, sharing personal anecdotes or observations of peers who "fucked around" with wide interests in their youth and later achieved great things, while those who were grinding from a young age often burned out or became average.

A significant portion of the debate centered on the statistical interpretation of the findings. Several users, including MontyCarloHall and gwern, suggested the results could be explained by statistical artifacts like Berkson's Paradox or regression to the mean. They argued that selecting for individuals who are top performers in both youth and adulthood is a rare combination, and that observing a negative correlation between early specialization and later elite success might be a mathematical artifact of this selection process rather than a true causal relationship.

The discussion also branched into related themes:
*   **The Role of Generalism:** Commenters connected the findings to David Epstein's book "Range," emphasizing that cross-domain knowledge and analogical thinking are powerful tools for innovation and escaping "local maxima" in a specialized field.
*   **Systemic Barriers:** A counterpoint was raised that modern academic and professional systems are structured to reward early specialization, potentially filtering out generalists before they can demonstrate their later-stage potential.
*   **Nature vs. Nurture:** The debate touched on whether early high achievers are products of intense parental pressure that leads to burnout, versus individuals with innate but narrow abilities who eventually hit a ceiling.
*   **ADHD Misconceptions:** A side discussion emerged when one commenter linked the described path of intense focus to ADHD. This was strongly refuted by another user, who clarified that "hyperfocus" is not a diagnostic criterion for ADHD and that the medical condition is not correlated with high career performance, criticizing the popular "ADHD as a superpower" narrative.

---

## [White House Posts Digitally Altered Image of Woman Arrested After ICE Protest](https://www.theguardian.com/us-news/2026/jan/22/white-house-ice-protest-arrest-altered-image)
**Score:** 130 | **Comments:** 16 | **ID:** 46725268

> **Article:** The Guardian article reports that the White House digitally altered an image of a woman arrested during an ICE protest to make her appear more menacing. When questioned about the alteration, the White House did not deny it but instead posted a message on X (formerly Twitter) from Deputy Communications Director Kaelan Dorr. The response mocked those defending the arrestee, stated that "the memes will continue," and emphasized that law enforcement enforcement would proceed. The article highlights the use of generative AI by the government to manipulate images of individuals who have not been convicted of a crime.
>
> **Discussion:** The Hacker News discussion focuses on the implications of the government using digital manipulation and AI to shape public perception of legal matters. Commenters expressed alarm at the normalization of fabricating evidence and the erosion of due process norms. Key themes included the comparison of the current U.S. political climate to other nations experiencing democratic backsliding, such as South Africa during the "State Capture" years, with users noting that "bonkers" behavior often signals a breakdown in social order. There was also specific criticism regarding the White House's communication style, noting that the official response mimicked the aggressive, meme-heavy rhetoric often associated with Trump. While one user questioned the relevance of a church/state separation angle regarding the arrestee's target, the broader consensus was that the government's admission of creating "memes" of arrestees represents a dangerous disregard for judicial truth-finding processes.

---

## [Satya Nadella: "We need to find something useful for AI"](https://www.pcgamer.com/software/ai/microsoft-ceo-warns-that-we-must-do-something-useful-with-ai-or-theyll-lose-social-permission-to-burn-electricity-on-it/)
**Score:** 128 | **Comments:** 171 | **ID:** 46718485

> **Article:** The article reports on Microsoft CEO Satya Nadella's warning that the tech industry must quickly find genuinely useful applications for AI. He argues that without demonstrating clear utility, society will withdraw the "social permission" for AI's massive energy consumption. The piece frames this as a shift in narrative from previous tech industry stances that blamed users for not adopting the technology correctly, suggesting a growing concern that the current AI boom may not be delivering enough practical value to justify its environmental and economic costs.
>
> **Discussion:** The Hacker News discussion is overwhelmingly skeptical of Nadella's statement, viewing it as a defensive maneuver rather than a genuine call for utility. Commenters largely perceive the AI industry as being in a "bubble" driven by investor hype rather than real-world demand.

A dominant theme is the critique of the "you're using it wrong" narrative. Several users argue that Nadella's plea for usefulness is merely a rephrasing of the old trope that blames end-users for failing to realize the technology's potential. They contend that if a product requires a "prophetic vision" to see its value, it likely lacks practical application for the average person.

Many commenters question the premise that the public is the primary stakeholder. They suggest Nadella's real audience is investors, and his urgency is a tactic to maintain funding and secure scarce resources like electricity for data centers, rather than a reflection of genuine public dissatisfaction.

The discussion highlights a perceived lack of tangible benefits for ordinary people. Users report that their non-technical friends and family treat AI as a "toy" for entertainment or simple queries, not as a productivity booster. There's a strong consensus that for the vast majority of the population, AI has not delivered significant productivity gains, and the "slop" it generates is becoming a noticeable problem.

Finally, there is deep skepticism about AI's actual impact on cognitive ability and productivity. One user cites a study suggesting AI may hinder thinking, while another argues that even time saved on tasks like web searches is negligible in the grand scheme of one's workday. The overall sentiment is that the industry is struggling to find a killer app and is burning through resources in the process.

---

