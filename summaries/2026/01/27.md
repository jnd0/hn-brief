# Hacker News Summary - 2026-01-27

## [TikTok users can't upload anti-ICE videos. The company blames tech issues](https://www.cnn.com/2026/01/26/tech/tiktok-ice-censorship-glitch-cec)
**Score:** 768 | **Comments:** 519 | **ID:** 46779809

> **Article:** CNN reports that TikTok users are experiencing difficulties uploading videos critical of ICE (Immigration and Customs Enforcement), with the company attributing the issue to technical glitches. The timing is notable as it follows the recent forced sale of TikTok's US operations to American owners amid national security concerns about Chinese control. The article highlights growing suspicions about whether these "technical issues" represent deliberate censorship, particularly given the platform's history of content moderation controversies and its new ownership structure under US-based entities with reported ties to the Trump administration.
>
> **Discussion:** The HN discussion rapidly expanded beyond the specific TikTok-ICE issue into broader debates about platform censorship, geopolitical information warfare, and the nature of social media control. Several distinct threads emerged:

**Censorship and Platform Control**
Commenters debated whether the forced TikTok sale was genuinely about national security or about controlling information flows to American users. One user argued the sale was designed to hide information from Americans that others worldwide can access, while another countered that TikTok in China itself operates under heavy censorship—suggesting the US was merely replicating Chinese-style control. A detailed anecdote described how TikTok's algorithm in South America surfaces anti-US content while filtering out criticism of China, illustrating how platform algorithms can serve as subtle propaganda tools.

**Partisan Dynamics and Hypocrisy**
The discussion revealed deep skepticism about "both sides" framing of censorship debates. One commenter dismissed right-wing complaints about deplatforming as bad-faith rhetoric, noting that conservatives now control major platforms including Twitter/X, Facebook, and traditional media outlets. Others pushed back, with centrist-leaning users describing how they've faced labeling and brigading for moderate positions. The Epstein case was raised as another example of apparent suppression, with reports that TikTok was blocking the name in direct messages—suggesting rapid implementation of content controls under new ownership.

**Technical vs. Intentional Moderation**
Users disagreed about whether observed changes were deliberate policy shifts or normal algorithmic behavior. One person described their TikTok feed being completely reset, while others attributed similar experiences to "exploration injection"—a known engagement technique. This tension between user experience and platform explanations remained unresolved.

**Structural Solutions and Skepticism**
Proposed remedies included federated networks with open-source algorithms, though this drew substantial pushback. Critics noted federation's historical failure to achieve mainstream adoption, user indifference to technical architecture, and the unsolved challenges of moderation at scale. Alternative suggestions like P2P systems with IP-based reputation scoring were proposed but not deeply explored.

**Broader Political Concerns**
Several comments connected the TikTok situation to democratic erosion, with references to armed IRS agents as political tools, the Minnesota protests, and what one user termed "Orbanisation" of media—referencing Hungary's concentrated state media control. The underlying anxiety concerned how quickly platform infrastructure could be repurposed for political ends, with one commenter noting that China's existing censorship tech merely needed new keyword lists to serve US interests.

---

## [ChatGPT Containers can now run bash, pip/npm install packages and download files](https://simonwillison.net/2026/Jan/26/chatgpt-containers/)
**Score:** 418 | **Comments:** 297 | **ID:** 46770221

> **Article:** Simon Willison reports on a significant new capability in ChatGPT: containers that can run bash commands, install packages via pip/npm, and download files. This appears to be a sandboxed Linux environment (likely Ubuntu-based) with 4GB RAM and surprisingly, 56 CPU cores (though these are shared with other containers). The feature enables LLMs to execute arbitrary code, compile software, and interact with external resources—effectively giving ChatGPT a full computational environment rather than just code interpretation.
>
> **Discussion:** The discussion quickly diverged into several contentious debates about AI's role in software development. A provocative claim by behnamoh—that "most code is written by LLMs" and that this might end the era of dynamic languages like Python in favor of compiled languages like Go—sparked immediate pushback. jacquesm and koe123 challenged this as a "massive assumption," with koe123 noting that AI-generated code remains rare in production environments they respect, and dismissing "vibecoding in prod" as irresponsible. Others pushed back on the pushback: cheeze, identifying as FAANG, estimated 20%+ of their team's code now comes from LLMs, particularly for boilerplate and tests, while fooker insisted that by lines of code, AI output already dominates "by an order of magnitude" even if much is "janky garbage."

A parallel debate emerged about whether LLMs even need traditional package managers anymore. jmacd suggested dependencies may become obsolete when LLMs can simply generate needed functionality directly, though PunchyHamster countered that downloading deps saves tokens versus "hallucinating more code." kristianp expressed frustration with JavaScript/TypeScript tooling bloat, wishing more AI-coded projects would use Go instead.

The practical utility of containerized agents generated more concrete discussion. dangoodmanUT described compounding benefits: agents can resolve weird edge cases like detecting JPEGs mislabeled as PNGs by reading magic bytes—capabilities that lpcvoid dismissed as trivial for humans using standard Unix tools, prompting darknoon to admit even 15-year veterans couldn't do this from memory on the CLI. Lerc clarified that the point isn't replacing human capability but removing blockers: agents can now handle file identification and preprocessing, letting LLMs focus on what they're good at.

Elsewhere, xnx and simonw explored technical limits—whisper transcription might work with creative file handling, though the 4GB RAM constraint matters. Imustaskforhelp raised economic questions about OpenAI subsidizing 56-core containers, while tintor noted these are shared resources. The thread also contained flagged off-topic comments drawing parallels between AI development and historical authoritarianism, plus a New Yorker cartoon reference about AI's tendency to confidently "help" with problems it just caused.

---

## [Kimi Released Kimi K2.5, Open-Source Visual SOTA-Agentic Model](https://www.kimi.com/blog/kimi-k2-5.html)
**Score:** 394 | **Comments:** 181 | **ID:** 46775961

> **Article:** Moonshot AI released Kimi K2.5, an open-source 1 trillion parameter Mixture of Experts (MoE) model with 32 billion active parameters. It claims state-of-the-art performance on visual and agentic tasks, including the ability to self-direct "agent swarms" of up to 100 sub-agents executing parallel workflows across 1,500 tool calls. The model is released under a modified MIT license requiring large commercial users (100M+ MAU or $20M+ monthly revenue) to prominently display "Kimi K2.5" in their product interface.
>
> **Discussion:** The Hacker News discussion centered on three main themes: hardware requirements, licensing strategy, and the broader implications of massive open-source model releases.

On hardware, commenters debated whether this model could realistically run locally. While some noted the 1T parameter count would require ~500GB of VRAM even at INT4 quantization, others pointed to the MoE architecture—only 32B parameters are active per token—as making local deployment feasible. Proposed setups ranged from $20,000 dual Mac Studio configurations (using MLX and Thunderbolt 5) to $500,000+ server racks with 16× H100 GPUs. Skeptics countered that Mac Studios lack sufficient bandwidth for expert routing and that practical use would require high-end enterprise hardware.

The license modification drew criticism as effectively a "marketing tax" on large users—dheera questioned why they didn't simply charge $1 million instead of requiring brand placement. Others saw it as a clever growth strategy reminiscent of Google's early search widgets.

Several commenters connected this release to the "DeepSeek moment" from a year prior, marveling at how Chinese AI companies continue releasing frontier models for free. Explanations ranged from state-sponsored efforts to nullify US technological advantages, to loss-leading strategies that force competitors to innovate while keeping Chinese models relevant through usage. The business model remained puzzling to many, with motoboi asking directly: "What is the business here?"

The agent swarm capability generated technical interest, with jumploops highlighting that Kimi uses reinforcement learning not just on tool calling but on agent orchestration itself. Others sought clarification on whether this was intrinsic to the model or implemented in surrounding infrastructure.

A minority skeptical voice (PlatoIsADisease) dismissed the DeepSeek/Kimi open-source strategy as primarily marketing, claiming no one actually uses these models in practice and alleging astroturfed social media promotion. This was countered by references to the active LocalLLaMA community and the practical utility of quantized models for many use cases.

---

## [Celebrities say they are being censored by TikTok after speaking out against ICE](https://www.pride.com/culture/celebrities/tiktok-censoring-megan-stalter-and-finneas)
**Score:** 276 | **Comments:** 203 | **ID:** 46777652

> **Article:** The article from Pride.com reports that celebrities including Megan Stalter and Finneas (Billie Eilish's brother) have alleged that TikTok is censoring their content after they spoke out against ICE (Immigration and Customs Enforcement). The celebrities claim their videos about immigration enforcement and related protests have seen reduced reach or visibility on the platform. This comes after TikTok's forced sale to a US consortium led by Oracle's Larry Ellison, with close ties to the Trump administration, following legislation requiring ByteDance to divest from the app due to national security concerns.
>
> **Discussion:** The Hacker News discussion quickly became polarized around whether the topic itself belonged on the site, with early comments noting the post had been flagged by users. Several participants argued this was precisely the kind of story HN should cover—a major platform changing hands under government pressure, with observable effects on functionality—while others suggested political topics attract reflexive flagging from those who don't want to see criticism of the current US administration. One user characterized this as a "proto-fascist contingent" suppressing regime-critical discussion, while another lamented the difficulty of finding spaces for genuine cross-ideological conversation, blaming HN's voting mechanisms for creating echo chambers.

Beyond the meta-discussion about HN moderation culture, participants debated what might actually be happening with TikTok's algorithm. Some suggested algorithmic opacity makes any claim of censorship hard to verify against simple engagement variance, though others countered that the political context—new ownership with documented administration ties, following a controversial Supreme Court decision allowing the forced sale—makes intentional throttling plausible. A few commenters distinguished between capitalism as an economic system and as a system of power where capital overrides other concerns, with one noting this arrangement resembles mercantilism more than free markets given the government-orchestrated nature of the ownership transfer.

The practical discussion yielded little consensus. One user with video platform experience emphasized how difficult it is to distinguish intentional suppression from algorithmic unpredictability, while others pointed to broader patterns of platform manipulation and the administration's documented willingness to mischaracterize protest activity. Several commenters expressed exhaustion with US political discourse on tech forums, wishing for more constructive angles like technical workarounds for censorship rather than rehashed partisan argument. The thread concluded with unresolved tension between those seeing urgent democratic stakes in platform control and those skeptical of anecdotal claims lacking transparent data.

---

## [Cloudflare claimed they implemented Matrix on Cloudflare workers. They didn't](https://tech.lgbt/@JadedBlueEyes/115967791152135761)
**Score:** 254 | **Comments:** 109 | **ID:** 46781516

> **Article:** A Mastodon post claims that Cloudflare's announcement of implementing Matrix on Cloudflare Workers was misleading. The linked GitHub repository (nkuntz1934/matrix-workers) appears to be a minimal, possibly AI-generated proof-of-concept rather than a functional implementation. Evidence cited includes: only two commits in the repository's history, removal of TODO comments in a subsequent commit (described as "cleaning up code comments"), misaligned ASCII diagrams in the README, and claims of "production-grade" quality despite apparent incompleteness. The author is identified as a Senior Engineering TPM at Cloudflare.
>
> **Discussion:** The HN discussion centers on what commenters view as a pattern of misleading technical marketing, particularly around AI-assisted development. Several key threads emerge:

**Evidence of low-quality implementation** — Multiple commenters highlight repository red flags: just two commits total, a commit that removed TODO comments while claiming to merely "clean up code comments," and obvious formatting errors like misaligned ASCII art. One commenter notes the original HN submission was made from a throwaway account, suggesting the author knew the claims were questionable.

**Comparisons to other incidents** — Commenters connect this to recent similar cases, particularly Cloudflare's OAuth library for Workers (which claimed thorough human review by security experts but later had a CVE) and the debunked Cursor "web browser built from scratch with GPT-5.2" story. The pattern identified is companies presenting incomplete AI-generated demos as fully-engineered solutions.

**Debate over accountability** — A significant subthread involves palata cautioning that the author is a real person facing harassment, while others (particularly wswope) argue that deliberately misrepresenting work as "production-grade" constitutes fraud worthy of public criticism. Parliament32 draws a parallel to engineering licensing, suggesting public shaming substitutes for professional consequences in software.

**Broader industry concerns** — Multiple commenters express frustration with what embedding-shape calls "the slop" — major companies publishing unreviewed hype content. Augusteo notes this erodes the traditional purpose of technical blogs (demonstrating expertise and building trust), while dfajgljsldkjag warns it makes explaining real engineering effort harder. Stackskipton suggests Cloudflare's motivation is vendor lock-in through their Workers platform.

**Defense of the concept** — A minority view, represented by palata and armchairhacker, acknowledges the underlying technical idea (running Matrix on workerd) as interesting regardless of the post's quality issues.

---

## [I made my own Git](https://tonystr.net/blog/git_immitation)
**Score:** 249 | **Comments:** 102 | **ID:** 46778341

> **Article:** TonyStr wrote a detailed walkthrough of building a simplified Git clone from scratch in Rust, named "tvc" (Tony's Version Control). The article explains core Git concepts by implementing them: content-addressable storage using SHA-256 hashes, blob/tree/commit object types, compression with zstd, and basic commands like init, add, commit, and log. The author deliberately made simplifying choices—using YAML for human-readable object formats, skipping the index/staging area, and omitting merges—to keep the project approachable while still capturing Git's fundamental design. The writeup serves as both a working minimal VCS and an educational tool for understanding how Git actually works under the hood.
>
> **Discussion:** The discussion touched on several interconnected themes around the project, LLMs, and version control systems more broadly.

A recurring thread concerned AI training and code scraping. The author noted surprising pre-publication clone activity on their repo, suggesting automated scraping of new public GitHub repositories for LLM training datasets. This sparked speculation about "poisoning" LLMs with circular self-referencing content, and prompted the author to clarify they used LLMs only for coding advice and research suggestions, not for generating the article itself.

Technical implementation choices generated substantial debate. Several commenters suggested SQLite as a storage backend to eliminate parsing complexity, which led to discussion of Fossil SCM—an established project using SQLite. However, others noted that Fossil's actual format remains plaintext for longevity, and that SQLite's relational model may create impedance mismatches with Git's DAG-heavy operations. The author acknowledged performance limitations in their implementation, particularly around recomputing file hashes, and discussed Git's optimization techniques like hash-prefix directory sharding.

Merge strategies became another tangent, with one commenter praising Git's recursive merge and rerere for remembering conflict resolutions, while another advocated for Pijul's approach of treating conflicts as first-class repository objects.

The conversation also surfaced educational resources for understanding Git internals, with multiple recommendations including "Git from the Bottom Up," "The Git Parable," "Write yourself a Git," and "ugit"—suggesting this genre of "build your own Git" projects resonates strongly with developers seeking deeper understanding.

Finally, practical security considerations emerged around hash algorithm choice, with discussion of SHA-1's known vulnerabilities versus SHA-256, and the theoretical risks of hash collision attacks even in content-addressed systems not designed for cryptographic security.

---

## [A list of fun destinations for telnet](https://telnet.org/htm/places.htm)
**Score:** 248 | **Comments:** 78 | **ID:** 46775135

> **Article:** A curated list of active telnet destinations accessible via telnet.org, featuring ASCII art animations (including the famous Star Wars Episode IV), MUDs (Multi-User Dungeons), bulletin boards, weather services, and other text-based internet services. The site serves as a nostalgic directory preserving a pre-web era of internet communication.
>
> **Discussion:** The HN thread sparked warm nostalgia for the "literary age of the internet"—a time of pure text interfaces without JavaScript frameworks, cookie banners, or loading spinners. Many commenters traced their technical origins to telnet: augusteo discovered the internet's "secret passage" through the Star Wars ASCII animation, while nomel learned email protocols by hand-crafting POP3 commands, eventually building their first email client and web server. The educational value of telnet as a teaching tool resonated throughout, with several sharing how manual protocol interaction demystified internet fundamentals.

MUDs (Multi-User Dungeons) emerged as a dominant theme, with sixtyj confirming 35-year-old games still run, and others confessing how MUDding both taught them programming and nearly derailed their education. The social dimension of early text-based communities surfaced through memories of EW-too talkers and late-night global conversations.

Practical matters interspersed the reminiscing: the famous towel.blinkenlights.nl Star Wars server was briefly mourned as dead before being confirmed alive (with IPv6 enhancements), though some reported connectivity issues. Modern friction appeared as tgv noted telnet isn't installed by default anymore, requiring deliberate installation with awareness of its unencrypted nature—Bender explained this is intentional security policy, though enterprise appliances keep telnet relevant.

The thread touched on contemporary relevance through phplovesong's speculation about retreating to text-based systems as an escape from AI slop and advertising, with Bender suggesting Gopher and IRC as alternatives. VMG injected necessary caution about ANSI escape sequence vulnerabilities, prompting debate about relative risks versus modern web attack surfaces. The discussion closed with playful absurdity—jayknight's "fingering" reference (to the finger protocol) and xeyownt's struggles with a deliberately obtuse CAPTCHA requiring "Venera Venera Venera."

---

## [Dithering – Part 2: The Ordered Dithering](https://visualrambling.space/dithering-part-2/)
**Score:** 239 | **Comments:** 33 | **ID:** 46770274

> **Article:** This is Part 2 of a visual, interactive series on dithering algorithms, focusing specifically on ordered dithering (also known as Bayer dithering or threshold maps). The article explains how ordered dithering works by using a fixed matrix pattern to determine whether pixels should be on or off, rather than propagating errors to neighboring pixels like error diffusion methods. The piece features interactive demonstrations allowing readers to explore different matrix sizes and thresholds, comparing the characteristic "cross-hatch" or patterned look of ordered dithering against other approaches. The presentation is notable for its polished, bite-sized, scroll-driven interactive format that teaches through direct manipulation.
>
> **Discussion:** The HN discussion reveals a vibrant community of practitioners working with dithering across diverse domains. Several commenters shared their own projects: PMunch wrote about dithering for an e-paper laptop, comparing error diffusion, Bayer, blue noise, and novel approaches; ggambetta used ordered dithering in a ZX Spectrum raytracer constrained by 8×8 pixel blocks; mblode built a blue noise generator library in Rust and TypeScript; and AndrewStephens created a web component for Atkinson dithering.

Technical comparisons dominated much of the conversation. Storystarling and robinsonb5 discussed how physical ink bleed and dot gain in print media favor ordered dithering over error diffusion, drawing parallels to traditional litho printing's clustered dot screens and even 1-bit audio output techniques. Quag and leguminous debated quasi-random sequences versus blue noise for modern GPU applications, with leguminous noting challenges in adding temporal components to quasi-random approaches for animation.

The presentation format itself sparked disagreement: ginko found the bite-sized pacing "disrespectful," while haritha-j and Sunspark defended it as effective for education and a legitimate portfolio demonstration of research, coding, and design skills. Others simply praised the craftsmanship, with treavorpasan offering effusive comparison to Michelangelo, and austinthetaco asking how such polished 3D transitional sites are built beyond basic Three.js knowledge.

Historical and cultural notes emerged too: a_shovel and spicyjpeg identified Bayer dithering as signature to Flipnote Studio animations and original PlayStation graphics respectively, with the latter explaining how Sony's 4×4 hardcoded matrix and composite video blur created a now-replicated aesthetic. The PS1's curious inclusion of a 24-bit DAC despite GPU limitations—used mainly for title screens and MJPEG playback—drew particular interest.

---

## [When AI 'builds a browser,' check the repo before believing the hype](https://www.theregister.com/2026/01/26/cursor_opinion/)
**Score:** 228 | **Comments:** 137 | **ID:** 46769965

> **Article:** The Register article critiques a recent demonstration by Cursor (an AI coding tool) where they claimed to have "built a browser" using GPT-5.2 running autonomously for a week, generating 3+ million lines of code. The author urges skepticism, noting that examination of the repository reveals the project heavily depends on Servo (Mozilla's browser engine) rather than being a from-scratch implementation as implied. The piece highlights how AI-generated code demos can be misleading when not scrutinized, with the actual output being described by a Servo maintainer as "a uniquely bad design that could never support anything resembling a real-world web engine."
>
> **Discussion:** The HN discussion centers on whether Cursor's demonstration represents genuine technical progress or misleading hype, with participants debating where the line falls between impressive demo and deceptive marketing.

Several commenters expressed frustration with how the project was framed. A Servo maintainer's harsh assessment—that the code wasn't merely wiring dependencies nor copied from existing implementations, but rather "uniquely bad" design—was widely cited. Critics argued this should have been positioned as an experiment rather than a success story, warning that such presentations fuel executive misconceptions that AI can replace expensive engineers.

Simon Willison defended Cursor's claims as not particularly extreme, noting their blog post used careful language ("it kind of works") and that CEO tweets naturally lack nuance. He pushed back against accusations of "access journalism" in his own coverage, arguing the actual statements were modest compared to typical tech hype.

The "lines of code" metric drew particular scorn, with multiple participants noting this regressed software engineering wisdom—Dijkstra's 1988 observation that LOC should be counted as "spent" not "produced" was quoted. One commenter introduced the blacksmithing concept of "anvil shaped objects"—things that look functional but fail under real use—as an apt metaphor for AI-generated demos.

A significant tension emerged between those seeing genuine capability in autonomous agents running for a week without collapsing, and skeptics noting the output didn't actually compile and ultimately just called `servo.render()`. The cost claim of "10-20 trillion tokens" was disputed as architecturally implausible given sequential agent loops.

Underlying much discussion was anxiety about real-world consequences: management believing hype, firing staff, and creating job market damage regardless of eventual AI capabilities. Some argued the demo showed promising trajectory; others that present misrepresentation for future potential is itself harmful. The debate ultimately reflected broader HN divisions between AI optimism and skepticism, with both sides accusing the other of missing the point.

---

## [AI code and software craft](https://alexwennerberg.com/blog/2026-01-25-slop.html)
**Score:** 224 | **Comments:** 139 | **ID:** 46769188

> **Article:** The linked article (dated January 25, 2026) by Alex Wennerberg discusses "AI code and software craft," examining the tension between AI-generated code and traditional software craftsmanship. The piece appears to frame this as a debate between those who value human agency, quality, and apprenticeship in coding versus those prioritizing efficiency and speed through AI tools.
>
> **Discussion:** The HN discussion centers on whether AI coding tools represent a genuine parallel to historical technological displacement or something fundamentally different. **Herring** opens by framing this as a classic Luddite vs. Industrialist debate, suggesting human roles will simply shift again—perhaps toward roles emphasizing human connection, since people biologically prefer interacting with other humans for important matters.

**convolvatron** strongly disputes this historical parallel, arguing that unlike weaving or CNC machining—where technology removed tedious labor without reducing quality—current AI-generated code and creative work is "objectively much worse." This quality gap distinguishes past industrialization from today's AI transition. **lkey** intervenes with historical correction, noting actual Luddites were skilled operators protesting labor practice violations, not anti-technology zealots, drawing pointed parallels to modern worker suppression.

The practical experience of AI coding divides commenters sharply. **will__ness** compares coding agents to chainsaws versus handsaws—same result, different method—suggesting quality code emerges through orchestrated planning, implementation, and review. **acedTrex** counters that in reality, LLM code is "orders of magnitude worse" and they're "drowning in mountains of LLM slop patches." **nielsbot** notes the overhead: often it's faster to just write code oneself. **will__ness** pushes back, claiming modern agents excel at pattern replication when properly directed.

Historical analogies proliferate with conflicting interpretations. **ako** advocates embracing AI for better software craft, comparing it to luthiers using CAD/CNC—tools don't preclude craftsmanship. **Cthulhu_** critiques this: CNC machines are deterministically programmed, while LLMs are probabilistic and require "wait & hope." The "software engineering is programming over time" observation—that we haven't seen LLM code age yet—resurfaces as crucial unknown.

**fauigerzigerk** argues AI could enable *more* great software by freeing effort from basic features, while **slotrans** darkly predicts AI will "annihilate the last vestiges of craftsmanship forever." **0xbadcafebee** offers counter-examples: power tools didn't kill hand-tool woodworking, looms didn't end hand-knitting, blacksmithing persists. Craftsmanship becomes niche, not extinct.

**hackyhacky** accepts this but finds it grim: blacksmithing was once "a viable career path," now niche eccentricity. Coding faces the same "purgatory." **Ronsenshi** asks who advances AI or builds novel things if hand-coding knowledge disappears. **trollbridge** questions whether software can ever be "well-defined, repeatable processes" like machining, suggesting prompting resembles high-level programming more than true automation.

The debate ultimately crystallizes around whether AI coding tools are *augmentative* (skilled operators using better tools) or *substitutive* (replacing understanding with probabilistic generation), and whether "craftsmanship" migrates to prompt engineering and AI orchestration or simply evaporates.

---

## [Google Books removed all search functions for any books with previews](https://old.reddit.com/r/google/comments/1qn1hk1/google_has_seemingly_entirely_removed_search/)
**Score:** 213 | **Comments:** 71 | **ID:** 46769201

> **Article:** Google Books has seemingly removed or severely degraded search functionality for books with previews, particularly affecting modern copyrighted works. Users report that around January 21, 2025, search quality dropped dramatically—from returning relevant contemporary results to surfacing only decades-old editions. The core issue appears to be that cross-book full-text search no longer works effectively for preview-enabled books, though in-book search remains partially functional if you already know which book to examine. Public domain works appear unaffected.
>
> **Discussion:** The discussion reveals deep frustration with Google's apparent retreat from its mission to make information universally accessible, with several competing theories emerging about why this happened. The most prominent explanation involves AI training concerns—commenters speculate that publishers, wary of their content being scraped to train language models, pressured Google to limit searchable access, or that Google itself is restricting access to preserve valuable training data for its own AI products. This theory gained traction through comparisons to other Google moves, like blocking ChatGPT from summarizing YouTube videos while allowing Gemini to do so.

A significant thread explored the tension between traditional "information wants to be free" ideals and newer anxieties about AI training data. One commenter pointedly asked whether people's views had genuinely shifted or if different voices were now dominating the conversation. Responses largely held the line on information freedom, with one detailed rebuttal arguing that copyright remains a regressive force and that the real solution involves compensating creators through collective licensing rather than restrictive DRM.

Alternative technical explanations also surfaced: some suggested Google switched from traditional inverted index search to cheaper vector search (though others disputed this as actually more expensive), while another noted that search could be exploited to reconstruct entire books through carefully crafted queries. The most legally grounded explanation came from a commenter emphasizing that preview functionality exists through publisher contracts, making this likely a publisher-demanded change under threat of complete preview removal.

The conversation naturally turned to alternatives, with Library Genesis, Anna's Archive, Sci-Hub, and Z-Library recommended as replacements—though acknowledged as lacking full-text search across their collections. Several participants advocated for building local indexes instead. Underlying much of the discussion was exasperation with copyright term lengths extending nearly a century, which one commenter illustrated with the striking example of Metropolis (1927) being public domain in the US but copyrighted in Germany until 2047.

A minority voice defended the change as potentially beneficial, noting that newer book editions are generally preferable to old ones. However, this was countered by others pointing out that Google Books serves researchers and searchers more than casual readers, for whom edition recency matters less. The thread concluded with some practical verification that limited search still exists within individual books, though the cross-book discovery functionality that made Google Books valuable for research appears deeply compromised.

---

## [Y Combinator website no longer lists Canada as a country it invests in](https://betakit.com/y-combinator-website-no-longer-lists-canada-as-a-country-it-invests-in/)
**Score:** 212 | **Comments:** 128 | **ID:** 46773242

> **Article:** BetaKit reported that Y Combinator removed Canada from its website's list of countries where it invests, sparking concern about reduced Canadian startup access to the prominent accelerator. The list previously included US, Cayman Islands, Singapore, and Canada; it now only lists US, Cayman Islands, and Singapore. However, commenters clarified this reflects a structural change rather than exclusion: YC still funds Canadian founders but now requires them to incorporate in Delaware, Singapore, or Cayman Islands—aligning Canada with standard YC policy for international founders rather than maintaining its previous exception allowing Canadian-domiciled entities.
>
> **Discussion:** The discussion revealed this change is primarily about corporate governance simplification rather than rejecting Canadian founders. Multiple commenters emphasized that YC continues to fund Canadian entrepreneurs but now requires the standard "flipped" structure used for hundreds of companies from Europe, Asia, Africa, and Latin America—where founders maintain Canadian operations under a US/Cayman/Singapore parent entity. This removes legal complexity for YC and future investors, as managing foreign corporate stakes creates significant operational overhead.

The thread surfaced deeper tensions about Canada's startup ecosystem. Some commenters highlighted genuine Canadian advantages: government incentives (like Calgary programs covering half of ML engineer payrolls), lower total compensation costs, universal healthcare reducing benefits burdens, and deep talent pools in Toronto, Vancouver, and Calgary. Others countered with structural critiques—greenavocado's lengthy indictment of regulatory capture, protected oligopolies in banking/telecom/aviation, and crushing red tape that favors incumbents. Several founders confirmed these difficulties, with steve_adams_86 calling BC's environment "practically punitive" with "abysmal" risk-reward ratios for small business.

A revealing subthread explored why Canadian institutional capital doesn't fill the gap. Alephnerd, identifying as VC/PE, noted that Canadian pension funds like OTPP and CDPQ overwhelmingly invest outside Canada seeking double-digit returns, leaving domestic startups undercapitalized. This creates a self-reinforcing cycle: scarce local VC pushes founders toward US structures and markets, which then drains talent and headquarters from Canada.

The political dimension drew mixed attention. One commenter speculated about political motivation, while others dismissed this. More substantively, throwup238 and compiledkoala detailed why Delaware, Cayman, and Singapore dominate: predictable chancery courts, streamlined corporate law, and reduced governance deadlock risks. Canadian common law's recent rulings apparently created specific investor concerns about governance deadlocks that VCs would struggle to evaluate.

The discussion concluded with unresolved tension between Canada's livability advantages and economic realities. One US senior developer expressed serious interest in relocating for citizenship path, citing political concerns about America's trajectory—prompting rebuttal that Canada remains fundamentally vulnerable to US dynamics. Others acknowledged that while lifestyle differences matter, income gaps and ecosystem limitations continue pushing ambitious Canadian founders southward.

---

## [Russia using Interpol's wanted list to target critics abroad, leak reveals](https://www.bbc.com/news/articles/c20gg729y1yo)
**Score:** 197 | **Comments:** 65 | **ID:** 46776454

> **Article:** A BBC investigation based on leaked documents reveals Russia has been systematically abusing Interpol's wanted list to target political opponents and business figures abroad. The case of Vladimir Pestrikov, a former mining executive who fled Russia in 2022, illustrates the pattern: he was placed on an Interpol red notice after leaving Russia with 250 million rubles, but Interpol's own review body later canceled the request, ruling his case was "predominantly political." The leak shows Russia has filed thousands of requests, with hundreds flagged as potentially politically motivated by Interpol's internal compliance body. The practice extends beyond Russia—Turkey and other authoritarian states similarly exploit the system to harass dissidents overseas.
>
> **Discussion:** The HN discussion reveals significant skepticism about the BBC's framing of Pestrikov as a "government critic," with commenters like **kgeist** and **braincat31415** digging into his background as a 1990s-era oligarch who privatized state assets through shady deals, faced tax evasion charges, and allegedly threatened people with a rifle. They suggest he fits the profile of a criminal using political persecution as a shield against extradition rather than a genuine dissident—an interpretation seemingly supported by **pydry**, who notes the BBC's choice to call him a "businessman" rather than "oligarch" hints at political motivations behind his removal from the list.

Yet **embedding-shape** counters this by citing Interpol's own documents, which found Russia's evidence "generic and formulaic" with "inadequate explanation of the alleged crime," leading the Commission for the Control of Interpol's Files to rule his case predominantly political. This tension—between individual guilt and systemic abuse—runs through the thread.

The discussion broadens to established precedents, with **s_dev** and others citing Bill Browder and the Magnitsky case as clearer examples of Russian Interpol abuse. **BeetleB** argues Turkey "perfected this technique," sharing links about Americans targeted for criticizing Erdogan on social media. An Austrian case mentioned by **preisschild** illustrates the operational reality: an official allegedly looked up journalists' addresses for FSB agents who later broke into an apartment.

Technical aspects of Interpol's system draw attention too—**JasonADrury** notes the grim irony that one can pay $500 in cryptocurrency to check red notice status on criminal forums, while **strken** clarifies that most notices aren't publicly visible, being restricted to law enforcement. **bilekas** initially missed how Pestrikov discovered his status (he proactively contacted Interpol after fleeing to France), highlighting how opaque the system remains for most targets.

The thread touches on broader patterns of state coercion: **dvfjsdhgfv** describes how Russian business culture systematically entraps entrepreneurs in technical violations to ensure compliance, while **rdtsc** warns of "exchange" arrests of Western citizens. Comparisons to Brazil, India, and the Netherlands emerge, though with varying evidentiary support. A minor derailment occurs over **preisschild's** use of "ruzzians"—defended by **jimbohn** as distinguishing pro-war Russians from the general population, criticized by **SanjayMehta** as childish, and flagged by **cpursley** as symptomatic of how political posts devolve into "Reddit-style" hostility.

Underlying much of the discussion is **lazide's** observation that in Russia's judiciary, "every case is a political case"—complicating any clean distinction between criminal and political persecution, and suggesting that even guilty individuals may be targeted selectively based on regime priorities rather than rule of law.

---

## [I let ChatGPT analyze a decade of my Apple Watch data, then I called my doctor](https://www.msn.com/en-us/news/technology/i-let-chatgpt-analyze-a-decade-of-my-apple-watch-data-then-i-called-my-doctor/ar-AA1UZxip)
**Score:** 194 | **Comments:** 192 | **ID:** 46772495

> **Article:** A journalist fed ten years of Apple Watch health data into ChatGPT and asked for a "heart longevity grade." The AI gave him an F, citing poor cardiovascular fitness based largely on his VO2 max estimate. Alarmed, he consulted his doctor, who found him healthy with normal blood pressure, cholesterol, and no concerns. The author discovered ChatGPT's assessments were inconsistent—repeated queries yielded grades ranging from F to B. The piece highlights problems with AI health analysis: unreliable wearable data (Apple's VO2 max estimates can run 13% low), AI's tendency to present confident but flawed conclusions, and the mismatch between fitness metrics and medical health assessments.
>
> **Discussion:** The discussion reveals deep tension between AI's potential utility and its real dangers in health contexts. Several commenters shared starkly contrasting experiences: one user's wife received a terrifying but false diagnosis from ChatGPT that caused "borderline traumatic" stress before a specialist corrected it, while another credited ChatGPT with persistently identifying their gallbladder issue after medical professionals dismissed it, ultimately leading to correct surgery for a chronically inflamed organ.

A central debate emerged about responsibility and framing. Some argued that LLMs are simply probabilistic text generators without "conviction," and that prominent disclaimers about AI fallibility represent a reasonable middle ground between access and safety. Others pushed back forcefully, noting that OpenAI's own marketing materials portray ChatGPT as a trustworthy source for serious health decisions—featuring ads where users describe relying on it for "facts" alongside doctor expertise, or using it to analyze medical scans and estimate calories from meal photos. The actual product interface, they noted, says "ask anything" with no cautionary fine print.

Commenters also dissected the deeper methodological problems. Health metrics like VO2 max, BMI, and HRV are population-level measures that break down at individual levels, and doctors evaluate health differently than fitness enthusiasts—often finding patients "fine" by medical standards while wearables flag them as deficient. Several noted that modern medicine struggles with "subtlety and small problems," leaving a gap that fitness nerds and AI tools fill poorly with guesswork and anecdote.

The Apple Watch itself came under scrutiny, with some defending its validated algorithms while others emphasized that estimates remain imperfect inputs for high-stakes AI analysis. The core frustration, expressed throughout: AI companies are shipping tools that present confident, authoritative-sounding health assessments based on noisy data, leaving ordinary users to navigate when to trust them and when to panic.

---

## [People who know the formula for WD-40](https://www.wsj.com/business/the-secret-society-of-people-who-know-the-formula-for-wd-40-e9c0ff54)
**Score:** 187 | **Comments:** 284 | **ID:** 46771599

> **Article:** A Wall Street Journal article profiles the "secret society" of WD-40 executives who know the complete formula for the iconic water-displacement spray. Access requires special keys, NDAs, passage through a bank vault, and typically an executive title. The company maintains elaborate secrecy protocols around its 70-year-old formulation, treating it as a closely guarded trade secret despite the product's ubiquity.
>
> **Discussion:** The HN discussion largely debunks the mystique around WD-40's secrecy. Several commenters note that the ingredients are actually listed on safety data sheets—though one user clarifies that SDS documents don't reveal exact percentages, processing methods, or all ingredients, so reverse-engineering wouldn't be trivial. The consensus emerges that the secrecy is primarily marketing theater rather than genuine competitive protection.

On product performance, opinions vary but trend skeptical. One user cites testing showing WD-40 underperforms against dedicated penetrating oils, and notes it's a poor long-term lubricant because it's designed to evaporate, which concentrates grime. Others defend its practical value: farmers appreciate that it's skin-safe and cheap for field repairs where you just need to unstick something quickly with minimal tools. Several users emphasize that WD-40 works best for its actual intended purpose—water displacement and light rust removal—rather than as the universal panacea marketing suggests.

The manufacturing secrecy puzzle generates interesting speculation. Users wonder how production works if no single person knows the complete formula, with comparisons to Coca-Cola's compartmentalized supply pipeline where unlabeled ingredients from separate sources are combined. This mirrors techniques reportedly used in defense software engineering where developers don't know their code's ultimate application.

Comparisons to Coca-Cola recur throughout—another famously "secret" formula that food chemists can actually reverse-engineer quite closely. One user mentions OpenCola and notes that only the coca leaf extract (not caffeine, as another corrects) truly distinguishes Coke, requiring a special license. A YouTuber's recent attempt to replicate Coke with HPLC draws both interest and criticism for clickbait titling.

Alternative products and approaches surface: used motor oil for cheap lubrication, Super Lube (PTFE-based, food-safe), silicone oil, lithium grease, and graphite for specific applications. One user mentions canola oil for basic tasks. The thread closes with practical use cases—machining aluminum, removing old grease—and the observation that despite its limitations, WD-40 endures through brand recognition and adequate performance across many situations, akin to Python's "decent all-rounder" philosophy.

---

## [Xfwl4 – The Roadmap for a Xfce Wayland Compositor](https://alexxcons.github.io/blogpost_15.html)
**Score:** 184 | **Comments:** 112 | **ID:** 46779645

> **Article:** The linked article outlines the roadmap for "xfwl4," a new Wayland compositor for the XFCE desktop environment. This represents XFCE's planned migration from its traditional X11 window manager (xfwm4) to native Wayland support. The project is being implemented in Rust using the Smithay library (the same abstraction layer used by System76's Cosmic desktop) rather than the more established C-based wlroots. The roadmap emphasizes maintaining behavioral parity with xfwm4 while adapting to Wayland's fundamentally different architecture—most notably, the compositor-centric design where the compositor alone controls window positioning, focus, and rendering, unlike X11's client-server model where applications had more direct control over these aspects.
>
> **Discussion:** The HN discussion reveals a community grappling with the tensions between technological progress and preservation of valued characteristics. The core debate centers on whether Wayland represents genuine advancement or misallocated effort, with participants dividing roughly into three camps: enthusiastic adopters, skeptical traditionalists, and pragmatic transitionists.

The Wayland skepticism voiced by ok123456 resonates with a significant minority who experience Wayland as "regression" due to missing features, protocol fragmentation, and lengthy standardization processes. This perspective sees Wayland as over-engineered—"a past compromise" after 16 years of development—lacking the elegant simplicity of protocols like SMTP. The critique touches on genuine pain points: applications losing capabilities they had under X11, compositor-specific workarounds creating ecosystem fragmentation, and the "it's just a protocol" mantra feeling hollow when essential functionality remains unstandardized.

Defenders, led by jchw's detailed technical rebuttal, counter that Wayland's radical design choices—eliminating global coordinate space, making compositors sole arbiters of focus and positioning—enable cleaner solutions to long-standing problems: proper DPI scaling, HDR, multi-monitor docking, and application isolation. The argument emphasizes that Wayland's "design-by-committee" slowness, while frustrating, produces robust protocols and that XWayland preserves backward compatibility for legacy applications. jchw's firsthand experience with KDE suggests the transition pain may be front-loaded, with substantial quality-of-life improvements following.

Coldpie's intervention as a longtime XFCE user challenges stereotyping of the userbase as reactionary technophobes, reframing XFCE values as "things just work and not change for no good reason"—a pragmatism compatible with Wayland given its growing momentum. This provokes cf100clunk's valid objection to the dismissive "diehards" framing, which risks alienating legitimate concerns.

Fiveplus raises substantive architectural questions about behavioral fidelity: XFCE's focus-stealing prevention relied on X11's client-powerful model where applications *could* grab focus, requiring complex heuristics to restrain them. Wayland's compositor-authority model inverts this—clients merely request, never seize—making "the same behavior" a design puzzle rather than direct port. More critically for XFCE's identity, Fiveplus probes whether mandatory compositing in Wayland sacrifices the "snappy" responsiveness of uncomposited X11 on low-end hardware, a performance class PunchyHamster bluntly declares irretrievable.

BearOso's technical assessment highlights implementation risks: Rust's binding ecosystem immaturity versus C's, Smithay's beta status versus wlroots' maturity, and the broader tragedy of duplicated effort across five+ independent Wayland implementations each solving the same "deceptively complex" graphics problems. Yet there's acknowledgment that Smithay's active development by Cosmic's team provides collaborative benefits, and respect for avoiding yet another ground-up compositor.

The Rust language choice itself draws mixed reactions. jchw notes its crash-prevention benefits for compositors—particularly valuable given Wayland's "more severe" crash consequences—while anticipating traditionalist skepticism. Pjmlp appreciates the honest justification over "because I like it," yet flags the "language island" costs: build complexity, ecosystem integration friction, and contributor accessibility constraints. The tension between Rust's safety guarantees and C's systems integration dominance remains unresolved.

Throughout, an undercurrent concerns XFCE's essential character: lightweight, functional, unpretentious. Whether Wayland+Rust preserves or erodes this identity depends on which attributes one prioritizes—binary size, memory footprint, responsiveness, stability, or maintenance burden. The roadmap's success will be measured not by architectural purity but by whether longtime users recognize their desktop in the transition.

---

## [Amazon to Shut Down All Amazon Go and Amazon Fresh Stores](https://www.wsj.com/business/retail/amazon-to-shut-down-all-amazon-go-and-amazon-fresh-stores-0301dfb7)
**Score:** 163 | **Comments:** 115 | **ID:** 46781707

> **Article:** The Wall Street Journal reports that Amazon plans to shut down all Amazon Go cashierless convenience stores and Amazon Fresh grocery stores. This represents a major retreat from Amazon's physical retail expansion, which included the high-tech "Just Walk Out" technology and attempts to compete in the grocery sector beyond its Whole Foods acquisition.
>
> **Discussion:** Hacker News commenters offered extensive firsthand accounts of why Amazon's grocery experiment failed, alongside broader analysis of retail dynamics and labor issues.

**Operational Failures and Poor Experience**
Multiple shoppers described Amazon Fresh as fundamentally mismanaged. Bluecobra's detailed critique highlighted absentee management, employees prioritizing online orders over in-store customers, expired products on shelves, and bizarre return policies—while noting they only tolerated these problems because of artificially low prices like $0.85 pasta boxes. Justonceokay, located near a major Seattle Amazon Fresh, described how the store replaced a beloved local grocer with a "shit grocery store" that stocked popular items but lacked essential cooking ingredients, employed surveillance-heavy European consultants with clipboards, and treated cashier positions as "sub-human" roles for non-union workers.

**Pricing Strategy and Market Impact**
Randycupertino observed what appeared to be deliberate loss-leading: avocados at $0.25, carrots half Safeway's price, and carts costing $21 versus $36 at Walmart for identical items. This sparked concerns about predatory pricing to eliminate local competition. Several commenters confirmed Amazon's destructive footprint—g947o and bumblehean described how Amazon bought out and demolished local businesses for Fresh locations that never opened, leaving vacant buildings in town centers.

**Technology vs. Reality**
The discussion revealed Amazon's "Just Walk Out" technology as largely illusory. Mjr00 cited Wikipedia documentation that approximately 1,000 Indian workers manually reviewed transactions, with computer vision failing to deliver on its promises. Giraffe_lady contextualized rising outsourcing costs within India's massive labor movement—250 million people striking in a single day—suggesting economic pressures made the human-backstopped automation unsustainable.

**Urban Retail Geography**
A notable exchange examined supermarket viability in dense cities. PaulHoule praised Wegmans for showing NYC "what a real supermarket looks like," but hshdhdhj4444 countered that this misunderstood urban shopping patterns: specialized local shops within walking distance and subway-adjacent buying-as-needed reduce demand for massive supermarkets. Wegmans' Brooklyn Navy Yard location specifically targets car-dependent areas, not walkable neighborhoods. Ghc pushed back that family life changes these calculations, with urban supermarkets offering time-saving consolidation.

**Union Presence and Labor**
SirFatty's skeptical question about unionized grocery workers prompted informative responses: buildsjets detailed UFCW3000 representation across Seattle-area stores (Safeway, Fred Meyer, QFC, PCC, Uwajimaya), while The-Bus noted UFCW's 800,000 grocery workers nationally. This underscored Amazon's deliberate non-union strategy as a competitive wedge.

**Broader Pattern**
Nebula8804 connected this to Amazon's HQ2 "dog and pony show," where cities competed for a headquarters Amazon seemingly predetermined for Bezos's convenience—praising AOC's resistance as ultimately vindicated when the selected location underperformed. The consensus suggested Amazon's physical retail expansion reflected tech-industry hubris: applying optimization logic to fundamentally human, relationship-driven businesses, substituting surveillance and automation for the accumulated knowledge and community presence that makes grocery retail function.

---

## [The age of Pump and Dump software](https://tautvilas.medium.com/software-pump-and-dump-c8a9a73d313b)
**Score:** 148 | **Comments:** 55 | **ID:** 46780065

> **Article:** The article "The Age of Pump and Dump Software" describes a new phenomenon where crypto promoters collaborate with tech-savvy individuals to rapidly produce AI-generated software projects. The pattern involves: crypto promoters seeking technical credibility approaching developers who use AI coding tools (like Cursor) to "vibe-code" projects quickly, generating hype through social media and influencer networks, launching associated crypto tokens, then abandoning the project after extracting value. The author distinguishes this from legitimate AI-assisted experimentation, noting the telltale signs include rushed development, excessive marketing, crypto token integration, and eventual abandonment. Examples mentioned include various AI coding agents and tools that have emerged with suspicious patterns of promotion and rapid obsolescence.
>
> **Discussion:** The discussion reveals deep skepticism about AI-generated software projects, particularly those with crypto connections, while also defending genuine experimentation in the emerging AI coding space.

Several commenters investigated specific projects mentioned, with _pdp_ conducting forensic analysis on "clawdbot" and its rebrand to "molt.bot," uncovering spam backlink networks, Reddit astroturfing, critical security vulnerabilities, and suspicious commit patterns—concluding it was part of a coordinated scam. Esskay countered that the rebrand was legitimate and forced by an Anthropic takedown notice, though _pdp_ maintained the new domain showed identical red flags.

Steve Yegge's "Gas Town" project became a flashpoint for debate. Uehreka defended it as a genuine learning experience in coding agent orchestration, having personally experimented with it without financial loss. Leynos similarly framed such projects as legitimate public experimentation with immature technology, comparing the supervisor-worker architecture to approaches Anysphere independently developed. Critics like noosphr dismissed Gas Town as incoherent "bullshit" comparable to Time Cube, while storystarling questioned whether the economics of AI agent architectures could compete with human developers—though simoncion noted Yegge explicitly targeted users unconcerned with cost.

Broader themes emerged about the nature of software development itself. Justonceokay's speculative comment about future historians viewing this era as either unprecedented complexity or a "Wild West" period resonated, with bee_rider suggesting future AIs might use today's overcomplicated code as training data for understanding human software excess. Pjc50 referenced Vernor Vinge's "software archaeologist" profession as prescient.

The crypto-software nexus drew particular ire. Avaer, claiming insider experience with billion-dollar scams, argued this represents an acceleration of age-old patterns through unregulated crypto gambling, AI hype incomprehensible to average users, and social media amplification. Matt Levine's observation about founders receiving money for zero equity was cited, with askl noting that VC-backed startups themselves represent a form of "pump and dump" where "successful exit" substitutes for "dump."

Defenders of AI experimentation pushed back against blanket cynicism. Polishdude20 shared a concrete example of using Cursor to rapidly prototype a computer vision project for ski lift analysis, with isk517 noting rapid prototyping as generative AI's most viable use case. Skybrian cautioned against excessive cynicism destroying room for sincere vision, while mentalgear identified a parallel phenomenon: AI-hype "developer influencers" running life-coach pyramid schemes repackaged for tech.

The discussion ultimately circled a fundamental tension: distinguishing legitimate exploration of transformative but immature technology from exploitative hype cycles, when both can look superficially similar and often coexist in the same projects.

---

## [iPhone 5s Gets New Software Update 13 Years After Launch](https://www.macrumors.com/2026/01/26/iphone-5s-software-update/)
**Score:** 145 | **Comments:** 65 | **ID:** 46774108

> **Article:** Apple pushed a software update to the iPhone 5s, a device launched in September 2013, nearly 13 years after its release. The update (build 12.6.03) replaces an expired certificate that was preventing the device from functioning properly. While not a feature update, it ensures basic functionality continues for the small number of users still operating these legacy devices. The iPhone 5s was notable as the first iPhone with Touch ID and a 64-bit processor.
>
> **Discussion:** The HN discussion largely centered on Apple's exceptional legacy support compared to industry norms, though participants debated the significance and motivations behind this particular update.

Several commenters praised Apple's commitment to old devices. mrandish, while no fan of Apple's "walled garden," called this "a case of Apple doing a good thing and deserves praise." Others contrasted this with Android's update situation—ChrisMarshallNY noted acquaintances with 18-month-old flagship Android phones unable to get latest releases, recommending Pixel phones for better OS support. However, thebruce87m pushed back on Pixel recommendations, citing unresolved emergency call issues.

A key clarification came from tokyobreakfast and augusteo: this was merely a certificate replacement, not substantive software updates. Still, augusteo found it notable since "lots of old devices become paperweights because of expired certs." This practical perspective was echoed by rdsubhas, who speculated the update was cost-driven—legal and support costs from bricked phones likely exceeded the expense of pushing a certificate.

The conversation branched into broader reflections on update culture. pjmlp observed that outside tech communities, "regular people hardly care about updates," describing how many in their circle buy ~€300 Android devices and use them until they break, often turning updates off entirely. jen20 countered pjmlp's historical claim about pre-smartphone updates, noting PalmOS Treo devices received software updates without developer tools.

Some participants shared personal experiences with aging devices. bartread ran a 5S from 2013 to 2020; fouc mentioned having an unused battery replacement kit. brewmarche and nake89 discussed still using original and second-gen iPhone SE models, with practical caveats about app compatibility. Others like al_borland expressed nostalgia for smaller phone form factors.

The discussion also touched on alternative support models. bastawhiz suggested Apple should offer jailbreaks for decade-old phones, arguing the risks are minimal for such a small user base. fsflover advocated for open-sourcing obsolete products to enable community support. Comparisons emerged with Sony's continued PS3 Blu-ray DRM updates and AMD's mixed record on GPU support—jauntywundrkind noting that while AMD drops official support quickly, their open architecture enables community driver improvements for 14-year-old GCN cards.

---

## [India and EU announce landmark trade deal](https://www.bbc.com/news/articles/crrnee01r9jo)
**Score:** 142 | **Comments:** 117 | **ID:** 46778821

> **Article:** The BBC reports on a landmark trade agreement announced between India and the European Union, described as the most significant trade deal for either party in years. The agreement aims to reduce tariffs on goods and improve market access for services. Negotiations had been ongoing for nearly a decade. The deal comes amid shifting global trade dynamics, with both sides seeking to diversify economic partnerships beyond traditional allies.
>
> **Discussion:** The Hacker News discussion quickly fragmented into several distinct threads, with immigration becoming the dominant—if contested—theme despite the article's focus on trade.

**Immigration as a Wedge Issue**
A Canadian commenter (breitling) raised concerns about immigration being "lop-sided" in Canada's context, prompting a sharp rebuttal from diego_moita, who challenged the framing by comparing labor mobility to other trade commodities. This exchange sparked broader debate about whether people should be treated as tradable goods like oil or groceries. User alephnerd repeatedly flagged what they saw as coordinated attempts to derail discussion toward immigration, noting that Reuters' reporting on draft terms did not mention mobility provisions—suggesting the BBC article may have overstated this aspect. However, RhysabOweyn countered by citing Indian government communications that explicitly touted a "mobility framework" for students and workers.

**US-EU Talent Competition**
The prospect of EU-India labor mobility drew comparisons to the US H1B system. User augusteo, drawing on personal experience with US immigration, argued that reducing friction for skilled workers benefits everyone by expanding options for talented individuals. Espressosaurus suggested the US may be ceding this competition through "deliberate actions," potentially enabling a "European flowering"—though fooker pushed back forcefully on salary competitiveness, claiming US tech workers still earn 3-4× European equivalents even accounting for healthcare and other benefits. Lawn countered that factoring in education and childcare costs narrows this gap.

**Geopolitical Context**
Several comments situated the deal within broader strategic realignments. Alephnerd highlighted China's sustained diplomatic opposition to the agreement, linking it to Beijing's efforts to prevent India's economic integration with Western blocs. They also noted significant security dimensions: Indian defense technology vendors gaining access to EU modernization funds, and Franco-Indian cooperation against Chinese disinformation operations targeting their defense industries. Deafpolygon framed the deal as economic stabilization against "Trump's tariff shenanigans."

**Media and Access**
A secondary thread emerged around BBC's US-only paywall, with profsummergig lamenting the broadcaster's diminished global accessibility. Dewey defended the policy as reasonable given non-UK visitors don't contribute via taxes, while Symbiote argued for maintaining free access as soft power projection—something Britain appears to have abandoned.

**Political Irony**
PlatoIsADisease observed ideological realignments, noting leftists celebrating free trade and gun ownership in this timeline, while predicting partisan loyalty would override principle when administrations change. Seanmcdirmid clarified that moderate support for free trade has been consistent across Democratic administrations, with Republican opposition being the more recent development.

---

