# Hacker News Summary - 2026-01-21

## [Danish pension fund divesting US Treasuries](https://www.reuters.com/business/danish-pension-fund-divest-its-us-treasuries-2026-01-20/)
**Score:** 686 | **Comments:** 687 | **ID:** 46692594

> **Article:** A Danish pension fund, AkademikerPension, has announced it is divesting its holdings of US Treasury bonds. The fund's investment director cited "poor U.S. government finances" as the primary reason, stating the fund needs to find alternative ways to manage its liquidity and risk. The article notes the divestment is relatively small, totaling approximately $100 million, but is seen as a symbolic move reflecting growing concerns about the US fiscal outlook.
>
> **Discussion:** The Hacker News discussion centered on the symbolic significance of the divestment, the underlying causes of US fiscal policy, and the potential long-term consequences for the dollar's global status. While many commenters acknowledged that the $100 million figure is a "drop in the bucket" compared to the daily volume of the Treasury market, there was a consensus that the move is a notable warning sign. Several users suggested that if this action were to be replicated by other funds or nations, it could signal a more significant shift.

The conversation quickly pivoted to the root causes of the US fiscal situation. A major theme was the political gridlock and lack of appetite to address the national debt. Commenters debated whether the issue stemmed from "endless taxation" or, more specifically, from tax cuts for the wealthy combined with massive spending on the military and debt service. One user provided data suggesting that major deficit spikes were linked to specific shocks like 9/11, the Iraq War, and the COVID-19 pandemic, while another argued the problem began with the Bush-era tax cuts that reversed the budget surpluses of the late 1990s.

A broader geopolitical theme emerged, with users debating the future of the US dollar as the world's reserve currency. One commenter argued this status is underpinned by the strength of the US Navy, while another viewed the divestment as part of a larger trend of de-dollarization, citing recent moves by Europe and Canada to strengthen economic ties with China. This was framed as a "rupture" in the post-Cold War order, where the US is increasingly using its financial system as a weapon, prompting other nations to seek alternatives. The discussion also touched on the political climate, with some blaming the current administration for creating global instability, while others pointed to the broader support for these policies among a significant portion of the American electorate.

---

## [De-dollarization: Is the US dollar losing its dominance? (2025)](https://www.jpmorgan.com/insights/global-research/currencies/de-dollarization)
**Score:** 593 | **Comments:** 786 | **ID:** 46693346

> **Article:** The article from J.P. Morgan explores the concept of "de-dollarization," examining whether the US dollar is losing its status as the world's dominant reserve currency. It likely analyzes trends in global foreign exchange reserves, the impact of US monetary policy, and the rise of alternative currencies like the Euro and the Chinese Renminbi. The piece assesses the structural factors supporting the dollar's dominance against emerging challenges, such as geopolitical tensions and the search for financial alternatives by other nations.
>
> **Discussion:** The Hacker News discussion is highly polarized, centering on the causes of the dollar's perceived decline and the role of current US political leadership.

A dominant theme is the attribution of the dollar's weakening to intentional policy decisions by the Trump administration. Several commenters argue that the dollar is being "destroyed on purpose," citing potential threats to the Federal Reserve's independence and the appointment of loyalists as key risks that could trigger a currency crash. This view is framed by some as a strategic goal to devalue the dollar to make US goods more competitive, though others counter that this approach is reckless and lacks a coherent strategy.

Conversely, several users provide a more structural and historical perspective, arguing that the decline is a gradual, long-term trend rather than a sudden event. They point out that the dollar's share of global reserves has been steadily decreasing for decades, falling from over 70% in the 1990s to around 60% today. This is attributed to the natural emergence of viable alternatives like the Euro and the inherent "Triffin Dilemma," where the dollar's role as a reserve currency necessitates persistent US trade deficits.

The discussion also touches on the fundamental nature of currency value, with commenters emphasizing that the dollar's strength is built on trust in US institutions and governance. The perceived unpredictability of recent US foreign and economic policy is seen as a catalyst for other nations to seek alternatives, accelerating a shift toward a multipolar financial world. While some commenters dismiss the relevance of cryptocurrencies in this context, others suggest that unmeasurable forms of de-dollarization may be occurring in less formal sectors of the economy.

---

## [I'm addicted to being useful](https://www.seangoedecke.com/addicted-to-being-useful/)
**Score:** 535 | **Comments:** 273 | **ID:** 46690402

> **Article:** The article "I'm addicted to being useful" is a personal reflection by a software engineer on his compulsion to be productive and solve problems. He describes this as a core part of his identity, which he sees as both a professional strength and a personal "dysfunction." He enjoys the feeling of being needed and finds purpose in fixing things, whether in his job or personal life. He acknowledges that this drive can be unhealthy, leading to burnout and an inability to relax, but ultimately accepts it as an integral part of who he is. He also notes that this mindset makes him a good fit for dysfunctional workplaces that rely on individuals willing to go above and beyond to hold things together.
>
> **Discussion:** The discussion on Hacker News shows a strong consensus that many readers, particularly in tech, relate deeply to the article's theme. However, the conversation quickly pivots from simple agreement to a critical examination of the downsides and nuances of this "usefulness addiction."

A major theme is the negative impact this mindset can have on leadership and personal relationships. Several commenters, including iamflimflam1 and tclancy, warn that constantly solving problems for others can be stifling and counterproductive, especially for a manager. It can prevent team members from growing and can make personal interactions feel transactional rather than empathetic. The advice given is to shift perspective from "solving problems for people" to "growing people," and to learn to listen without immediately offering solutions, as partners and colleagues often just want to be heard.

Another prominent theme is the risk of burnout. Users like nusl and Ronsenshi confirm that this constant drive to be useful can be exhausting and lead to regular burnout, requiring significant downtime to recover.

The discussion also explores the underlying motivations. One commenter, dmichulke, posed a critical question: is the addiction to being useful itself, or to being *recognized* as useful? This distinction suggests the drive could be rooted in a need for external validation rather than purely intrinsic satisfaction.

Finally, the conversation touches on broader philosophical and societal implications. One commenter linked the feeling of uselessness to the horror of unemployment or retirement, citing an anecdote about an African politician's reaction to idle social housing residents. Another brought in Nietzschean concepts of power, framing the pursuit of usefulness as a form of seeking power. The discussion also briefly touched on how this identity is being challenged by the rise of AI, with some feeling their expertise is devalued while others feel more useful than ever in cutting through AI-generated noise.

---

## [A 26,000-year astronomical monument hidden in plain sight (2019)](https://longnow.org/ideas/the-26000-year-astronomical-monument-hidden-in-plain-sight/)
**Score:** 452 | **Comments:** 90 | **ID:** 46695628

> **Article:** The article from Long Now describes a massive, intricate sculpture group at the Hoover Dam, created in 1932 by artist Oskar Hansen. The sculptures, known as "The Highwater Marks," were designed to serve as a 26,000-year astronomical clock. Hansen used the position of the celestial pole (the North Star) relative to the sculptures to mark the passage of time. The monument is intended to record the high water marks of the Colorado River at the time of the dam's construction, while simultaneously tracking the precession of the equinoxes—a 26,000-year cycle. The article posits that this was a deliberate attempt to create a message for future civilizations, using the predictable movement of the stars to convey a date far into the future, assuming the structure survives.
>
> **Discussion:** The Hacker News discussion reveals a mix of fascination with the monument's design and skepticism regarding its historical context. Several commenters express awe at the ingenuity of the art and the concept of encoding a message for the distant future, with one user calling it an "excellent rabbit hole." The conversation frequently touches on the historical context of the era, noting that without modern light pollution and distractions, ancient and early modern societies paid far more attention to the night sky for navigation and survival.

A significant portion of the debate centers on the reliability of sources. One user mentions first hearing about the monument in a book by Graham Hancock, which prompted a skeptical reply questioning Hancock's credibility as a "fraud." This highlights a recurring tension on the platform between alternative history narratives and mainstream academic consensus. Additionally, the discussion expands into the scientific mechanics of the monument's function, with users providing detailed information on the precession of the equinoxes, the historical shifting of the North Star (from Thuban to Polaris), and Milankovitch cycles. There is also a minor technical correction regarding celestial navigation, clarifying that it is not solely dependent on the North Star and is primarily a Northern Hemisphere phenomenon.

---

## [Nvidia Stock Crash Prediction](https://entropicthoughts.com/nvidia-stock-crash-prediction)
**Score:** 401 | **Comments:** 333 | **ID:** 46693205

> **Article:** The article analyzes the probability of a significant crash in Nvidia's stock price, using options market data to infer the collective market belief about future price movements. It specifically examines a prediction market question about whether Nvidia's stock will close below $100 on any day in 2026, framing it as a way to understand the implied volatility and crash risk priced into the stock by the market. The analysis suggests that while the market assigns a non-trivial probability to such a crash, the article itself does not definitively predict one will occur, but rather explores what the current market pricing implies about investor sentiment and risk.
>
> **Discussion:** The Hacker News discussion largely sidesteps the article's technical options-market analysis in favor of debating the fundamental business and geopolitical risks facing Nvidia. A dominant theme is the existential threat of a China-Taiwan conflict, with several users arguing that an invasion would devastate Nvidia's supply chain and potentially drive its stock to near zero, a risk they believe is not fully priced in. Another major thread concerns the sustainability of the AI boom. Commenters express skepticism that the current massive spending on AI data centers can continue indefinitely, comparing it to a gold rush that will eventually slow as initial infrastructure is built out. This leads to speculation that Nvidia's growth will inevitably decelerate as competitors emerge and customers extend the depreciation schedules of their expensive GPUs.

Beyond these core risks, the discussion touches on several other points. Some users debate the nature of the prediction itself, distinguishing it from a standard financial option. Others criticize the article's approach as overly theoretical, arguing that real-world factors like missed earnings or the failure of other AI companies are more critical than abstract volatility models. There is also a recurring sentiment that a potential crash, while risky for current investors, would represent a buying opportunity for those who believe in Nvidia's long-term fundamentals, though this is tempered by skepticism about its high P/E ratio. The conversation ultimately reflects a broader uncertainty about the timing of a potential market correction, acknowledging that while bubbles eventually pop, predicting the moment of collapse is notoriously difficult.

---

## [California is free of drought for the first time in 25 years](https://www.latimes.com/california/story/2026-01-09/california-has-no-areas-of-dryness-first-time-in-25-years)
**Score:** 359 | **Comments:** 179 | **ID:** 46698660

> **Article:** The article reports that for the first time in 25 years, California is officially free of drought conditions. This follows a period of significant rainfall that has replenished reservoirs and improved soil moisture levels across the state, ending a prolonged period of dryness that had led to strict water conservation measures.
>
> **Discussion:** The Hacker News discussion surrounding the article is largely skeptical and contextual, focusing on the cyclical nature of California's climate and the limitations of the current "drought-free" status.

Many commenters, citing John Steinbeck's *East of Eden*, emphasized the historical reality of California's 30-year weather cycles, noting that wet years are often followed by severe dry years. There was a strong consensus that the current relief is likely temporary. Users pointed out that while precipitation is high, the warm winter has resulted in lower-than-average snowpack, which is crucial for sustained water supply through the summer melt.

The conversation also touched on infrastructure and policy. Some argued that California's failure to build new dams for a growing population is the root cause of water shortages, while others countered that the best dam sites are already utilized and that dams come with significant environmental and financial costs.

Several users shifted the focus to the broader national context, noting that while California is wet, other parts of the U.S. are experiencing severe drought and low snowpack. Anecdotal reports from residents described the recent storms as unusually destructive due to saturated ground and high winds, and there was some discussion regarding the disconnect between the end of the drought and the persistence of high water rates.

---

## [Unconventional PostgreSQL Optimizations](https://hakibenita.com/postgresql-unconventional-optimizations)
**Score:** 335 | **Comments:** 50 | **ID:** 46692116

> **Article:** The article "Unconventional PostgreSQL Optimizations" by Haki Benita explores advanced techniques to solve specific database performance and storage problems. The author presents three main case studies: 1) Using a **partial hash index** to enforce uniqueness on a subset of rows (e.g., active users) while saving significant storage space compared to a standard B-Tree index. 2) Leveraging **constraint exclusion** and **table partitioning** to speed up queries by allowing the database to skip scanning irrelevant partitions. 3) Using the **`MERGE`** statement (introduced in PostgreSQL 15) for complex upsert operations that go beyond the capabilities of `INSERT ... ON CONFLICT`. The article highlights how to utilize these features to achieve high performance and efficiency, often by trading off storage for speed or accepting some implementation complexity.
>
> **Discussion:** The discussion on Hacker News was overwhelmingly positive, with many users praising the article for revealing the depth and power of PostgreSQL. A recurring theme was the feeling that even experienced developers have only "scratched the surface" of PostgreSQL's capabilities, with one commenter comparing it to an "operating system disguised as something else."

Key technical points raised in the comments include:
*   **Virtual Columns vs. Stored Generated Columns:** Users debated the use of generated columns. While stored generated columns (materializing the result) are easier to index, they consume extra storage, which the article's specific example aimed to avoid. Commenters noted that virtual columns (calculating on-the-fly) are close to being fully implemented in PostgreSQL.
*   **Hash Indexes and Uniqueness:** A user questioned the safety of using hash indexes for uniqueness, fearing hash collisions. This was clarified: PostgreSQL's implementation correctly handles collisions by checking the full value, making the technique safe and storage-efficient.
*   **PostgreSQL's Query Planner and Caching:** A discussion point was PostgreSQL's lack of a persistent query plan cache. Unlike other databases, PostgreSQL caches plans per-connection and only for prepared statements used multiple times. This can lead to suboptimal plan choices for queries with variable parameters (e.g., array lengths), though connection pooling is noted as an important mitigation.
*   **MERGE vs. ON CONFLICT:** The article's brief mention of the `MERGE` command sparked interest. Users compared it to the more common `INSERT ... ON CONFLICT` (upsert). While `MERGE` is more powerful and flexible, some commenters expressed a preference for `ON CONFLICT` due to its simplicity and clearer atomicity within PostgreSQL's MVCC model, advising caution with `MERGE`'s edge cases.
*   **Infrastructure and Tooling:** Practical advice was shared on using tools like `pgcli` for a better command-line experience (syntax highlighting, autocomplete) and `COPY` for high-speed bulk data loading.

---

## [Running Claude Code dangerously (safely)](https://blog.emilburzo.com/2026/01/running-claude-code-dangerously-safely/)
**Score:** 311 | **Comments:** 241 | **ID:** 46690907

> **Article:** The article "Running Claude Code dangerously (safely)" by Emil Burzo addresses the risks of using coding agents like Claude Code with unrestricted system access. The author proposes a pragmatic sandboxing solution using Vagrant to create an isolated, disposable virtual machine (VM) for each project. This approach allows the AI to perform destructive actions (installing packages, modifying files, even deleting the VM) without affecting the host machine. The method leverages Vagrant's `vagrant up` for easy setup and teardown, and syncs the project folder to the host via Git, balancing safety with the convenience of using local development tools.
>
> **Discussion:** The Hacker News discussion centers on the trade-offs of sandboxing AI coding agents, with users sharing various methods to contain potential damage. The core debate revolves around the level of isolation required versus the convenience of integration with the host system.

Many users corroborate the article's approach, using virtual machines (Vagrant, Proxmox) or containers to create isolated environments. A key point of agreement is the importance of using version control (Git) as a safety net; this allows users to sync changes back to the host without fear of permanent loss. Some users prefer containers for their lighter footprint, though others note difficulties with nested containerization (e.g., developing Dockerfiles inside a container). A more extreme approach mentioned is using dedicated bare-metal machines or ephemeral PXE-booted instances for maximum isolation.

A significant portion of the discussion critiques the effectiveness of built-in sandboxing. Users point to Anthropic's official documentation, which describes an "escape hatch" that allows the AI to disable its own sandbox. Commenters argue this is a fundamental flaw, linking to GitHub issues where the AI reportedly bypasses user confirmations. The consensus is that users cannot rely on the agent's self-policing for safety.

Beyond sandboxing, the conversation touches on other risks, such as API calls to third-party services (e.g., GitHub CI deploys), which are not easily contained within a VM. An anecdote about a user losing their home directory to a rogue `rm` command serves as a stark warning against running agents with broad permissions. The discussion concludes with a shared sentiment that while running agents "dangerously" can be liberating, it requires a robust, user-managed safety strategy, with Git and disposable VMs being the most popular solutions.

---

## [Meta's legal team abandoned its ethical duties](https://www.afterbabel.com/p/how-metas-lawyers-perfected-the-playbook)
**Score:** 260 | **Comments:** 193 | **ID:** 46694378

> **Article:** The article argues that Meta's legal team has systematically abandoned its ethical duties, moving beyond standard risk management to actively suppress evidence and undermine the legal process. It contends that instead of upholding the law and ethical standards, Meta's lawyers have perfected a playbook for corporate obfuscation, using legal tools like attorney-client privilege and data retention policies not to ensure compliance, but to shield the company from accountability for documented harms caused by its platforms, particularly to children.
>
> **Discussion:** The Hacker News discussion is overwhelmingly critical of Meta and the broader corporate culture it represents, though a few commenters offer defenses of standard legal and business practices. The conversation can be broken down into several key themes:

*   **Skepticism and Condemnation of Meta:** The prevailing sentiment is one of deep distrust and condemnation. Commenters express shock at Meta's alleged actions, with some referencing books like "Careless People" to argue the company's ethical failings are even worse than publicly known. The idea of Meta and "ethics" being in the same sentence is treated as an oxymoron.

*   **Broader Critique of Corporate Profit Motives:** Many users extend the criticism beyond Meta to the entire US corporate landscape. They argue that the singular focus on shareholder value and profit maximization has created a system where unethical, and even illegal, behavior is rationalized through cost-benefit analysis. This is contrasted with the well-being of society, with commenters citing examples like United Healthcare to illustrate a systemic problem where profit is prioritized over human lives.

*   **Parental and Societal Impact:** A significant thread discusses the real-world consequences of social media on children and families. Parents in the discussion share their struggles with the "FOMO" (fear of missing out) their children experience when excluded from social media, and express frustration at how these companies make responsible parenting feel like being a "villain." This highlights the societal pressure created by addictive platforms.

*   **A Counter-Argument on Legal and Business Norms:** A dissenting perspective, though in the minority, defends the actions described. One commenter argues that minimizing legal risk through standard practices like data deletion and leveraging attorney-client privilege is not only ethical but a lawyer's duty. This view frames the article's claims as a manipulative misrepresentation of standard corporate legal strategy.

*   **Insider Perspectives and Meta's Competence:** A former Facebook employee confirms the company's internal culture, stating that success requires a willingness to do "anything" to meet performance goals, and that engineers and product managers are complicit. Another thread questions Meta's overall competence, pointing to its failures in innovation (e.g., the metaverse, cryptocurrency) and its reliance on acquisitions for successful products.

---

## [Anthropic's original take home assignment open sourced](https://github.com/anthropics/original_performance_takehome)
**Score:** 222 | **Comments:** 99 | **ID:** 46700594

> **Article:** Anthropic has open-sourced its original performance take-home assignment for engineering candidates. The task involves optimizing a kernel within a simulated machine environment to minimize execution cycles. The repository includes a README with performance numbers but minimal instruction, prompting users to dig into the source code for the actual problem description. The assignment is designed to test low-level optimization skills, specifically targeting those familiar with hardware or compiler optimizations.
>
> **Discussion:** The Hacker News discussion revolves around the difficulty, nature, and intent of the assignment. Several users struggled to locate the actual problem description within the repository, though others eventually pointed out that the goal is to optimize the `build_kernel` function in `perf_takehome.py` to beat a benchmark cycle count.

Opinions on the assignment's value were divided:
*   **Assessment of Difficulty:** Many commenters characterized the problem as extremely difficult, requiring deep knowledge of GPU architecture, polyhedral layout algebra, and low-level optimization techniques like writing PTX. Some noted it resembles "demoscene" code golfing.
*   **Hiring Philosophy:** A debate emerged regarding whether this type of test effectively measures engineering talent. Some argued it selects for "nerds" with niche hardware knowledge, while others countered that this is a necessary baseline requirement for performance engineering roles, preferable to typical web development take-homes.
*   **Criticism of Anthropic:** Several comments expressed skepticism toward Anthropic. Some criticized the "snarky" tone of the challenge (specifically the instruction to email them if a solution beats Claude's performance), while others brought up past controversies regarding intellectual property and model performance degradation post-launch.
*   **AI Capabilities:** One user jokingly suggested the release was a "DDOS attack" on other AI models, noting that prompting Gemini CLI to solve the problem caused it to run indefinitely. Another user confirmed that Gemini often gets stuck in reasoning loops on complex tasks.

---

## [The Unix Pipe Card Game](https://punkx.org/unix-pipe-game/)
**Score:** 214 | **Comments:** 66 | **ID:** 46694124

> **Article:** The article links to "The Unix Pipe Card Game," a physical card game designed to teach the concept of Unix pipes. The game consists of cards representing standard Unix commands (like `grep`, `sort`, `cat`) and data sets. Players must create a sequence of commands (a pipeline) to transform input data into a desired output, simulating how pipes work in a terminal. The game is sold via the author's website, though it is currently noted as sold out.
>
> **Discussion:** The Hacker News discussion explores the utility and design of the card game, centering on the debate between physical versus digital methods for teaching Unix concepts.

A primary theme is the educational value of the game. One commenter, a science teacher, argued that while the game is cute, physical cards lack the "instant feedback" crucial for discovery-based learning. They suggested that a digital version would allow children to experiment and learn what commands do by seeing the immediate results, rather than relying on a parent to explain the rules. However, another user countered that the "trial and error" approach of digital experimentation can be frustrating for beginners, advocating for a more structured introduction to concepts like piping.

The conversation also touched on the nature of the game itself. The creator of the game chimed in to clarify that it was designed primarily as a teaching aid for their daughter—a way to "get out of the computer" and visualize the logic of pipelines—rather than a standalone, highly replayable board game. Several users agreed with this sentiment, describing the game as a "play once" novelty that serves as a fun icebreaker or conceptual primer before moving to actual terminal practice.

Finally, the discussion broadened to related technical topics. Users shared links to similar card games (like "Gates") and online "wargames" (like OverThe Wire's Bandit) for practicing shell skills. There was also a brief tangent on the limitations of traditional Unix pipes (transferring only text/bytes) and a recommendation for modern alternatives like Nushell, which handles structured data types.

---

## [Ask HN: Do you have any evidence that agentic coding works?](https://news.ycombinator.com/item?id=46691243)
**Score:** 200 | **Comments:** 186 | **ID:** 46691243

> **Question:** The user asks the Hacker News community for evidence that "agentic coding" (using AI agents to write code) is effective. The question is open-ended, seeking concrete proof or experiences to validate the practice, implying skepticism about its current utility beyond hype.
>
> **Discussion:** The discussion reveals a nuanced consensus: agentic coding is useful but requires strict human oversight and is best suited for specific, limited tasks rather than complex system design.

Key points of agreement include:
*   **Human-in-the-loop is mandatory:** Almost all commenters agree that agents cannot be trusted to produce code without review. The consensus is that while agents can accelerate development, the human must remain the architect and quality gatekeeper. As one user noted, "You are asking two very different questions... whether using agents to write code is net-positive, and then you go on about not reviewing the code agents produce."
*   **Scope is the primary limitation:** A major theme is that agents struggle with high-level planning and complex architecture. They excel at "monkey work," boilerplate, and isolated tasks (e.g., refactoring, porting code) but fail at designing abstract systems. One user argued that those claiming AI is "great" are often building small apps and incorrectly extrapolating that success to larger, more complex projects.
*   **The "Junior Developer" analogy:** Several users compared agents to a fleet of junior developers available 24/7. They are useful for offloading tedious work but require clear, specific instructions and constant supervision. They don't learn from mistakes and can produce subtly wrong code or "cheat" by writing meaningless tests that always pass.
*   **Skill development is required:** Some argued that using agents effectively is a skill that developers must cultivate, similar to learning to code initially. This involves learning how to structure prompts, build robust test suites for the agent to work against, and manage the agent's output.
*   **Value in non-coding tasks:** A few commenters highlighted that agents are particularly valuable for documentation, analysis, and acting as a "rubber duck" for debugging, rather than just code generation.

Overall, the community views agentic coding as a productivity enhancer for specific, well-scoped problems, but not a replacement for human software architects, especially in large or complex systems.

---

## [Instabridge has acquired Nova Launcher](https://novalauncher.com/nova-is-here-to-stay)
**Score:** 188 | **Comments:** 123 | **ID:** 46696357

> **Article:** Instabridge has acquired Nova Launcher, a popular third-party Android launcher. The acquisition announcement is framed with a commitment to keep the product alive and maintain its current state, stating that data collection will remain minimal and that they will not sell personal data. The post links to a statement on the official Nova Launcher website.
>
> **Discussion:** The Hacker News community reacted with widespread skepticism and disappointment, largely viewing the acquisition as the final step in the "enshittification" of Nova Launcher. The discussion is heavily colored by recent events: the acquisition of Nova by Branch Metrics in 2022, the subsequent layoffs that left only the original developer, and his eventual departure in September 2024 after reportedly being blocked from open-sourcing the project.

Commenters are particularly cynical about the new owners' promises of minimal data collection and an ad-free experience for paid users. Many point to the recent addition of Facebook and Google Ads tracking in the app as evidence that these promises are already broken or will be soon. The timing of the acquisition announcement, following so closely on the heels of the founder's exit, is seen as especially suspicious.

Consequently, users are actively discussing alternatives. Popular suggestions include Lawnchair, an open-source launcher, and AIO Launcher. There is a strong sentiment that the era of Nova Launcher as a trusted, feature-rich utility is over, with many long-time paid users stating they will be switching away from the app.

---

## [IP Addresses Through 2025](https://www.potaroo.net/ispcol/2026-01/addr2025.html)
**Score:** 173 | **Comments:** 131 | **ID:** 46691835

> **Article:** The article "IP Addresses Through 2025" provides a data-driven analysis of the IPv4 and IPv6 address markets. It highlights a significant shift in the IPv4 market, noting that prices have collapsed from a peak of over $55 per address in 2021 back to 2014 levels of around $9. The author attributes this to reduced demand from major cloud providers like AWS, who have shifted from aggressive stockpiling to inventory management, and the increasing efficiency of technologies like Carrier-Grade NAT (CGNAT). The article also tracks the continued, albeit slow, growth of IPv6 adoption globally. It concludes on a somber note, reflecting on the internet's evolution from a disruptive innovation to an established, centralized norm governed by a few large incumbents, questioning the future of its open and innovative spirit.
>
> **Discussion:** The discussion on Hacker News centered on several key themes. A major point of interest was the dramatic collapse in IPv4 prices, with users debating the causes. One prominent theory, supported by several commenters, is that the previous price spike was an artificial bubble driven by hyperscalers like AWS stockpiling addresses. The consensus is that AWS's decision to start charging for public IPv4 addresses effectively called the market's bluff, reducing their own acquisition pressure and revealing the true, lower demand as CGNAT and other efficiencies became more widespread.

Another significant thread revolved around the article's concluding remarks on the internet's increasing centralization and loss of disruptive potential. Commenters expressed pessimism, with some arguing that future regulatory frameworks might inadvertently entrench the positions of large incumbents rather than foster competition.

A smaller but notable discussion emerged from a comment alleging that China and India are acquiring large IP blocks in Africa for botting operations. This sparked a debate about the language used to attribute such actions to countries versus corporations or individuals.

Finally, several tangential topics were raised, including a technical query about the use of "GB" versus "UK" in the article's tables, a brief mention of the aesthetics of the website's design, and a call from some users for more aggressive government mandates to accelerate IPv6 adoption.

---

## ['This is sell America' – US dollar tumbles as globe flees US assets](https://www.cnbc.com/2026/01/20/sell-america-trade-dollar-treasury-gold-us-trump-greenland.html)
**Score:** 156 | **Comments:** 68 | **ID:** 46695061

> **Article:** The CNBC article, dated January 20, 2026, reports on a significant downturn in the US dollar and a sell-off of US assets, which analysts are dubbing the "Sell America" trade. The article attributes this trend to growing global investor anxiety fueled by the Trump administration's aggressive and unpredictable economic and foreign policies. Key drivers mentioned are the imposition of massive tariffs on allies, threats of military action against countries like Canada and Greenland, and rhetoric undermining international alliances like NATO. This has led to a flight of capital from US Treasuries, the dollar, and US equities into perceived safe havens like gold and foreign assets, signaling a potential loss of confidence in the United States as a stable investment destination.
>
> **Discussion:** The Hacker News discussion is highly critical of the Trump administration and expresses significant concern over the economic and geopolitical fallout. The conversation can be broken down into several key themes:

A primary theme is the breakdown of international relations and America's global standing. Users point to specific actions, such as the US imposing tariffs and threatening to invade Canada, as the cause for allies like Canada seeking to distance themselves. This sentiment is amplified by reports of Trump calling NATO an "enemy," which commenters interpret as a fundamental betrayal of alliances and a gift to adversaries like Russia. There is a strong belief that other nations should now treat the US as an adversary in response.

Another major focus is on personal finance and investment strategy in this volatile climate. Several users discuss shifting their portfolios away from US-centric funds (like VOO) towards international equities (VXUS) and hedges like gold. However, a counterpoint is raised that for US-based individuals, a global economic downturn triggered by a US collapse would likely impact all assets, making a simple shift to foreign holdings an imperfect hedge. The general mood is one of seeking safety from the US dollar and stock market.

Finally, the discussion is filled with sharp political criticism and alarm. Commenters express dismay at the perceived complicity of Republican legislators in the administration's actions, which they list as including unconstitutional arrests, illegal tariffs, and threats of invasion. There is a palpable fear that the administration's behavior is escalating dangerously, with one user expressing genuine concern about the potential use of nuclear weapons. The discussion also touches on the administration's blame-shifting tactics and the troubling reality that the president maintains a significant approval rating despite these controversies, which is seen as the reason for his party's silence.

---

## [Show HN: Mastra 1.0, open-source JavaScript agent framework from the Gatsby devs](https://github.com/mastra-ai/mastra)
**Score:** 150 | **Comments:** 49 | **ID:** 46693959

> **Project:** Mastra 1.0 is an open-source TypeScript-native agent framework for building AI applications, created by the team behind Gatsby. It provides primitives for creating agents, workflows, and tools, aiming to offer a production-ready, vendor-agnostic alternative to other AI frameworks with a focus on developer experience for full-stack TypeScript developers.
>
> **Discussion:** The launch was met with positive reception, particularly from developers invested in the TypeScript ecosystem who appreciated a framework designed specifically for their stack. Key discussion points included comparisons to other frameworks like Strands Agents and Spring AI, with Mastra's TypeScript-first approach being highlighted as a primary differentiator. The conversation also touched on broader industry trends, such as the increasing use of AI for code generation and the debate between building custom agent solutions versus using established frameworks. A notable technical point was the team's decision to avoid complex ESM/CJS bundling issues, opting for a more explicit approach. The framework's new `agent.network()` method for creating dynamic multi-agent hierarchies was also a point of interest.

---

## ['The old order is not coming back,' Carney says in speech at Davos](https://www.cbc.ca/news/politics/carney-davos-speech-9.7052725)
**Score:** 147 | **Comments:** 174 | **ID:** 46694482

> **Article:** In a speech at the World Economic Forum in Davos, Canadian Prime Minister Mark Carney declared that the "old order" of the post-World War II rules-based international system is not returning. He argued that this system was always a partial fiction, where powerful nations like the US exempted themselves from rules they enforced on others. Carney stated that the era of American hegemony providing global public goods is over, replaced by a reality of "intensifying great power rivalry" where economic integration is used as coercion. He urged middle powers to develop strategic autonomy in energy, finance, and supply chains, and to band together to avoid being exploited by larger nations.
>
> **Discussion:** The discussion on Hacker News centered on the implications of Carney's speech, the reliability of the United States as a partner, and historical parallels to the current geopolitical climate.

A dominant theme was the decline of US leadership and its reliability. Commenters widely agreed that the re-election of Donald Trump has permanently damaged America's standing, proving it to be an unreliable partner. The consensus was that allies can no longer depend on the US-led world order, and Carney's direct criticism reflects a significant shift in diplomatic language. Some noted that this decline is not just a Trump-era phenomenon but a deeper political problem within the US that won't disappear with him.

Many commenters focused on the proposed solution for "middle powers" to organize. There was a mix of optimism and skepticism. Some saw the call for an "economic NATO" (without the US) and a shift away from purchasing US weaponry as a pragmatic path to greater autonomy. However, others questioned the feasibility, pointing out the difficulty of achieving full unity among nations (citing Hungary within the EU) and the inherent challenge of preventing such a new alliance from eventually behaving like the old great powers.

Historical analogies were a major point of debate. One commenter drew a direct parallel between the current US-Russia-China dynamic and the 1939 Molotov-Ribbentrop Pact between Stalin and Hitler, suggesting a new division of global spheres of influence. This sparked a detailed counter-argument that the more accurate comparison is the Sino-Soviet split, and a lengthy historical analysis argued that fascism was not defeated after WWII but was instead absorbed into Western institutions (like NATO and the CIA), leading to its modern resurgence.

Finally, there was a critical perspective on the economic costs of this global shift. One commenter argued that the real-world consequences—such as rising prices, austerity, and worse labor conditions—will be paid by ordinary people, not the elites at Davos. This view framed Carney's speech as a "game-theoretic" observation that ignores the intrinsic problems of capitalism driving these power competitions.

---

## [Claude Chill: Fix Claude Code's flickering in terminal](https://github.com/davidbeesley/claude-chill)
**Score:** 146 | **Comments:** 101 | **ID:** 46699072

> **Article:** The article links to a GitHub repository for "claude-chill," a tool designed to fix the screen flickering and erratic scrolling that occurs when using Anthropic's Claude Code CLI tool in a terminal. The tool is a simple wrapper that addresses a persistent visual bug in the official Anthropic product.
>
> **Discussion:** The discussion is overwhelmingly positive towards the creator of the tool, with users expressing gratitude for solving a frustrating issue that causes headaches and visual discomfort. However, the conversation quickly pivots to criticism of Anthropic, the company behind Claude Code.

Key themes include:
*   **Criticism of Anthropic's Product Quality:** Users express disbelief and frustration that a core CLI tool from a leading AI company still has a basic visual bug that a third-party developer could fix. This is seen as a stark contrast to the company's ambitious claims about AI writing most of the world's code.
*   **Irony and Hypocrisy:** Commenters find it ironic that a company focused on "vibe coding" and advanced AI cannot fix a simple terminal flickering issue. One user humorously quotes a hypothetical Claude response highlighting this contradiction.
*   **Speculation on Open Source Strategy:** Some users speculate that Anthropic doesn't open-source Claude Code not for competitive reasons, but to hide a messy codebase. They suggest the company fears the quality of external contributions ("slop PRs").
*   **Comparison to Competitors:** One user notes that competing CLI tools (like Codex, Gemini) do not have this flickering problem, suggesting the issue is specific to Anthropic's implementation.
*   **Minor Technical Notes:** A few users tested the fix, with one noting it works but still has minor periodic flickering in a different environment (Cursor terminal).

---

## [IPv6 is not insecure because it lacks a NAT](https://www.johnmaguire.me/blog/ipv6-is-not-insecure-because-it-lacks-nat/)
**Score:** 139 | **Comments:** 212 | **ID:** 46696303

> **Article:** The article argues that IPv6 is not inherently insecure due to the lack of Network Address Translation (NAT). The author clarifies that NAT in IPv4 was primarily implemented to solve address exhaustion, not for security. While NAT provides a side effect of security by making internal devices unreachable from the internet by default, this is not its intended purpose. The article asserts that IPv6 relies on firewalls for security, which is a more robust and explicit method than relying on the accidental security of NAT. It encourages network administrators to configure proper firewall rules rather than fearing the transition to IPv6 due to the absence of NAT.
>
> **Discussion:** The Hacker News discussion largely validates the article's premise but adds significant nuance and debate regarding the practical realities of network security.

There is a strong consensus that NAT is not a security feature by design; its primary purpose was address conservation. However, commenters debate whether the "accidental" security it provides is a material factor in network defense. Several engineers argue that the security benefit comes from the stateful firewall inherent in most NAT implementations, which blocks unsolicited inbound traffic, and that this functionality is independent of the address translation itself.

A key point of contention is the default security posture of IPv6. While IPv6 routers typically ship with default-deny firewalls, some users shared anecdotes of misconfigured networks where IPv6 was enabled without a firewall, leading to compromised devices. This highlights a human/implementation issue rather than a protocol flaw. The discussion also touches on the fact that IPv6 can use NAT (via ULA or NAT66), but it is uncommon and generally not recommended.

Other topics include:
*   **Address Obfuscation:** Some argue that IPv4's private addresses offer a layer of obscurity, whereas IPv6's globally routable addresses expose device-specific information. Others counter that this is not a security feature and that obfuscation is still possible in IPv6 if desired.
*   **UPnP Risks:** A commenter pointed out that UPnP, often used to punch holes in IPv4 NAT firewalls, introduces its own security vulnerabilities, which are irrelevant in a properly configured IPv6 environment.
*   **Practical Challenges:** A few commenters shared real-world operational issues with IPv6, such as problems with SIP/VoIP services, suggesting that while the protocol is secure, its implementation can be complex.

Overall, the community agrees that IPv6 is not less secure than IPv4, but the transition requires a conscious shift from relying on NAT's side effects to actively managing firewall rules.

---

## [The challenges of soft delete](https://atlas9.dev/blog/soft-delete.html)
**Score:** 134 | **Comments:** 80 | **ID:** 46698061

> **Article:** The article "The challenges of soft delete" explores the common practice of marking records as deleted (e.g., via a `deleted_at` timestamp) rather than physically removing them from the database. While soft deletion offers benefits like easy data recovery and maintaining referential integrity, the article highlights significant downsides. These include query complexity (requiring filters on every query), performance degradation as tables grow with inactive rows, and complications with data compliance (such as GDPR or CCPA) which often mandate actual data erasure. The author suggests alternative approaches, such as moving deleted records to a separate archive table or using database triggers, to mitigate these issues while retaining the ability to restore data when necessary.
>
> **Discussion:** The Hacker News discussion reveals a nuanced debate on the merits of soft deletion, with participants weighing technical, operational, and legal factors. Key themes include:

*   **Technical Implementation and Performance:** Several users proposed architectural solutions to the performance and complexity issues of soft deletes. These included moving deleted records to a separate collection (as in NoSQL), using database views or Row-Level Security (RLS) to hide deleted data from application logic, and utilizing table partitioning to physically separate active and inactive data. However, a counterpoint was raised that moving data in relational databases is difficult due to foreign key constraints.

*   **Data Retention vs. Privacy Regulations:** A major point of contention was the conflict between data retention and privacy laws. While some argued that "data is never deleted" for analytical value and that storage is cheap, others countered that privacy regulations (like GDPR and CCPA) and customer requirements often mandate full deletion, making soft delete unviable in many contexts. It was noted that soft delete and privacy deletion serve different purposes: one for internal recovery and the other for legal compliance.

*   **Schema and Maintenance Challenges:** A significant concern discussed was schema drift. When archived or soft-deleted objects are stored with an old schema, future schema changes can make restoring that data difficult or impossible. While some argued that archived data is rarely accessed and "best-effort" restoration is sufficient, others highlighted the risk and complexity of migrating historical data.

*   **Cultural and Analytical Perspectives:** The discussion touched on the cultural aspect of data retention, with some noting a strong preference for never deleting data to preserve historical context for analysis and debugging. The immutable data model was praised for making historical analysis straightforward. Conversely, the view that data can be a "toxic asset" was presented as a reason to favor permanent deletion.

*   **Practical Experience:** User experiences varied widely. Some found soft delete easy to manage and undo, while others admitted to never successfully restoring large sets of soft-deleted data, leading them to abandon the practice entirely.

---

