# Hacker News Summary - 2026-01-12

## [The struggle of resizing windows on macOS Tahoe](https://noheger.at/blog/2026/01/11/the-struggle-of-resizing-windows-on-macos-tahoe/)
**Score:** 2383 | **Comments:** 1002 | **ID:** 46579864

> **Article:** The article "The struggle of resizing windows on macOS Tahoe" argues that recent macOS updates (specifically referencing the "Tahoe" design language) have significantly degraded the user experience of window management. The author details issues like unresponsive resizing, a lack of visual feedback, and the removal of predictable window frame interactions. The core thesis is that Apple is prioritizing a "modern," iOS-inspired aesthetic over the functional, established conventions of the desktop interface, resulting in a "weird" and less usable operating system.
>
> **Discussion:** The Hacker News discussion is overwhelmingly critical of Apple's recent UI decisions, viewing the window resizing issues as a symptom of a larger problem. A recurring theme is the perception that Apple's designers, increasingly focused on mobile paradigms, are fundamentally misunderstanding or disrespecting the Mac's legacy desktop interface. This has led to a decline in usability, with many commenters comparing the new macOS experience negatively to the perceived jankiness of older Linux desktops or problematic Windows releases like Vista and 8.

While some users shared tips for hidden functionality (like Option-clicking corners), the general sentiment was that such obscure shortcuts are a poor substitute for intuitive design. The conversation also highlighted a divergence in user coping strategies: some have abandoned the mouse for keyboard-driven window managers, while others expressed a growing reluctance to upgrade their OS, with a few even suggesting this might be the push they need to switch to Linux.

---

## [Statement from Jerome Powell](https://www.federalreserve.gov/newsevents/speech/powell20260111a.htm)
**Score:** 751 | **Comments:** 636 | **ID:** 46582420

> **Article:** Federal Reserve Chair Jerome Powell delivered a statement addressing the fact that the Department of Justice (DOJ) has subpoenaed the Federal Reserve and threatened criminal indictment regarding the Fed's management of its physical headquarters. Powell characterized these actions as an "unprecedented" attempt to interfere with the central bank's independence. He emphasized that the Fed's decisions on interest rates and building renovations are made based on data and the public interest, not the preferences of the President. Powell stated that the Fed will not be intimidated and will continue to operate according to its statutory mandate, asserting that the independence of the central bank is essential for economic stability.
>
> **Discussion:** The Hacker News discussion expresses significant alarm and strong support for Jerome Powell, viewing the DOJ's actions as a dangerous political assault on the independence of the Federal Reserve. Commenters describe the situation as "crazy," "unprecedented," and a slide toward a "banana republic," arguing that the rule of law and institutional norms are being eroded.

The conversation frequently connects these events to the presidency of Donald Trump, with users characterizing the pressure as a dictator-like attempt to control monetary policy for personal or political gain. Many commenters fear that if the Fed loses its independence, interest rates will be set based on arbitrary presidential whims rather than economic data, likely leading to inflation and instability. Despite previous disagreements with Powell's economic policies, there is a consensus of respect for his courage in publicly resisting this pressure. The prevailing sentiment is one of concern that the checks and balances of the US government are failing.

---

## [CLI agents make self-hosting on a home server easier and fun](https://fulghum.io/self-hosting)
**Score:** 701 | **Comments:** 471 | **ID:** 46580326

> **Article:** The article argues that "CLI agents" like Anthropic's Claude Code, combined with affordable hardware and networking tools, are making self-hosting personal servers easier and more fun. It presents a modern stack for a home lab: inexpensive mini-PCs for hardware, Tailscale for secure remote access without exposing ports, and an AI coding assistant to handle complex Linux administration tasks. The author demonstrates this by using Claude Code to set up various services like Vaultwarden (a Bitwarden server), Jellyfin, and Home Assistant, effectively using the AI as a "slot machine cosplaying as a sysadmin" to bridge the skill gap for non-experts.
>
> **Discussion:** The discussion reveals a strong consensus that Tailscale is the most significant "unlock" for self-hosting, as it solves the primary security concern of exposing a home server to the internet, making it accessible from anywhere safely. While many agree that AI assistants like Claude Code are powerful and can dramatically speed up setup, some experienced users feel the core Linux skills are still essential and prefer to understand their systems rather than delegate to an AI. The conversation also touches on practical considerations like power consumption (debunking fears with examples of efficient hardware like Mac Minis) and security best practices (with some caution against hosting highly sensitive data like password managers on a home setup). A notable counterpoint is that the prevalence of AI in such articles is becoming tiring, but the overall sentiment is that the barrier to entry for creating a powerful "private cloud" has never been lower.

---

## [iCloud Photos Downloader](https://github.com/icloud-photos-downloader/icloud_photos_downloader)
**Score:** 591 | **Comments:** 223 | **ID:** 46578921

> **Article:** The article links to an open-source command-line tool called "iCloud Photos Downloader" on GitHub. The tool is designed to download all photos and videos from a user's iCloud account, addressing a need that the poster claims is not met by official Apple solutions. It provides a way for users to create a local backup of their entire iCloud photo library.
>
> **Discussion:** The discussion revolves around the difficulty of downloading large photo libraries from iCloud and the motivations behind it. A central debate is whether Apple intentionally makes this process difficult to discourage users from leaving its ecosystem. Several users argue that Apple does provide official methods, such as using the "Download and Keep Originals" option on Mac/iOS or the "Request to transfer a copy of your data" feature on privacy.apple.com, which can transfer photos to Google Photos or provide a data archive. However, other users counter that these official methods are often unreliable, with the Photos app crashing on large libraries, or are too slow, citing the "week or two" wait time for a data archive.

Beyond the debate, the comments offer practical solutions for users looking to back up or migrate their photos. These include using Apple's privacy portal for a GDPR-style data request, transferring directly to Google Photos, and using other tools like `ifuse` for local access. There is also significant interest in self-hosting solutions to gain full control over personal data, with users mentioning services like Immich for photo management. Finally, a notable side-thread highlights a potential security concern where the project's maintainer is seeking a successor, which could lead to a "hijack" of the repository if not handled carefully.

---

## [Statement by Federal Reserve Chair Jerome F. Powell [video]](https://www.youtube.com/watch?v=KckGHaBLSn4)
**Score:** 354 | **Comments:** 4 | **ID:** 46582441

> **Article:** The article is a YouTube video of a speech by Federal Reserve Chair Jerome F. Powell. The HN discussion notes that the official transcript and video are available on the Federal Reserve's website.
>
> **Discussion:** The discussion was brief and focused on the submission itself rather than the speech's content. Commenters identified the post as a duplicate of an existing thread. The primary suggestion was to update the link to point to the official Federal Reserve webpage, which contains both the video and a full text transcript, rather than directly to YouTube.

---

## [Anthropic: Developing a Claude Code competitor using Claude Code is banned](https://twitter.com/SIGKITTEN/status/2009697031422652461)
**Score:** 308 | **Comments:** 166 | **ID:** 46578701

> **Article:** A tweet from user SIGKITTEN alleges that Anthropic's Terms of Service (ToS) for its "Claude Code" product ban users from developing a competitor to Claude Code using the tool itself. The tweet quotes a ToS clause restricting the use of services to create competing products and contrasts it with a public statement from an Anthropic employee who claimed the company supports developers building on Claude via its API. This has sparked a debate about whether Anthropic is hypocritically using its ToS to stifle competition while publicly encouraging development on its platform.
>
> **Discussion:** The Hacker News discussion is highly critical of Anthropic's perceived stance, with the initial sentiment being one of outrage. Many commenters immediately framed this as a classic case of corporate hypocrisy, pointing out that AI companies built their models by scraping vast amounts of data from the internet (i.e., "breaking rules") and are now trying to create rules to protect their market position from upstarts. This was summarized by the sentiment that "he who has the most gold makes the rules."

However, the conversation quickly evolved into a more nuanced debate about the specifics of the ToS. Several users argued that the "outrage bait" was based on a misinterpretation. They contended that the restriction isn't about building a competing product *with* Claude's help, but about reverse-engineering Claude Code's specific API implementation or using the consumer "Max plan" OAuth as a substitute for the official, paid API. One user provided a screenshot suggesting that attempting to use the OAuth API for third-party tools results in an error, indicating it was never intended for that purpose.

A key counter-argument was that even if this is the intended interpretation, the ToS is written too broadly and could create a chilling effect, potentially alienating developers who fear future legal conflicts. Furthermore, some users argued that such a ToS is ultimately futile, as determined competitors with significant financial incentives could easily circumvent it. The discussion also touched on the competitive landscape, with some users noting that better alternatives like "opencode" exist and that Anthropic's "walled garden" approach might backfire, pushing users toward more open ecosystems with multiple model providers.

---

## [Floppy disks turn out to be the greatest TV remote for kids](https://blog.smartere.dk/2026/01/floppy-disks-the-best-tv-remote-for-kids/)
**Score:** 305 | **Comments:** 182 | **ID:** 46587934

> **Article:** The article proposes a clever hack to make modern TVs more kid-friendly by repurposing old floppy disks as physical TV remote controls. Instead of storing data, the floppy disks act as physical "keys" or tokens. A floppy drive connected to a computer (like a Raspberry Pi) is used to read a specific identifier from the inserted disk. This identifier triggers a script to play a specific movie or show. The system is designed to be simple and tactile, allowing children to select media by physically inserting a disk, bypassing the complex and often hostile user interfaces of modern streaming apps.
>
> **Discussion:** The Hacker News community reacted very positively to the idea, with many commenters expressing a desire to build similar systems for their children. A central theme was the shared frustration with the poor user experience of modern smart TVs, which are often slow, confusing, and filled with distracting ads, not only for kids but for older adults as well.

Several users shared their own DIY solutions or similar concepts:
*   **Alternatives to Floppies:** Many suggested using other physical media, such as RFID cards/stickers (similar to commercial products like Yoto Players and Tonies), NFC tags, or even burnable DVDs and CDs as "hooks" to trigger media playback.
*   **Commercial Products:** Commenters pointed out that commercial products like Yoto and Tonies already implement this concept for audio, validating the core idea of a screen-free, physical interface.
*   **Technical Implementation:** The discussion included technical details, such as using Arduino libraries to read floppy disks, the possibility of using the disk's serial number as a trigger, and creative ways to handle disk insertion detection.

The tone was largely nostalgic and creative, with users appreciating the tactile nature of the floppy disk and the cleverness of using it as a physical token rather than a storage medium. One commenter humorously noted the irony that this would make the "Save" icon even more confusing for a generation that has never seen a floppy disk.

---

## [Xfce is great](https://rubenerd.com/xfce-is-great/)
**Score:** 285 | **Comments:** 211 | **ID:** 46584173

> **Article:** The article "Xfce is great" is a short, enthusiastic endorsement of the Xfce desktop environment (DE). The author praises it for being lightweight, stable, fast, and unopinionated. They contrast this with modern DEs and commercial operating systems that they feel are bogged down by unnecessary UI changes, bloat, and "marketing-driven" design. The core message is that Xfce respects the user's time and intelligence by providing a simple, efficient, and highly customizable traditional desktop experience that "just works" and stays out of the way.
>
> **Discussion:** The Hacker News community largely agrees with the article's sentiment, with Xfce being praised for its speed, stability, and low resource usage. A recurring theme is the "perceived latency" or "click lag" of other modern desktops (including Windows, macOS, KDE, and Gnome), which many users feel is absent in Xfce, making it feel significantly more responsive even on powerful hardware. This responsiveness makes it a popular choice for older machines and for users who prioritize performance and a "no-BS" workflow.

However, the discussion also presents counterpoints. Some argue that Xfce's default appearance is dated and might be off-putting to new Linux users, who might be better served by more modern-looking DEs like Gnome or KDE. A technical debate emerged regarding Xfce's architecture, with one user arguing that its modular, X11-era design is an anti-pattern for the modern Wayland display server, potentially causing latency. This was met with a strong rebuttal from long-time users who value the flexibility of its modularity and find its performance more than sufficient.

Alternatives were also suggested, with LXQt and LXDE mentioned as even lighter-weight options. The conversation also touched on Xfce's customizability, with users sharing links to aesthetically pleasing "unixporn" setups to counter the "ugly" perception, and its utility in specific scenarios like VNC servers or for users with Nvidia GPUs due to its reliability.

---

## [Ozempic reduced grocery spending by an average of 5.3% in the US](https://news.cornell.edu/stories/2025/12/ozempic-changing-foods-americans-buy)
**Score:** 282 | **Comments:** 463 | **ID:** 46587536

> **Article:** A Cornell University study analyzing retail data found that US households using GLP-1 medications (like Ozempic) reduced their grocery spending by an average of 5.3% within six months of starting the drug. The spending reduction was even steeper for higher-income households (over 8%). This decrease was driven by significant drops in purchases of savory snacks (down ~10%), sweets, baked goods, and staples like bread and meat. Conversely, spending on yogurt, fresh fruit, nutrition bars, and meat snacks increased. The study notes that these changes in spending patterns tend to reverse if the medication is discontinued.
>
> **Discussion:** The discussion centered on several key themes regarding the study's implications and context. A primary point of clarification was that the 5.3% reduction applies only to households using the medication, not the entire US population, with many commenters finding the actual savings ($30-$100/month) to be modest relative to the drug's high cost.

Commenters debated the reasons behind the spending shifts. Some suggested that healthier foods like fresh fruit are often more expensive than processed snacks, so the savings came from eating less overall rather than substituting with cheaper healthy options. There was also speculation that increased yogurt purchases might be to counteract the drug's digestive side effects or to boost protein intake.

The conversation broadened to critique the US food environment, with many agreeing that the high adoption rate of these drugs highlights a systemic failure of processed foods in America compared to European standards. A notable counterpoint was introduced via a link to a Bloomberg article, suggesting that while grocery spending falls, GLP-1 users may actually spend more on dining out, potentially due to higher disposable income. Finally, commenters discussed the social stigma surrounding these drugs in Europe and speculated on the future conflict between the pharmaceutical and food industries.

---

## [This game is a single 13 KiB file that runs on Windows, Linux and in the Browser](https://iczelia.net/posts/snake-polyglot/)
**Score:** 275 | **Comments:** 71 | **ID:** 46580864

> **Article:** The article by Iczelia details the creation of a Snake game that is a single 13 KiB polyglot file. This file is simultaneously a valid DOS .COM executable, a Linux shell script, and an HTML file that runs in a browser. The author explains the technical trickery used to achieve this, such as using a shell script that is also a polyglot for the LZMA decompressor and embedding the game's logic and assets within comment blocks that are ignored by the different interpreters.
>
> **Discussion:** The Hacker News community reacted with admiration for the technical cleverness of the polyglot file. The discussion centered on a few key themes:

*   **Practicality and Compatibility:** Users tested the file across platforms, finding that while it worked, it required specific conditions. On Linux, it needed the `xz` package and was sometimes misidentified by Mono. On Windows, it required disabling Data Execution Prevention (DEP). The browser version simply worked after renaming the file to `.html`.
*   **Historical Context:** Commenters placed the achievement in a broader context. Some pointed to the EICAR.COM antivirus test file as an early example of a COM/plaintext polyglot. Others were reminded of demoscene classics like the 96k FPS *kkrieger*, which pushed the boundaries of what was possible in a small file size, and the original 128k *The Legend of Zelda*, which marveled at how much gameplay could be packed into a tiny amount of data.
*   **Modern Applications:** The idea of single-file, portable applications resonated with some developers. One commenter discussed their work on a serverless platform using single HTML files, while another noted the limitations of running such files from the `file://` protocol due to browser security restrictions (e.g., lack of access to many modern web APIs without HTTPS).

---

## [The next two years of software engineering](https://addyosmani.com/blog/next-two-years/)
**Score:** 270 | **Comments:** 302 | **ID:** 46580703

> **Article:** The article "The next two years of software engineering" by Addy Osmani (a Google engineer) argues that the role of software engineers is rapidly shifting from writing code to orchestrating AI. He predicts that AI will handle the bulk of boilerplate and implementation, while the human engineer's value will lie in high-level tasks: system design, problem decomposition, and prompt engineering. For junior developers specifically, Osmani advises against competing on volume of output. Instead, they should become "AI-proficient," using tools to amplify their productivity to match larger teams. He emphasizes the importance of understanding the generated code deeply and focusing on soft skills and domain knowledge, which AI cannot easily replicate. He also suggests that traditional CS degrees may need to evolve to include more practical AI and DevOps integration.
>
> **Discussion:** The Hacker News discussion is highly skeptical of the article, with many commenters viewing it as corporate propaganda or a misunderstanding of software engineering fundamentals.

A major theme is the skepticism regarding the author's identity as a Google employee working on Gemini. Many commenters dismissed the article as marketing disguised as analysis, suggesting it serves to promote AI tools rather than provide an objective outlook.

The debate over the value of junior developers was prominent. While the article suggested juniors must use AI to compete, several commenters argued that the hiring drop is due to executive cost-cutting, not a lack of junior capability. There was a strong counter-argument to the idea that "we are all juniors now." Commenters emphasized that seniority is defined by architectural taste, experience managing complexity, and the ability to avoid "entropy" in codebases—skills they argue LLMs currently degrade rather than enhance. The analogy was made that AI allows unskilled developers to move fast without the foundational training required to avoid crashes.

Finally, there was a distinction made between the hype of "vibe coding" and the reality of professional usage. Many developers described LLMs as a productivity booster (a "better Google") rather than a replacement for engineering logic. They argued that the article overestimates current AI capabilities, noting that while LLMs speed up coding, they struggle with context-specific trade-offs and complex architectural planning.

---

## [Meta announces nuclear energy projects](https://about.fb.com/news/2026/01/meta-nuclear-energy-projects-power-american-ai-leadership/)
**Score:** 264 | **Comments:** 319 | **ID:** 46578497

> **Article:** Meta has announced a series of projects to secure nuclear energy for its data centers, aiming to power its AI initiatives and ensure reliable, carbon-free electricity. The move is framed as a commitment to American energy leadership and sustainability, positioning Meta to meet its growing energy demands with a stable, large-scale power source.
>
> **Discussion:** The Hacker News discussion is highly skeptical of Meta's announcement, focusing on the company's motives and the economic realities of energy. The consensus is that this is a self-serving business decision to secure cheap, reliable power for its AI data centers, not a benevolent act for society.

Key points of debate include:

*   **Corporate Motives vs. Public Good:** Many commenters are cynical, arguing that Meta is simply securing a private resource for its own profit, which could drive up energy prices for the general public. The idea that this investment will trickle down to improve quality of life for others is heavily disputed.
*   **Nuclear vs. Renewables:** A major point of contention is whether nuclear is the right long-term investment. Proponents see it as a necessary, stable source of clean energy. However, critics argue that renewables (solar, wind) combined with battery storage are now cheaper and faster to deploy, making nuclear an economically inferior choice. They point to studies suggesting that nuclear is not required for a stable grid and that its high cost is a barrier.
*   **Economic Impact:** Commenters question whether this new generation capacity will actually lower electricity bills. The counter-argument is that the majority of a residential bill comes from distribution infrastructure, not generation costs, so consumers may not see a direct benefit.
*   **Meta's Competence:** Some users express doubt about Meta's ability to execute such a complex project, drawing parallels to other high-profile corporate failures, while others note that Meta is partnering with established power companies (like Vistra) to use existing facilities, not building new reactors from scratch.
*   **General Cynicism:** The discussion is peppered with broader criticisms of Meta, from its software quality to its role in society, with some commenters sarcastically linking the energy project to unrelated issues like poor customer service.

---

## [BYD's cheapest electric cars to have Lidar self-driving tech](https://thedriven.io/2026/01/11/byds-cheapest-electric-cars-to-have-lidar-self-driving-tech/)
**Score:** 222 | **Comments:** 285 | **ID:** 46579927

> **Article:** An article from "The Driven" reports that BYD is set to equip its cheapest electric vehicles, such as the Atto 1 (sold as the Seagull in China), with Lidar self-driving technology. This model is priced around AUD $24,000 in Australia and is a bestseller in its home market. The move is significant because it brings advanced driver-assist hardware to the budget EV segment, a space traditionally devoid of such features. The article frames this as a major competitive advantage for BYD and a challenge to Western automakers.
>
> **Discussion:** The Hacker News discussion is highly focused on the technological and economic implications of BYD's strategy, largely viewing it as a disruptive force.

A central theme is the debate between Lidar and camera-only (vision) systems for autonomous driving. Many commenters argue that BYD's move validates Lidar, especially as its cost has plummeted (reportedly by 40x), making it increasingly affordable. They contend that Elon Musk's decision to bet on a vision-only system for Tesla was "ill-timed" and that choosing vision over Lidar for cost reasons is now "insane." However, some users caution that these cost comparisons are often based on outdated figures and that the real-world economics are more complex.

The conversation also highlights the stark competitive gap between Chinese and Western automakers. Commenters assert that US manufacturers are "cooked" due to their inability to compete on price and technology. This is attributed to strong protectionist tariffs (100%+) imposed by the US government, which effectively block BYD from the market. A user notes that while BYD's cheapest EV sells for the equivalent of ~$16,600 USD, it would be a game-changer if available in the US.

Finally, there are discussions on practical and safety aspects. Some express concern over the aesthetics of roof-mounted Lidar sensors, though others compare it to the iPhone's "notch," suggesting consumers will adapt. A unique safety concern was raised about potential retinal damage to pedestrians from Lidar lasers, though this was met with skepticism. On the technical side, one user explained that training AI models with Lidar data is straightforward, as it can be collected during manual driving and used to create high-level environmental models.

---

## [Apple picks Google's Gemini to power Siri](https://www.cnbc.com/2026/01/12/apple-google-ai-siri-gemini.html)
**Score:** 219 | **Comments:** 163 | **ID:** 46589675

> **Article:** According to a CNBC report, Apple has selected Google's Gemini AI model to power a future version of Siri. This represents a major strategic shift for Apple, which has been internally developing its own AI models. The deal reportedly involves a custom-built Gemini model that will handle more complex, on-screen, and agentic tasks within Siri, moving beyond the current capabilities provided by the on-device models and the existing ChatGPT integration for specific queries. The move is seen as an acknowledgment of the immense cost and infrastructure required to build and train frontier-level AI models, a domain where Apple lags behind competitors like Google.
>
> **Discussion:** The Hacker News discussion is dominated by a mix of strategic analysis, skepticism, and surprise at the news. A central theme is the strategic rationale for the deal. Many commenters, like Fiveplus, argue that Apple is making a pragmatic choice to avoid the massive capital expenditure of building its own frontier models from scratch. Instead, Apple is leveraging its strength in hardware and user experience, effectively becoming the "last mile" delivery network for intelligence trained by others, like Google. This is framed as a smart move to let competitors burn cash on R&D while Apple focuses on integration and privacy-preserving inference on its own hardware.

The financial aspect is also a key point of discussion. Several users speculate that this deal is not a simple cash payment from Apple to Google, but rather an offset against the multi-billion dollar fees Google pays Apple to be the default search engine on its devices. This makes the partnership a financially efficient way for Apple to acquire top-tier AI capabilities.

There is significant surprise and criticism. Some users express dismay at outsourcing a core feature like Siri to a major competitor, questioning the long-term wisdom of relying on an external provider for such a critical part of the user experience. Others are simply surprised that Apple, a company known for its software prowess, is ceding this ground. A few commenters also express personal dissatisfaction with Siri's existing performance and privacy implications.

Finally, users clarify the context of Apple's other AI partnerships. It's noted that Apple already has a deal with OpenAI to integrate ChatGPT as an option within Siri. The consensus is that the Gemini deal will likely function similarly, offering another model choice for users, rather than a complete replacement of the existing ChatGPT integration.

---

## [FUSE is All You Need – Giving agents access to anything via filesystems](https://jakobemmerling.de/posts/fuse-is-all-you-need/)
**Score:** 195 | **Comments:** 67 | **ID:** 46580136

> **Article:** The article "FUSE is All You Need" proposes using FUSE (Filesystem in Userspace) to create a virtual filesystem that exposes non-file resources (like databases, APIs, or application data) to AI agents. The author argues that since LLMs are heavily trained on CLI operations and filesystem interactions, presenting data as files is a more intuitive and powerful interface than building custom tools. This approach allows agents to use standard utilities (`ls`, `grep`, `cat`, etc.) to interact with complex data sources without needing to learn new APIs. The article suggests this method bridges the gap between an application's internal data representation and the agent's operational environment, making it easier to integrate agents into existing systems.
>
> **Discussion:** The Hacker News discussion presents a polarized debate on the practicality of using FUSE for AI agents. The core tension is between the elegance of the filesystem abstraction and the performance and architectural limitations of mapping non-file data to files.

Several users expressed strong skepticism. The top comment argues that giving agents access via standard database views and permissions is superior to adding a "layer of indirection for indirection's sake." Another user detailed a negative personal experience, stating they implemented a similar system and ultimately "ditched it because, well it sucks," citing the inefficiency of operations like `grep` which would trigger numerous slow API calls instead of using a database's native indexing. A separate thread criticized the article's casual use of the term "sandbox," arguing that the described setup is not a secure context.

Conversely, many commenters were enthusiastic about the concept. One user mentioned they've implemented a similar framework for their employer, unlocking "absolutely bonkers capabilities." Another provided a detailed example of their project, Filestash, which uses a virtual filesystem to expose dozens of systems (SQL, LDAP, cloud storage) as files and makes them available to agents via MCP. The discussion also included technical alternatives and context, with users pointing to the 9P protocol (from Plan 9) as a potentially better network-first solution and noting that LLMs actually "excel at SQL," challenging the premise that filesystems are the most intuitive interface.

---

## [Sampling at negative temperature](https://cavendishlabs.org/blog/negative-temperature/)
**Score:** 195 | **Comments:** 56 | **ID:** 46579374

> **Article:** The article from Cavendish Labs explores the concept of "negative temperature" in the context of Large Language Model (LLM) sampling. It explains that the standard softmax function used to convert model logits into probabilities can be generalized to include negative values for the temperature parameter (T). While positive T > 1 increases randomness (diversity) and T < 1 makes the distribution sharper (more deterministic), T = 0 represents perfect determinism (selecting the most likely token). The article demonstrates that as T approaches 0 from the negative side, the sampling becomes deterministic but selects the *least* likely tokens. The author shows that this produces "anomalous" tokens that are often nonsensical or located near the centroid of the model's embedding space, effectively representing the model's "opposite" of high-probability outputs.
>
> **Discussion:** The Hacker News discussion was largely positive, with users appreciating the article's clear explanation and creative approach. Key themes included:

*   **Clarifications on Physics vs. ML:** Several users with backgrounds in physics (specifically thermodynamics and molecular dynamics) clarified the analogy. While negative temperature is a real physical phenomenon (e.g., in spin systems where adding energy reduces entropy), they noted that in LLMs, it's primarily a mathematical extension of the sampling function. The core concept of "inverting" the probability distribution was the main takeaway.
*   **Practical Implications and Limitations:** Commenters debated the utility of negative temperature. The author of the "min_p" sampling method argued that the field misunderstands temperature and that exploring these extremes is valuable. However, others questioned if the output is meaningful, with one user suggesting the "least likely" tokens might just be numerical noise rather than coherent opposites. The author of the article responded that these tokens are indeed "worse than random" and nonsensical.
*   **Future Research Ideas:** Users proposed several follow-up experiments, such as dynamically adjusting temperature during generation, using negative temperature to create high-variance synthetic data for training, or even training a new model on text generated with negative temperature to see if it produces anything meaningful.
*   **Related Concepts:** The discussion also touched on "unlikelihood training" (a past research idea to train models to avoid common errors) and the potential for "laser-LLMs," drawing a parallel to population inversion in physics.

---

## [TimeCapsuleLLM: LLM trained only on data from 1800-1875](https://github.com/haykgrigo3/TimeCapsuleLLM)
**Score:** 176 | **Comments:** 72 | **ID:** 46590280

> **Article:** The article links to a GitHub repository for "TimeCapsuleLLM," a project featuring a Large Language Model trained exclusively on historical data from 1800 to 1875. The project's goal is to create an AI that reflects the knowledge, language, and worldview of the mid-19th century, effectively acting as a "time capsule" of that era's information.
>
> **Discussion:** The Hacker News discussion centered on the philosophical and practical implications of the project. The most prominent theme was using the model as a test for the creative and reasoning capabilities of LLMs. Commenters debated whether such a model, lacking any knowledge of modern science, could independently reason its way to discoveries like relativity or quantum mechanics. The consensus was that while it might combine existing concepts, it could not discover phenomena that require experimental data not available in its training set.

A second major theme was the model's potential as a historical tool. Users were intrigued by the idea of using it to gain insight into the past, though one commenter cynically noted this was essentially "reinventing the history book" with higher energy consumption and less accuracy. There was also curiosity about how the model would perform on modern benchmarks if its training data were restricted to a specific time period.

On a practical level, there was significant interest in how to easily run the model. Multiple users asked for a low-friction way to use it, such as through a hosted API or a pre-quantized build for popular local inference engines like Ollama or llama.cpp. A technical comment clarified that the model's architecture (nanoGPT and Phi 1.5) should make it easy to run on consumer hardware. Finally, a user provided a humorous example of the model's output, which resembled a nonsensical Markov chain, prompting a discussion on whether the model's limited training data resulted in lower-quality or more primitive-seeming text generation.

---

## [I'd tell you a UDP joke…](https://www.codepuns.com/post/805294580859879424/i-would-tell-you-a-udp-joke-but-you-might-not-get)
**Score:** 175 | **Comments:** 46 | **ID:** 46580946

> **Article:** The article is a link to a post on the website "codepuns.com" that presents a classic computer networking pun. The joke plays on the properties of the User Datagram Protocol (UDP), which is known for being an unreliable, connectionless protocol that does not guarantee message delivery. The joke is: "I'd tell you a UDP joke, but you might not get it."
>
> **Discussion:** The Hacker News discussion is a lighthearted and creative thread where users build upon the original UDP joke by creating more puns based on other networking protocols. The conversation quickly expands from the initial joke into a collaborative "punning" session.

Key themes in the discussion include:
*   **Protocol-based Puns:** Users create jokes for other protocols. For ICMP, one user offers a "Knock Knock" joke that ends with "Who's there? - Thank you," playing on the nature of ICMP requests and replies. Another adds a ping joke, and a third extends it with a "TTL" (Time To Live) pun.
*   **Jokes about UDP's Nature:** The core theme of unreliability is explored further. A user posts the joke "packets udp bar walk a into," which is a jumbled sentence representing out-of-order delivery. Another user comments that their brain automatically reassembled it, highlighting the psychological aspect of the joke.
*   **Expanding the Genre:** The thread broadens to include other programming and tech humor formats, such as "facts" about Jon Skeet, Chuck Norris, and Bruce Schneier, and references to other classic tech jokes like "10 kinds of people."
*   **Meta-Humor:** Some users contribute jokes that are themselves "broken" or out of order, directly mimicking the unreliable nature of UDP.

Overall, the discussion is a classic example of an HN community in-joke, where a simple prompt sparks a chain of clever, related humor from a technically knowledgeable audience.

---

## [LLVM: The bad parts](https://www.npopov.com/2026/01/11/LLVM-The-bad-parts.html)
**Score:** 167 | **Comments:** 22 | **ID:** 46588837

> **Article:** The article "LLVM: The bad parts" by Nikita Popov critically examines the practical challenges and architectural shortcomings of the LLVM compiler infrastructure. Despite its success and ubiquity, LLVM has significant issues that affect its users and developers.

Key problems identified include:
*   **Compilation Speed:** LLVM is notoriously slow, both in debug and release builds, which negatively impacts developer productivity. This is a regression from its original goal of being faster than GCC.
*   **Complexity and Instability:** The internal APIs are complex and frequently change between versions, making it difficult for downstream projects to maintain their passes and tools. The sheer size and complexity of the codebase make it nearly impossible to audit.
*   **Optimization Bugs:** The optimizer is a source of subtle and hard-to-diagnose bugs. The article provides a specific example related to Loop Invariant Code Motion (LICM) creating register pressure, which can paradoxically de-optimize code.
*   **Poor Documentation:** Key subsystems, particularly the backend components like SelectionDAG, are poorly documented. Developers are often forced to reverse-engineer the source code to understand the precise semantics of operations.
*   **Organizational Issues:** The review process can be inconsistent, and there is a lack of comprehensive, IR-level test suites, making it risky to develop custom backends or modify core components.

The author concludes that while LLVM is an incredible piece of engineering, these "bad parts" represent significant, ongoing costs for the entire software ecosystem that relies on it.
>
> **Discussion:** The Hacker News discussion largely validates the article's points, with many commenters sharing their own frustrations and experiences with LLVM. The conversation centers on a few key themes:

*   **Compilation Time and Tooling:** Several users echo the article's complaint about slow compilation speeds. One commenter highlights this as a major reason Go chose its own compiler toolchain over LLVM, which contributes to Go's faster build times. The slowness is a significant pain point for developers, especially in large projects like Rust.

*   **The Paradox of "Safe" Languages on Unsafe Infrastructure:** A prominent theme is the irony that "safe" languages like Rust are built on top of a massive, complex, and unauditable compiler like LLVM. This raises questions about the end-to-end security and reliability of such systems. However, others point out that the Rust project actively contributes back to LLVM, fixing bugs that benefit the entire ecosystem (including C/C++).

*   **Specific Technical Failures:** Commenters drill into the technical problems mentioned. The issue of register pressure from LICM is debated, with some suggesting it's a register allocator problem that needs better rematerialization capabilities, while others note the backend has limited visibility to fix these issues. The lack of documentation for backend components like SelectionDAG is strongly agreed upon, making it a major hurdle for anyone trying to work on it.

*   **Potential Solutions and Future Outlook:** The discussion includes some suggestions for improvement. One user proposes creating a comprehensive executable test suite starting from LLVM IR to stabilize backend development. Another suggests exposing more "knobs and levers" for frontend writers to tune optimization passes. There's also a sense that LLVM's age and accumulated complexity might eventually lead to a new, simpler tool replacing it, just as LLVM once challenged GCC.

Overall, the community sentiment aligns with the article's critical stance, viewing LLVM as a powerful but deeply flawed piece of software whose problems are a significant and persistent burden on the industry.

---

## [Uncrossy](https://uncrossy.com/)
**Score:** 162 | **Comments:** 43 | **ID:** 46582762

> **Article:** Uncrossy is a web-based puzzle game where the objective is to untangle a set of overlapping words. The core mechanic involves selecting a word and moving it to an empty space, which causes the letters in the original word to change to match the new location. The goal is to make all words disappear by strategically moving and transforming them. The game features a clean interface, a tutorial, and a hint system that can reveal the number of steps needed to backtrack to a mistake.
>
> **Discussion:** The HN community's reaction to Uncrossy is overwhelmingly positive, with many commenters praising it as a fun, clever, and well-executed game with a simple-to-understand concept. The discussion highlights several key points:

*   **Gameplay and Mechanics:** Users appreciate the clever mechanic where moving a word changes the letters of the word it leaves behind, creating a non-obvious puzzle dynamic. The undo/redo functionality is also highly valued.

*   **Unsolvable States:** A significant point of feedback is the frustration of accidentally reaching an unwinnable state without clear notification. Several users suggested improvements, such as an early warning system, a "safe mode" that prevents such moves, or a more helpful hint system to guide players out of dead ends.

*   **Technical and UX Feedback:** A user reported a bug in Firefox related to the use of `const` in the global scope, which was confirmed by another user due to an ad-blocker. There was also a minor note about an easy way to "cheat" using specific mouse actions. One commenter drew a parallel between the game's development philosophy and the concept of treating an LLM as a non-deterministic compiler, which sparked a brief sub-discussion on the viability of that approach for software maintenance.

---

