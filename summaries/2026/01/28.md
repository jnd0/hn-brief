# Hacker News Summary - 2026-01-28

## [TikTok users can't upload anti-ICE videos. The company blames tech issues](https://www.cnn.com/2026/01/26/tech/tiktok-ice-censorship-glitch-cec)
**Score:** 1368 | **Comments:** 887 | **ID:** 46779809

> **Article:** CNN reports that TikTok users are experiencing difficulties uploading videos critical of ICE (Immigration and Customs Enforcement), with the company attributing the problem to technical glitches. The timing is notable as it follows the forced sale of TikTok's US operations to American owners amid ongoing concerns about the platform's relationship with Chinese parent company ByteDance and potential government influence over content moderation.
>
> **Discussion:** The Hacker News discussion rapidly expanded beyond the specific TikTok/ICE incident into broader debates about platform censorship, geopolitical propaganda, and democratic backsliding.

**Censorship and "Technical Difficulties"**
Several commenters drew historical parallels to state media manipulation. One user recounted their father in 1989 Czechoslovakia immediately recognizing "camera broke down" as cover for hiding police violence against protesters—treating TikTok's "tech issues" with similar skepticism. Eastern European participants expressed particular alarm, with one noting nostalgic familiarity with these tactics and concern that the US is "on a fast track" toward authoritarian patterns.

**The TikTok Sale and Information Control**
The forced US-hosted sale was framed by some as an attempt to restrict Americans' access to international perspectives rather than protect them. However, others countered that TikTok's global algorithm itself represents selective information control—promoting critical content about Western governments while filtering out topics like Tiananmen Square, suggesting "the most brutally honest propaganda is always the most effective."

**Accelerating Platform Manipulation**
Users reported sudden algorithm changes coinciding with the ownership transition, including complete resets of personalized feeds and alleged blocking of terms like "Epstein" in direct messages. One commenter termed this rapid transformation "Orbanisation," referencing Hungary's media consolidation under Viktor Orbán.

**Political Hypocrisy and Escalation**
The discussion highlighted perceived double standards in how censorship tools developed for one purpose get repurposed. Several commenters warned that weapons built against "currently designated bad people" inevitably turn against their creators. The observation that "once the tables turn, it will be your turn" appeared repeatedly, with participants noting how recent years saw progressive causes justify content moderation that conservatives now appear ready to exploit.

**Platform Alternatives**
Brief mention was made of potential migration to alternatives like "upscroll," though participants expressed skepticism that any replacement could escape similar capture, given how TikTok's algorithm itself proved the decisive competitive advantage rather than mere format features.

---

## [FBI is investigating Minnesota Signal chats tracking ICE](https://www.nbcnews.com/tech/internet/fbi-investigating-minnesota-signal-minneapolis-group-ice-patel-kash-rcna256041)
**Score:** 746 | **Comments:** 1006 | **ID:** 46783254

> **Article:** The FBI is investigating Minnesota-based Signal group chats used by activists to track ICE (Immigration and Customs Enforcement) activities. The investigation focuses on whether protesters are using these encrypted chats to coordinate interference with immigration enforcement operations. According to reports, the investigation involves concerns about potentially unlawful activities including license plate scanning that may suggest insider assistance. The case highlights tensions between protected speech, surveillance capabilities, and government investigations into activist organizing.
>
> **Discussion:** The HN discussion revolves around several interconnected themes: the boundaries of constitutional protection for activist organizing, the technical vulnerabilities of Signal despite its encryption, and broader concerns about escalating government surveillance and authoritarian tactics.

A central debate emerged around whether this investigation represents an overreach against protected speech or legitimate law enforcement. Commenter bediger4000 framed it as "unequivocally constitutionally protected speech," but tptacek countered that while prosecution requires high standards, investigations face minimal constraints—especially when built on existing data from arrests and confidential informants. Randallsquared noted that conspiracy to commit crimes falls outside speech protections, with interpretations largely depending on political perspective.

The technical discussion focused on Signal's metadata vulnerabilities. Multiple commenters traced how phone numbers—Signal's required identifier—enable a chain of compromise: identifying the owner, compelling device unlock, and potentially exposing entire group chats. This validated long-standing criticisms that Signal's phone number requirement creates serious privacy risks. Disappearing messages and passcode protections were discussed as partial mitigations, though SR2Z suggested social engineering (turning group members against each other) represents the more likely attack vector than technical decryption.

Several commenters contextualized this within apparent government contradictions: fudged71 noted the paradox of Palantir's "advanced data algorithms" coexisting with seemingly indiscriminate ICE raids, suggesting the contradiction itself warrants public scrutiny. Crystal_revenge offered a skeptical counterweight, arguing Palantir likely overpromises like typical tech startups and that government incompetence may ironically protect against dystopia—though Eupolemos pushed back, citing Snowden's revelations that reality exceeded imagined surveillance capabilities.

The discussion took a transnational turn when amarant, a European commenter, asked whether conditions match their perception of deteriorating democratic norms and questioned why Second Amendment advocates weren't resisting state overreach. Idle_zealot responded that such resistance was always more theoretical than practical, and that constitutional safeguards have systematically eroded despite founders' intentions. Empact sharply rebutted that Europeans face their own speech restrictions, arguing deportation enforcement differs fundamentally from oppression.

The thread concluded with darker observations: epistasis highlighted DoJ attorneys resigning after being blocked from investigating ICE shootings, instead directed to investigate victims' families; chinathrow and hollandheese offered blunt assessments of law enforcement's institutional alignment with power rather than public protection. Mw888's straightforward summary—that the FBI "simply joined groupchats"—belied the deeper anxiety pervading the discussion about what such "simple" investigations portend for civil liberties.

---

## [Prism](https://openai.com/index/introducing-prism)
**Score:** 648 | **Comments:** 369 | **ID:** 46783752

> **Article:** OpenAI has launched **Prism**, a new AI-powered tool for creating scientific and academic documents. It appears to be a LaTeX-based writing environment with integrated AI assistance for tasks like finding and citing relevant papers, generating content, and formatting documents. The tool is positioned as a free alternative to existing platforms like Overleaf, with AI features deeply embedded into the workflow.
>
> **Discussion:** Discussion unavailable.

---

## [U.S. government has lost more than 10k STEM PhDs since Trump took office](https://www.science.org/content/article/u-s-government-has-lost-more-10-000-stem-ph-d-s-trump-took-office)
**Score:** 518 | **Comments:** 367 | **ID:** 46784263

> **Article:** A Science.org article reports that the U.S. government has lost more than 10,000 STEM PhD employees since Trump took office, representing a significant brain drain from federal agencies. The article likely connects this exodus to policy changes including research funding cuts, hostile immigration policies toward foreign researchers, and broader anti-intellectual trends in the administration. The NSF budget was reportedly targeted for a 55% cut (though this remains proposed, not enacted), and international scientific collaborations have been severely disrupted.
>
> **Discussion:** The HN discussion reveals deep concern about the damage to American scientific capacity, with commenters debating whether this exodus represents necessary reform or catastrophic self-sabotage.

**The "quality control" argument and its rebuttal**

JuniperMesos provoked strong reactions by questioning whether losing 10,000 STEM PhDs is inherently bad, arguing that academia produces much low-quality research and credentials don't guarantee value. Ixtli forcefully countered that there's no evidence the *least* productive researchers are leaving—if anything, the most mobile and talented would depart first. Several commenters noted that this framing ignores the structural reality: funding cuts and hostile policies aren't selectively filtering for quality, they're indiscriminately driving away talent.

**International perspective: the void being filled by China**

Multiple European researchers (adev_, retired) emphasized that collapsed US-EU collaborations are creating a vacuum that China is aggressively filling. Adev_ observed 10x growth in China-hosted conferences and joint projects, noting that "science hates void"—researchers need funding and partners, and China now offers both. This represents a strategic gift to America's perceived rival, with one commenter dryly "congratulating" the Trump administration for fueling Chinese technological advancement.

**Irreversible reputational damage**

Several outsiders (detritus, Insanity, kevinsync) stressed that trust, once broken, won't easily rebuild. Even a future policy reversal faces the "bouncer who beat you" problem—why return to a country that demonstrated hostility? Insanity noted that Trump's re-election suggests this isn't a fluke but a pattern, making long-term alliances risky for partners who fear the next electoral cycle.

**Structural and philosophical divides**

CharlieDigital introduced a compelling framing from Freakonomics: China is "run by engineers" (builders), America by lawyers (arguers/obstructors). This cultural distinction, several suggested, explains why the US tolerates or celebrates dismantling its own research infrastructure. The engineering mindset builds systems; the lawyerly mindset litigates and deconstructs them.

**Broader Western decline**

The discussion expanded to parallel crises in Europe, particularly the Netherlands, where engineers report being "priced out" and PhD positions disappearing. Retired engineers expressed pessimism about Western Europe's ability to sustain its social systems amid simultaneous brain and wealth drain. Ixtli cited data showing China graduating 1.3 million engineers annually—orders of magnitude beyond US production adjusted for population—suggesting a historic rebalancing of global technical capacity.

The consensus among most participants: this isn't pruning dead wood or efficient reallocation, but unilateral disarmament in scientific competitiveness, with consequences that will persist for decades regardless of future political changes.

---

## [Cloudflare claimed they implemented Matrix on Cloudflare workers. They didn't](https://tech.lgbt/@JadedBlueEyes/115967791152135761)
**Score:** 513 | **Comments:** 192 | **ID:** 46781516

> **Article:** A Mastodon post by JadedBlueEyes claims that Cloudflare falsely claimed to have implemented Matrix (the decentralized chat protocol) on Cloudflare Workers. The accusation centers on a Cloudflare blog post and associated GitHub repository by a Cloudflare employee that purported to demonstrate a production-grade Matrix homeserver running entirely on Workers. Critics found the implementation to be incomplete, AI-generated "vibe code" that was misrepresented as thoroughly engineered and production-ready. The repository showed signs of minimal effort—only two commits, removal of TODO comments labeled as "cleaning up code comments," and claims later revealed to be exaggerated. Cloudflare has since edited the blog post multiple times, first adding a "proof of concept" disclaimer, then removing claims about production use, and finally framing it as a personal experiment seeking contributions.
>
> **Discussion:** The HN discussion quickly centers on credibility and pattern recognition. Commenters note this fits a broader trend of AI-assisted projects being misrepresented as rigorously engineered—drawing direct parallels to the recently debunked Cursor "browser built from scratch" story and Cloudflare's own OAuth library, which was marketed as "thoroughly reviewed by security experts" but later had a significant vulnerability disclosed.

The technical critique of the Matrix implementation is damning: only two GitHub commits, TODO comments removed and described as "code cleanup," and fundamental architectural questions about the networking implementation. The author—identified as a Senior Engineering TPM at Cloudflare, not a software engineer—appears to have limited Git experience, having amended commit messages to obscure the TODO removal. The repository has since seen damage-control commits removing "production grade" claims and adding AI assistance disclosures.

Several themes emerge. First, skepticism toward corporate engineering blogs that blend marketing with technical credibility—what one commenter calls the erosion of trust when "we did X" becomes "we prototyped a demo of part of X." Second, concern about organizational processes: how did this pass review at a company where leadership reportedly reviews every blog post? Third, the "vibe coding" phenomenon and its risks when non-engineers or overconfident practitioners mistake AI-generated code for production software.

The discussion also includes a notable counter-example: embedding-shape's Show HN demonstrating that one developer with one AI agent could build a functional (if limited) browser in 20K lines of Rust, suggesting that impressive AI-assisted engineering is possible—but requires honest scoping and genuine technical skill, not marketing embellishment.

Underlying much of the thread is anxiety about Cloudflare's reliability and culture. Multiple commenters note recent incidents (the OAuth vulnerability, previous outages) and wonder if AI-assisted corner-cutting is becoming systemic at a critical infrastructure provider. The charitable interpretation—that an individual published without proper review—still raises questions about organizational controls. The less charitable one suggests deeper problems with technical judgment and accountability.

---

## [430k-year-old well-preserved wooden tools are the oldest ever found](https://www.nytimes.com/2026/01/26/science/archaeology-neanderthals-tools.html)
**Score:** 422 | **Comments:** 219 | **ID:** 46781530

> **Article:** Archaeologists have discovered the oldest known wooden tools ever found, dating back approximately 430,000 years. The well-preserved artifacts were likely crafted by Neanderthals or their immediate ancestors at a site in northern Europe. This finding pushes back the timeline for sophisticated woodworking by hominins and provides rare physical evidence of organic tool use from the Middle Pleistocene period, as wood typically decomposes and rarely survives from such ancient contexts.
>
> **Discussion:** The HN discussion began with surprise at the 430,000-year age of the tools, with user drakythe initially questioning whether this predated *Homo sapiens* entirely. Several commenters clarified that tool use long predates our species—stone tools like the Oldowan industry stretch back 2-3 million years, and indirect evidence of woodworking exists from 1.5 million years ago. The significance of this find lies in the exceptional preservation of wooden artifacts, which usually decay completely.

The conversation took several interesting turns. JumpCrisscross introduced a darker anthropological angle, citing Jane Goodall's observation that humans, chimpanzees, and wolves share a "genocidal tendency" toward exterminating rival groups rather than merely displacing them, and speculated this trait may have helped *Homo sapiens* outcompete other hominids who were more tolerant of coexistence. This prompted both fascination and pushback, with crazygringo arguing that genocide is historically exceptional rather than normative in human conflict.

A more contentious thread emerged when an0malous promoted Michael Cremo's "Forbidden Archaeology," suggesting evidence of million-year-old tools is systematically suppressed by scientific dogma. This drew skeptical responses—drakythe noted Cremo's questionable reputation, while 3RTB297 offered a nuanced defense about institutional incentives favoring incremental over revolutionary findings, citing historical examples like plate tectonics and warm-blooded dinosaurs. However, mmooss pushed back hard, noting that archaeology already accepts tool use from 2.5+ million years ago, making the "suppression" claim factually dubious.

Finally, melenaboija reflected on wood's remarkable durability under proper conditions, reconsidering the common European dismissal of American wooden construction in favor of concrete—especially given concrete's environmental costs and structural limitations (particularly rebar corrosion, as barbacoa noted, unlike enduring Roman unreinforced concrete).

---

## [I made my own Git](https://tonystr.net/blog/git_immitation)
**Score:** 356 | **Comments:** 163 | **ID:** 46778341

> **Article:** The author (TonyStr) built a simplified Git clone from scratch in Rust as a learning exercise, documenting the implementation process in a detailed technical blog post. The project, called "tvc" (Tony's Version Control), implements core Git concepts including blob/tree/commit object storage, content-addressable storage using SHA-256, delta compression with zstd, and basic commands like init, add, commit, and log. The author walks through design decisions such as choosing YAML over TOML for object serialization (despite being a Rust project), handling file parsing challenges, and implementing a simple key-value store for object storage. The implementation is intentionally minimal and educational rather than production-ready, with acknowledged performance limitations like recomputing hashes for all files on every status check.
>
> **Discussion:** The HN discussion branched into several interconnected themes. A significant thread emerged around AI training data, sparked when the author noted that their repository had been cloned 49 times by 28 unique users *before* they published the article—strong evidence of automated scraping for LLM training. This led to darkly humorous suggestions about "poisoning" training data with self-referential loops and deliberate bugs, alongside more practical observations that even self-hosted Gitea instances get crawled by AI bots.

The technical discussion around version control design proved equally rich. One commenter highlighted Git's underappreciated recursive merge strategy as superior to rebase workflows, noting it inherently remembers conflict resolutions without requiring `rerere` (which only caches locally). This prompted comparisons to Pijul, which treats conflicts as first-class repository objects, and Fossil, which uses SQLite for storage—though notably *not* for its object format, which remains plaintext for long-term durability. Several participants endorsed Fossil's local-first philosophy and integrated wiki/issue tracking, though acknowledged Git's ecosystem dominance makes adoption difficult.

Performance and architectural choices drew scrutiny. The author's approach of recomputing all file hashes triggered discussion about Git's optimizations (timestamp checking, two-letter directory sharding) and hash algorithm selection. BLAKE3 was suggested as faster than SHA-256 on x86, though countered that ARM64's native SHA-256 instructions reverse this advantage. A deeper architectural point emerged: Git's file-as-single-object model is primitive compared to content-defined chunking approaches that would enable better deduplication and parallelization.

The perennial HN debate about Git alternatives surfaced with mentions of Jujutsu (jj), while others argued new VCSes should innovate atop Git's storage layer for compatibility. The author's choice of YAML over TOML—despite being a Rust project—prompted mild curiosity, with the defense that machine-generated formats matter less to users than human-readable output flags.

Throughout, the author engaged substantively, clarifying that while they use LLMs for coding conventions and research suggestions, the article itself contains no generated text—adding a meta-layer to the training-data discussion given the article's instructional nature for exactly the kind of systematic problem-solving that coding agents learn from.

---

## [Thief of $90M in seized U.S.-controlled crypto is gov't contractor's son](https://www.web3isgoinggreat.com/single/lick-theft)
**Score:** 327 | **Comments:** 65 | **ID:** 46787521

> **Article:** A government contractor's son allegedly stole $90 million in cryptocurrency that was under U.S. government control. The crypto assets were seized by law enforcement and being managed by the father's company under contract with the U.S. Marshals Service. The thief, identified as Zach Lick, was caught after publicly flaunting his wealth through livestreams showing expensive watch purchases and openly taunting investigators—sending small amounts of Ethereum from the fraudulent wallets to law enforcement officials. Despite the brazen nature of the theft and public evidence, the government reportedly failed to acknowledge the theft occurred until after Lick's posts went viral, and significant questions remain about whether any consequences will follow.
>
> **Discussion:** The HN discussion reveals deep cynicism about government competence and institutional corruption. Commenters quickly established the basic facts: the son of a contractor managing U.S. Marshals crypto holdings stole seized assets, then essentially self-reported through conspicuous consumption and direct provocation of investigators. The community found dark humor in the incompetence on all sides—both the government's failure to secure the assets and the thief's inability to resist showing off.

Several themes dominated the conversation. First, widespread pessimism about accountability: multiple commenters suggested political connections might shield the family from consequences, with references to pardon markets and super PAC donations reflecting a belief that justice is increasingly transactional. One user noted that Trevor Milton's pardon after a $2 million donation establishes a troubling price point for impunity.

Second, the incident fueled broader critiques of institutional decay. Comparisons to Watergate suggested such scandals now barely register, while others argued corruption has always existed and what's changed is merely visibility. Some commenters traced specific blame to current political leadership; others pushed back, noting the theft occurred in October 2024 under the previous administration.

Third, practical questions about seized crypto management arose, with users sharing personal experiences of losing assets to government raids and debating whether holdings become "strategic reserves" or get liquidated. The discussion also touched on whether the father was complicit—opinions varied, though the circumstantial evidence of sudden family wealth drew suspicion.

Finally, the story's absurdity generated dark comedy, from sarcastic offers to accept bribes to observations that this represents "fascist incompetence" in action. The consensus: a perfect crime undone by ego, enabled by institutional failure, and quite possibly destined for inconsequential resolution.

---

## [Xfwl4 – The Roadmap for a Xfce Wayland Compositor](https://alexxcons.github.io/blogpost_15.html)
**Score:** 319 | **Comments:** 239 | **ID:** 46779645

> **Article:** The article outlines the roadmap for Xfwl4, a new Wayland compositor for the XFCE desktop environment. It represents a significant architectural shift from the existing X11-based xfwm4 window manager. The project is being written in Rust using the Smithay library, with the explicit goal of maintaining feature and behavioral parity with xfwm4 while transitioning to modern Wayland protocols. The roadmap covers implementation phases including core compositor functionality, XWayland integration for legacy application support, and gradual adoption of XFCE-specific features and configurations.
>
> **Discussion:** The Hacker News discussion centers on whether XFCE's traditionally conservative userbase will accept both Wayland and Rust, with opinions divided. Long-time XFCE user coldpie pushes back against the stereotype of inflexible traditionalists, arguing that users primarily want stability and that resistance to change fades when transitions are handled well—comparing X11 holdouts to SysV-init diehards as a vocal minority.

The technical debate intensifies around Wayland's merits. ok123456 delivers a scathing critique, calling Wayland a "regression" and "past compromise" after 16 years of development, citing missing features, fragmentation, and workarounds that violate the "it's just a protocol" mantra. They compare it unfavorably to X400 versus SMTP, suggesting a cleaner successor may eventually emerge.

jchw offers a detailed counterargument, defending Wayland's protocol-centric design as necessary to avoid X11's ossification. They highlight genuine improvements in DPI scaling, HDR, multi-head setups, and laptop docking experiences, while acknowledging the pain points: the deliberate elimination of global coordinate spaces breaks some application patterns, and protocol development moves glacially due to design-by-committee processes (citing a 5-year color management protocol as example). They note that XWayland preserves compatibility for reluctant applications, and that modern compositors increasingly use hardware planes to reduce latency overhead.

Fiveplus raises specific concerns about behavioral fidelity—particularly focus-stealing prevention heuristics that must be reimagined under Wayland's stricter compositor-authority model—and raw performance on low-end hardware where xfwm4's optional uncomposited mode historically excelled. jchw concedes that some latency increase is inevitable with mandatory compositing, though aggressive plane unredirection and higher refresh rates mitigate this. They acknowledge this leaves 60Hz laptop users with permanent minor latency penalties, framing it as an acceptable tradeoff for compositor benefits that the market has broadly accepted.

The performance discussion concludes with PunchyHamster's blunt dismissal that Wayland "has been consistently slower than X11" with no workaround possible—a claim left uncontested in the visible thread.

---

## [Lennart Poettering, Christian Brauner founded a new company](https://amutable.com/about)
**Score:** 299 | **Comments:** 434 | **ID:** 46784572

> **Article:** Lennart Poettering (creator of systemd) and Christian Brauner have founded a new company called Amutable. According to their website, they are "building cryptographically verifiable integrity into Linux systems" with the goal that "every system starts in a verified state and stays trusted over time." The founding team includes several engineers with backgrounds in systemd and Microsoft. The company appears focused on remote attestation and secure boot technologies for Linux.
>
> **Discussion:** The Hacker News discussion reveals deep skepticism and concern about Amutable's mission, rooted largely in Poettering's controversial history with systemd and fears about where "cryptographically verifiable integrity" leads when controlled by others.

**Trust and Control as Central Tensions**

The core anxiety crystallizes around a single question: *verifiable to whom?* Commenters immediately drew parallels to Richard Stallman's "Can You Trust Your Computer?" essay, worrying this technology enables remote parties—corporations, governments, platforms—to cryptographically verify and potentially restrict what software users can run. The specter of DRM, locked-down devices, and "kernel mode DRM" dominated early reactions. Stackghost's widely-upvoted comment envisioned a near future where banks, streaming services, and games refuse to function on "insecure" (read: user-controlled) devices.

**The Microsoft Connection**

Enriquto's observation that "half of the founders come from Microsoft" landed heavily, with many treating it as self-explanatory evidence of anti-user intent. This reflects broader anxieties about corporate capture of open infrastructure—Bayindirh's pointed question about whether Microsoft could eventually mandate removing user key enrollment permissions captures this fear precisely.

**Defense and Nuance from Insiders**

Founding engineers pushed back. Aleksa (cyphar) emphasized "users having full control of their keys" as both a freedom and enterprise security necessity. Daan DeMeyer (systemd maintainer) acknowledged systemd's controversial history of "optional" features becoming de facto mandatory, while insisting they "try to make every new feature... opt-in" and that the team remains committed to open source. Bri3d offered a counter-narrative: remote attestation could enable open-source cloud services to cryptographically prove they're running unmodified code—potentially *enhancing* privacy through transparency.

**The systemd Shadow**

Poettering's legacy loomed large. Stackghost's direct question about whether Lennart's "Apple-style you're holding it wrong" attitude has changed resonated with others who lost hours to systemd troubleshooting. Defenders like microtonal argued systemd solved real problems with SysV init, while critics like plagiarist objected to its "cancerous" spread throughout the OS. The concern isn't merely technical but procedural: devsda's worry about systemd maintainers using their position to push Amutable technology through tight coupling reflects a pattern users feel they've seen before.

**Technical Subthreads**

Several threads explored the actual security landscape. Nextgrid noted current Secure Boot is "effectively useless"—it authenticates the kernel but not initrd or userspace—suggesting room for genuine improvement. Others debated whether user-controlled keys (Foxboron: "Secure Boot allows you to enroll your own keys") meaningfully prevents lockdown, or whether market dynamics and network effects inevitably push toward vendor control.

The discussion ultimately pits two visions against each other: cryptographic verification as user-empowering security tool versus as infrastructure for remote control. Amutable's challenge is convincing a deeply skeptical community that "integrity" means *their* integrity, not Netflix's or Microsoft's.

---

## [Super Monkey Ball ported to a website](https://monkeyball-online.pages.dev/)
**Score:** 243 | **Comments:** 72 | **ID:** 46789961

> **Article:** A developer has created a browser-based version of Super Monkey Ball, the classic 2001 GameCube game, playable at monkeyball-online.pages.dev. The project is a TypeScript remake (not an emulator or direct decompilation) based on community reverse engineering efforts and decompiled code from the original game. The implementation features the core physics and gameplay mechanics, though notably lacks the monkey character inside the ball and some original audio elements like the falling scream. The source code is available on GitHub under the name WebMonkeyBall.
>
> **Discussion:** The HN discussion reveals immediate skepticism about AI involvement, with several commenters suspecting Claude generated much of the code based on stylistic patterns and the author's admission of being a "newbie at webdev." This sparked debate about disclosure and attribution, particularly since the author accepts donations. However, others defended the project as legitimate reverse engineering work, noting the author credited decompilation efforts and that the modding community had already documented much of the game's proprietary formats.

Technical observations dominated much of the thread: users noted missing elements (the monkey, the iconic "Aaaah!" fall sound), control sensitivity differences from the original GameCube analog stick, and a bug where completing stage 10 launches the player into space. Mobile users appreciated the gyroscope support, though iOS requires a workaround for permission. A pull request removing committed node_modules highlighted the author's inexperience while also humanizing them.

The project triggered nostalgia and historical reflection, with commenters recalling Super Monkey Ball as a 2008 iPhone App Store launch title that demonstrated native app superiority over web apps—a irony not lost given this browser port's existence. Others compared it to the now-removed GTA Vice City browser port and discussed the broader state of web gaming capabilities versus native platforms. The conversation occasionally veered into appreciation for the animated series Smiling Friends and observations about Dole banana product placement in the original game.

---

## [Show HN: One Human + One Agent = One Browser From Scratch in 20K LOC](https://emsh.cat/one-human-one-agent-one-browser/)
**Score:** 238 | **Comments:** 113 | **ID:** 46779522

> **Project:** A developer ("embedding-shape") built a functional web browser from scratch in 3 days using only themselves plus one AI coding agent (Codex/gpt-5.2). The resulting browser is ~20,000 lines of Rust (14K for the engine + X11, 6K for Windows/macOS support), uses no third-party crates, and can render real websites with HTML/CSS including flexbox and gradients. The project was explicitly positioned as a response to Cursor's recent "FastRender" browser project, which used hundreds of parallel agents over weeks and produced ~1.6 million lines of code. The author spent approximately €19 using ChatGPT Pro's flat-rate plan.
>
> **Discussion:** The discussion centered on what this project demonstrates about AI-assisted software development and how to properly evaluate such achievements.

**On "regurgitation" vs genuine capability:** A skeptical commenter ("deadbabe") dismissed the project as unimpressive, arguing browsers exist in training data so the agent merely reproduced known code. Simon Willison strongly contested this, noting that if regurgitation were the mechanism, the project wouldn't have required three days, thousands of tool calls, and iterative corrections. He emphasized that AI labs actively work to prevent memorization, making "it's in the training data" an unproductive mental model for understanding coding agents.

**Comparison to Cursor's FastRender:** Multiple participants agreed this project represents superior engineering—achieving comparable or better rendering capability with 1/80th the code, minimal dependencies, and readable source (Simon Willison linked to the flexbox implementation as evidence). The author noted they set explicit constraints: no third-party Rust crates, use only system libraries, and support three platforms. This sparked reflection on what makes agentic coding effective. One commenter ("vidarh") described their own multi-agent evaluation framework where code is scored against metrics, automatically tested, and discarded if improvements fail—treating code as "disposable" when it's cheap to generate.

**Human-in-the-loop vs full automation:** Several observers concluded this project undermines the hypothesis that massive parallel agent swarms can replace human judgment. The Cursor experiment asked "can thousands of agents build complex projects autonomously?" while this result suggests "one human + one agent" may be the more productive configuration. As one participant noted, agents lack pushback—they'll dutifully implement wrong approaches, making human direction valuable for problem selection and course correction.

**Practical mechanics:** The author clarified they used GPT-5.2 with "xhigh" reasoning effort via ChatGPT Pro (not API), making the €19 cost essentially "subscription arbitrage"—API pricing would be far higher. On managing context at 20K lines, participants noted modern agents use selective context loading (grepping for relevant code) rather than ingesting entire codebases, with GPT-5.2's 400K token window providing ample headroom.

**Historical perspective:** A former KHTML/Konqueror contributor contrasted today's agent-assisted development with early-2000s browser engineering, where months of labor yielded partial rendering on a smaller web, and standards were effectively "whatever IE was doing." They credited modern machine-readable test suites (CSS specs, W3C tests) as a hidden enabler—agents can validate against real specifications rather than reverse-engineering browser quirks.

Finally, when asked about their background, the author revealed they had no prior browser or systems programming experience (no X11, macOS, or Windows development), identifying primarily as a web developer with strengths in testing, infrastructure, and architecture—suggesting these "meta" skills may transfer effectively to agent collaboration.

---

## [Amazon closing its Fresh and Go stores](https://finance.yahoo.com/news/amazon-closing-fresh-grocery-convenience-150437789.html)
**Score:** 235 | **Comments:** 441 | **ID:** 46781444

> **Article:** Amazon is closing its Fresh grocery stores and Go convenience stores, marking a retreat from its physical retail expansion. The company had invested heavily in these formats, including the "Just Walk Out" technology that promised cashier-less shopping, but struggled to achieve profitability and operational excellence in the competitive grocery market.
>
> **Discussion:** The Hacker News discussion reveals deep skepticism about Amazon's grocery strategy and broader concerns about tech industry practices. Commenters with firsthand experience describe Amazon Fresh as poorly managed, with disorganized stores, expired products on shelves, and staff primarily focused on online order fulfillment rather than customer service. Several noted that Amazon appeared to be running stores at a loss to undercut competitors—pricing avocados at $0.25 and undercutting Walmart by 40% on identical carts—raising concerns about predatory pricing tactics designed to eliminate local competition before establishing market dominance.

The "Just Walk Out" technology attracted particular criticism after revelations that approximately 1,000 workers in India were manually reviewing transactions rather than AI handling everything autonomously. Commenters expressed discomfort with the surveillance-heavy experience, with one describing feeling treated like a presumed thief under constant scrutiny by "a thousand high powered lawyers." Others noted the technology's practical failures, including erroneous $70 charges for small purchases.

The discussion also touched on Amazon's broader pattern of behavior: duping a trucker device inventor by selling a copycat product at half price until he agreed to list on their platform, and the HQ2 fiasco where cities competed to offer incentives before Amazon located where Bezos wanted anyway. Several commenters shared local impacts, including grocery stores driven out by Amazon's expansion only to be replaced by empty storefronts when Amazon never opened or closed locations, creating food deserts.

Some defended aspects of the experience—self-checkout worked fine for many, and the "walk out" convenience appealed to tech-forward shoppers—but the consensus suggested Amazon fundamentally misunderstood grocery retail. As one commenter noted, they solved the wrong problem: optimizing checkout speed while failing to stock basic cooking ingredients and stripping away the human elements that make neighborhood stores function. Regional supermarket Wegmans was held up as a counterexample of what proper grocery retail looks like, though even Wegmans has reportedly declined recently. The conversation ultimately framed Amazon's grocery failure as emblematic of tech's tendency to prioritize growth metrics, surveillance infrastructure, and market dominance over sustainable business fundamentals and genuine customer service.

---

## [Amazon to shut down Go and Fresh stores](https://www.cnn.com/2026/01/27/food/amazon-fresh-go-closures)
**Score:** 233 | **Comments:** 4 | **ID:** 46781707

> **Article:** Amazon announced plans to shut down its Amazon Go cashierless convenience stores and Amazon Fresh grocery stores, marking a significant retreat from its physical retail expansion. The company had invested heavily in these formats—Go stores featured "Just Walk Out" technology using computer vision to eliminate checkout lines, while Fresh represented Amazon's attempt to compete in the traditional grocery space. The closures reflect Amazon's ongoing struggles to make brick-and-mortar retail profitable despite years of experimentation and acquisition (including Whole Foods in 2017).
>
> **Discussion:** The HN discussion was minimal and procedural rather than substantive. Multiple users (chrisbolt, ChrisArchitect) quickly identified the submission as a duplicate of an earlier post, linking to the original discussion at item ID 46781444. Moderator dang consolidated the threads by moving comments to the earlier submission. One user, bigwheels, noted a related macro-expanded submission with 14 comments that had also appeared 37 minutes prior. The lack of actual commentary on the Amazon news itself suggests the community's discussion was already concentrated in the original thread, with this submission serving only as a redirect point.

---

## [The age of Pump and Dump software](https://tautvilas.medium.com/software-pump-and-dump-c8a9a73d313b)
**Score:** 214 | **Comments:** 70 | **ID:** 46780065

> **Article:** The article "The age of Pump and Dump software" by Tautvilas argues that the software industry is increasingly resembling cryptocurrency pump-and-dump schemes. The author points to AI coding tools and projects—specifically Steve Yegge's "Gas Town" (an AI coding agent system) and "Clawdbot" (later rebranded as Molt/Moltbot)—as examples where hype, speculative tokens, and questionable marketing tactics are being used to attract attention and investment. The piece suggests these projects prioritize attention-grabbing and token economics over genuine utility, drawing parallels between the current AI coding boom and the excesses of crypto speculation.
>
> **Discussion:** The HN discussion reveals deep divisions about whether the "pump and dump software" framing is fair or cynical. Several defenders, including one who identifies as a Gas Town user, push back strongly: they describe these projects as genuine experimentation with new technology, not scams, and note they haven't spent money or touched crypto. Leynos offers a detailed counterthesis, framing Gas Town as "speculative fiction" and "experimental spike" into agentic coding—comparable to how Anysphere arrived at similar architectures through their own research. They invoke Andrej Karpathy's "alien technology" metaphor to argue nobody knows how to use these tools properly yet, and public experimentation (with both successes and failures) is necessary.

However, skepticism runs deep on multiple fronts. Storystarling and others question the unit economics of supervisor-worker AI architectures, noting current inference costs make them "significantly more expensive and slower than a human developer"—though Simoncion clarifies Yegge explicitly targeted users who "give zero shits about how much money they're forking over." The Clawdbot/Molt project attracts particular scrutiny: _pdp_ and others identify what they claim is a spam backlink network, Reddit astroturfing, critical security vulnerabilities, and suspicious commit patterns in the source code. Esskay defends the rebrand as a legitimate response to an Anthropic takedown notice, but _pdp_ counters that the new domain shows the same patterns.

Broader themes emerge about the nature of hype cycles and financialization in tech. Multiple commenters draw explicit parallels to VC-funded startups as "the original pump and dump software," with goinghjuk quoting Matt Levine's formulation: "we give you money, and you give us... nothing (0% stake)." Av aer, claiming insider experience with ~$1B in scams, argues this isn't new—just accelerated by unregulated crypto gambling, AI capabilities ordinary people can't evaluate, and social media amplification. They express sadness at how this dynamic corrupts genuinely interesting technology.

The discussion also touches on future visions of software: from Star Trek-style natural language computing to darker Butlerian Jihad scenarios where we reject "thinking machines." Bee_rider speculates future RAG AIs may use today's overcomplicated code as training data for what complexity looks like, while needing simpler stacks themselves. Polishdude20 offers a concrete positive use case—rapid prototyping of a computer vision project for ski lift analysis—which isk517 identifies as perhaps the most viable application of generative AI.

Underlying tensions persist between those who see legitimate exploration and those who detect manipulation. Leggerss attempts to separate the threads: AI experimentation merits encouragement, crypto token attachments remain puzzling, and creator motivations may deserve more charitable interpretation than "reputation laundering"—though they struggle to identify what that interpretation would be. The debate ultimately reflects uncertainty about whether current AI coding tools represent genuine technological transition or speculative bubble, and whether the financial structures surrounding them are corrupting or merely parallel to the underlying innovation.

---

## [Clawdbot Renames to Moltbot](https://github.com/moltbot/moltbot/commit/6d16a658e5ebe6ce15856565a47090d5b9d5dfb6)
**Score:** 213 | **Comments:** 183 | **ID:** 46783863

> **Article:** The GitHub repository "Clawdbot" has been renamed to "Moltbot" following apparent trademark pressure from Anthropic, whose AI assistant is named "Claude." The rename appears to be a defensive move to avoid legal conflict, with the new name referencing a lobster's lifecycle (claw → molt). The project, created by developer Peter Steinberger, is an AI-powered personal assistant that provides autonomous agents with broad system access to control macOS, send iMessages, manage email, and execute code. It has gained extraordinary popularity (70k+ GitHub stars) due to its deep OS integration, entertaining personality via "SOUL.md" configuration, and lack of guardrails compared to more constrained alternatives.
>
> **Discussion:** The HN discussion centers on three interconnected themes: security catastrophism, the project's explosive popularity, and the trademark-driven rename.

**Security concerns dominate the conversation.** Multiple commenters, including prominent AI safety voice Simon Willison, describe Moltbot as a "perfect storm" for prompt injection and "lethal trifecta" attacks—where an AI with tool access, private data access, and autonomy can be manipulated into harmful actions. Willison notes people are connecting these agents to Gmail, iMessage, and Telegram, creating massive attack surfaces. One commenter demonstrates this by successfully prompt-injecting a test message disguised as a doctor's appointment. The "YOLO mode" culture—exemplified by Sam Altman admitting he runs Codex unsafely—represents what another commenter calls "normalization of deviance." Practical mitigations discussed include LXC containers, dedicated hardware (Mac Minis), and guardrail models, though these are acknowledged as incomplete solutions. One commenter darkly suggests this pattern could enable mass-scale cyberattacks through deliberately vulnerable open-source tools.

**The project's popularity draws both admiration and skepticism.** Supporters credit creator Peter Steinberger's exceptional engineering skills, deep CLI ecosystem, macOS/iOS expertise, and entertaining "SOUL.md" personality system that makes interactions genuinely funny. The use of "pi" (likely a CLI framework) rather than standard SDKs is cited as a technical advantage. Critics dismiss it as "vibe-coded slop" replicable in a weekend with Claude Code, questioning why it outperforms long-established alternatives. A nuanced take suggests its appeal lies in superior multi-agent workspace organization—plain-text markdown files for memories, skills, and personalization—plus flexible job types (cron, heartbeat, "lobster" approval workflows) that make automation creation intuitive.

**The rename itself generates mixed reactions.** Most acknowledge Anthropic's legal necessity to defend the "Claude" trademark, with anecdotes about aggressive corporate enforcement (Kellogg's $15M lawsuit over "Leggo My Egg Roll"). Some criticize Anthropic's "obnoxious legal team" for damaging a project's momentum, while others note "clawbot" was also rejected, suggesting minimal viable alternatives existed. The "molt" metaphor finds defenders who consider it adequately memorable, though critics argue the complete brand rupture sacrifices hard-won recognition.

A final undercurrent involves exposed deployments: Shodan searches reveal internet-facing Moltbot instances, predominantly on VPSs, prompting debate about whether home-hosted Mac Minis represent prudent isolation or expensive overkill compared to cheaper NUCs or Pis—complicated by iMessage's Mac-only requirement.

---

## [AI2: Open Coding Agents](https://allenai.org/blog/open-coding-agents)
**Score:** 192 | **Comments:** 30 | **ID:** 46783017

> **Article:** The Allen Institute for AI (AI2) announced SERA-32B, the first model in their "Open Coding Agents" series. It's a 32B parameter coding agent that achieves 49.5% on SWE-bench Verified, matching the performance of larger models like Devstral-Small-2 (24B). The key differentiator is that AI2 releases everything openly: model weights, training code, inference stack, and—crucially—the training data. The model is built by fine-tuning Qwen3-32B. AI2 emphasizes that this "fully open" approach enables reproducible research and community-driven improvements, contrasting with models that only release weights or code without training data.
>
> **Discussion:** The discussion centers on what "open" really means in AI and whether fine-tuning on private codebases is worth the effort. A major thread explores the practical value of fine-tuning versus smart context management. One commenter working on "the biggest codebase in the world" reports that their fine-tuned model performs no better than base models for 99% of tasks, since modern models can already read headers and infer patterns from nearby context. Others agree that intelligently managing context with frontier models beats fine-tuning.

Benchmark comparisons sparked debate. A commenter flagged that AI2's claims ignored Meta's CWM models, which achieve 65% SWE-bench verified (with test-time scaling) at the same size. AI2's Ethan Shen responded that they deliberately excluded TTS to measure raw capability and controlled for context length—CWM uses 128K context versus their 32K, which matters enormously for deployment costs. They also noted their 64K YARN evaluation outperforms CWM's non-TTS result.

The definition of "open" got scrutiny. Philipkglass clarified that AI2's training data openness distinguishes it from Meta's CWM, which shares code and weights but not the training data needed for reproduction. However, kevmo314 pointed out that since SERA-32B fine-tunes Qwen3-32B rather than training from scratch, only a subset of training data is truly accessible.

Other observations: someone noted the article incorrectly called Devstral "closed-weight" when it's actually open-weights; another highlighted that "agent" usually refers to the harness, not the model, making AI2's claim about "only closed agent harness" being Claude questionable. The speed and local deployment potential drew praise, with speculation about language-specific variants and training techniques. Several commenters appreciated AI2's commitment to full openness as a research enabler, with one wryly noting OpenAI's role in reversing the open-source trend.

---

## [India and EU announce landmark trade deal](https://www.bbc.com/news/articles/crrnee01r9jo)
**Score:** 191 | **Comments:** 231 | **ID:** 46778821

> **Article:** India and the EU have announced a landmark trade agreement after years of negotiations. The deal aims to reduce tariffs and boost trade between the two partners, with particular significance given current global trade tensions. Key provisions include tariff reductions across most sectors except agriculture and cars under $17,000, with Indian tariffs on luxury vehicles and motorcycles set to disappear. The agreement also includes a security and defense pact allowing Indian defense technology vendors to participate in EU defense modernization efforts. Additionally, a mobility framework was announced to ease short-term travel restrictions for professionals between India and the EU, though this element has been disputed in reporting. The deal comes as both sides seek to diversify trade relationships amid uncertainty around U.S. trade policy.
>
> **Discussion:** The discussion quickly fragmented into several interconnected debates. The most substantive thread centered on **labor mobility and immigration**, triggered by augusteo's reflection on the difficulties of U.S. immigration and the potential benefits of easier EU-India professional movement. This sparked competing visions of global talent flows: Espressosaurus suggested the U.S. is deliberately ceding competitiveness, while fooker countered that European tech salaries remain far below U.S. levels (3-4x difference), with lawn noting that social benefits like healthcare and education narrow this gap somewhat. The immigration debate became heated, with breitling expressing Canadian concerns about "lop-sided" immigration patterns and diego_moita challenging whether describing human migration in trade terms is appropriate, drawing an analogy to importing groceries.

A **parallel controversy** erupted over BBC's new U.S. paywall, with profsummergig lamenting the loss of a once-universal news source for developing countries, while others noted the geographic disparity in access and defended the funding model. This tangled with a **meta-debate about media bias** when lenkite referred to the BBC as "British state media," prompting scott_w's correction that it's a public broadcaster with editorial independence.

The thread's most unusual dynamic emerged around **alephnerd's detailed geopolitical analysis**, which cited Reuters reporting to dispute the BBC's mobility claims, highlighted Chinese disinformation operations against the deal, and noted suspicious patterns in commenter behavior. This triggered accusations of paranoia from tokai and others, while nindalf vouched for alephnerd's expertise. The exchange illustrated how HN discussions can oscillate between technical policy analysis and suspicion of manipulation.

Economic perspectives varied: mmooss challenged the "rising tide lifts all boats" assumption behind talent mobility, arguing that without explicit worker protections, benefits accrue to elites; sashank_1509 analyzed sectoral trade implications; and orloffm dismissed the deal as primarily serving German automakers. Several commenters framed the agreement strategically—as deafpolygon put it, strengthening relationships "in the face of Trump's tariff shenanigans."

The discussion's fragmentation—jumping between immigration economics, media business models, geopolitical strategy, and moderation concerns—perhaps reflects the deal's own sprawling scope and the charged atmosphere around global mobility in 2025.

---

## [SoundCloud Data Breach Now on HaveIBeenPwned](https://haveibeenpwned.com/Breach/SoundCloud)
**Score:** 179 | **Comments:** 93 | **ID:** 46782930

> **Article:** SoundCloud has disclosed a data breach affecting approximately 29.8 million user accounts (about 20% of its total userbase), now listed on Have I Been Pwned. The breach occurred in December 2025 and involved unauthorized access that allowed an attacker to map publicly available profile data to email addresses. The compromised data includes 30 million unique email addresses, names, usernames, avatars, follower/following counts, and in some cases, user country information. SoundCloud emphasized that no passwords, financial data, or other "sensitive" information were taken, characterizing most of the data as already publicly visible on profiles. However, the critical new exposure is the linkage between email addresses and these public profiles, which previously were not connected.
>
> **Discussion:** The HN discussion reveals significant skepticism about SoundCloud's downplaying of the breach severity, with users noting that while individual data points may have been public, their aggregation and linkage to email addresses creates new privacy risks. Several commenters shared personal experiences illustrating these dangers: one user described how attackers used SoundCloud data to identify and compromise their accounts across multiple services, bypassing two-factor authentication through unknown means.

The conversation also surfaced long-standing grievances with SoundCloud's business practices. Former paying subscribers described hostile retention tactics where canceling premium service leads to hidden tracks and eventual deletion threats, with one user noting they cannot revert to their previous free-tier limits despite being well within documented boundaries. Others criticized platform jankiness, spam ecosystems, and controversial Terms of Service changes permitting ML training on user content.

Security practitioners in the thread recommended standard protective measures—unique passwords via managers and email aliasing—though some noted limited actionable response since passwords weren't compromised. The discussion touched on broader data privacy concerns, including whether this constitutes a GDPR violation and how Have I Been Pwned handles "sensitive" breaches differently. Several users expressed relief at having deleted accounts previously, with one confirming their data was actually purged rather than retained.

A lighter thread emerged around the cultural impact of exposing anonymous artists' real identities, with references to SoundCloud's historical role in launching careers of major artists like Lil B, Post Malone, and Billie Eilish during what some termed the platform's "golden years" of the early 2010s.

---

## [TikTok settles just before social media addiction trial to begin](https://www.bbc.com/news/articles/c24g8v6qr1mo)
**Score:** 175 | **Comments:** 188 | **ID:** 46786237

> **Article:** TikTok has settled a lawsuit just before a trial was set to begin that would have examined claims of social media addiction. The case, part of broader litigation against multiple tech companies including Meta and Google, alleged that TikTok's design intentionally harms young users' mental health through addictive features. The settlement terms were not disclosed. This was a "bellwether trial" combining hundreds of similar cases, intended to test the legal viability of holding social media platforms accountable for addiction-related harms.
>
> **Discussion:** The discussion centers on whether social media platforms, particularly TikTok, bear responsibility for addiction and harm to users—especially young people.

**The nature of the problem.** Liftyee opens with a personal framing: algorithmic feeds provide "free dopamine on tap" that undermines real-world motivation, describing it as getting stuck in a "local minimum." They've responded by blocking most algorithmic feeds entirely. Others push back on this framing—card_zero questions whether interest itself is now suspect, asking if easily available interesting things are inherently bad, and comparing TikTok to pinball as a potential hobby.

**Intentional design versus personal responsibility.** Quarrelsome sharply disagrees with card_zero's abstract framing, arguing these products are "intentionally designed to be addictive by some of the greatest minds of our generation" and that children are "effectively enslaved" for ad revenue. This tension between structural manipulation and individual choice runs throughout. SunshineTheCat raises the parental responsibility angle, comparing TikTok to cheeseburgers—both potentially harmful if overconsumed, questioning where liability lies when parents allow access. Others reject this equivalence: thinkingtoilet finds the comparison absurd, while JumpCrisscross notes the key difference is that TikTok is "handed out for free at the playground."

**The addiction debate.** Dankwizard's suggestion that people should "just put the phone down" draws immediate rebuttals comparing it to telling alcoholics to stop drinking or gamblers to stop betting. Flumpcakes clarifies: "If you could just stop then it isn't really an addiction."

**Why TikTok specifically?** Several commenters question why TikTok is singled out. Publicdebates offers striking personal testimony: 12-14 hours daily use for nearly a full year in 2024, calling their January 2025 ban "one of the best things that ever happened to me." They attribute this to TikTok's algorithm being "significantly better and therefore more addictive." Others note YouTube operates differently—less "relentless dopamine machine gun"—though its Shorts feature attempted to replicate TikTok's model.

**Looking forward.** Echelon situates TikTok as merely "the punch card phase" of immersive entertainment, imagining future "AI holodeck" experiences and speculating that advanced civilizations might turn inward on simulated pleasures rather than expanding outward—offering this as a possible answer to the Fermi paradox.

The thread also touches on legal mechanics: this was a bellwether trial combining hundreds of cases, raising questions about whether similar individual suits will follow, and whether sufficient litigation could force structural change or even put companies out of business.

---

